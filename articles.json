[
  {
    "id": "2026-01-04-ep196-cloud-load-balancer-cheat-sheet",
    "title": "EP196: Cloud Load Balancer Cheat Sheet",
    "date": "2026-01-04",
    "preview": "# EP196: 云负载均衡器备忘录  本周的系统设计回顾： *   云负载均衡器备忘录 *   CQRS 工作原理 *   Docker 工作原理 *   你必须了解的 6 种实用的 AWS Lambda 应用模式 *   容器化解释：从构建到运行时  ## 云负载均衡器备忘录...",
    "content": "# EP196: 云负载均衡器备忘录\n\n本周的系统设计回顾：\n*   云负载均衡器备忘录\n*   CQRS 工作原理\n*   Docker 工作原理\n*   你必须了解的 6 种实用的 AWS Lambda 应用模式\n*   容器化解释：从构建到运行时\n\n## 云负载均衡器备忘录\n\n高效的负载均衡对于优化云中应用程序的性能和可用性至关重要。\n\n然而，鉴于各种类型和配置选项，管理负载均衡器可能会让人不知所措。\n\n在当今的多云环境中，掌握负载均衡对于确保无缝的用户体验和最大化资源利用率至关重要，尤其是在跨多个云提供商编排应用程序时。拥有正确的知识是克服这些挑战并实现一致、可靠的应用程序交付的关键。\n\n在选择合适的负载均衡器类型时，必须考虑应用流量模式、可伸缩性要求和安全考量等因素。通过仔细评估您的具体用例，您可以做出明智的决策，从而提高云基础设施的效率和可靠性。\n\n这份云负载均衡器备忘录将帮助您简化决策过程，并帮助您为基于云的应用程序实施最有效的负载均衡策略。\n\n轮到你了：您认为在为应用程序选择合适的负载均衡器类型时，哪些因素最为关键？\n\n## CQRS 工作原理\n\nCQRS (Command Query Responsibility Segregation，命令查询职责分离) 将写入（Command）和读取（Query）操作分开，以提高可伸缩性和可维护性。\n\n其工作原理如下：\n\n客户端发送一个命令来更新系统状态。Command Handler（命令处理器）使用 Domain Model（领域模型）验证并执行逻辑。\n更改保存到 Write Database（写入数据库）中，也可以保存到 Event Store（事件存储）中。事件被异步发出以更新 Read Model（读取模型）。\n投影（projections）存储在 Read Database 中。该数据库与 Write Database 最终一致。\n\n在查询端，客户端发送一个查询来检索数据。\nQuery Handler（查询处理器）从 Read Database 中获取数据，该数据库包含预计算的投影。\n结果返回给客户端，而不会触及写入模型或写入数据库。\n\n轮到你了：您还会补充哪些内容来帮助理解 CQRS？\n\n## Docker 工作原理\n\nDocker 的架构围绕三个主要组件构建，它们协同工作来构建、分发和运行容器。\n\n**Docker Client（Docker 客户端）**\n这是用户与 Docker 交互的接口。它使用 Docker API 向 Docker Daemon（Docker 守护进程）发送命令（如 build、pull、run、push）。\n\n**Docker Host（Docker 主机）**\n这是 Docker Daemon 运行的地方。它管理镜像、容器、网络和卷，并负责构建和运行应用程序。\n\n**Docker Registry（Docker 注册表）**\nDocker 镜像的存储系统。公共注册表如 Docker Hub 或私有注册表允许拉取（pull）和推送（push）镜像。\n\n轮到你了：您在项目中使用 Docker 吗？\n\n## 你必须了解的 6 种实用的 AWS Lambda 应用模式\n\nAWS Lambda 开创了无服务器（serverless）范式，允许开发人员在无需预置、管理或扩展服务器的情况下运行代码。让我们看看使用 Lambda 可以实现的一些实用应用模式。\n\n### 按需媒体转换\n每当用户从 S3 请求的图像格式不可用时，可以使用 AWS Lambda 进行按需转换。\n\n### 单一来源的多种数据格式\nAWS Lambda 可以与 SNS 配合，创建一个层，在该层中数据可以按所需格式进行处理，然后再发送到存储层。\n\n### 实时数据处理\n创建一个 Kinesis 流和相应的 Lambda 函数，以处理来自应用程序的不同类型数据（如点击流、日志、位置跟踪或事务）。\n\n### 变更数据捕获\nAmazon DynamoDB 可以与 AWS Lambda 集成，以响应 DynamoDB 流中的数据库事件（插入、更新和删除）。\n\n### 无服务器图像处理\n使用 AWS Lambda 以无服务器方式处理和识别图像。与 AWS Step Functions 集成以实现更好的工作流管理。\n\n### 自动化存储过程\n将 Lambda 作为存储过程调用，以在对特定数据库表执行某些操作之前/之后触发功能。\n\n轮到你了：您在项目中使用过 AWS Lambda 吗？\n\n## 容器化解释：从构建到运行时\n\n“一次构建，随处运行。”这是容器化的承诺，以下是其具体工作原理：\n\n### 构建流程\n一切都始于 Dockerfile，它定义了应用程序的构建方式。当你运行 `docker build` 时，它会创建一个包含以下内容的 Docker Image（Docker 镜像）：\n*   你的代码\n*   所需的依赖项\n*   必要的库\n这个镜像具有可移植性。你可以在不同环境之间移动它，并且无论是在本地机器、CI 服务器还是云中，它的行为都将保持一致。\n\n### 运行时架构\n当你运行该镜像时，它就变成了一个 Container（容器），一个执行应用程序的隔离环境。同一个主机上可以运行多个容器，每个容器都有自己的文件系统、进程空间和网络栈。\n容器引擎（如 Docker, containerd, CRI-O 或 Podman）管理：\n*   容器生命周期\n*   网络和隔离\n*   资源分配\n所有容器共享 Host OS kernel（宿主操作系统内核），并位于硬件之上。这就是容器化如何实现一致性和效率的：它像进程一样轻量，但像虚拟机（VM）一样隔离。\n\n轮到你了：部署应用程序时，您更喜欢 Docker、containerd 还是 Podman？为什么？\n\n---\n\n## 要点总结\n\n1.  **云负载均衡器选择**：高效负载均衡是云应用性能和可用性的关键，选择时需考量应用流量模式、伸缩性与安全性。\n2.  **CQRS 核心思想**：CQRS（命令查询职责分离）通过将写入（Command）和读取（Query）操作分离，显著提升系统的可伸缩性和可维护性。\n3.  **CQRS 工作流程**：写入操作更新 Write Database 和可选的 Event Store，并异步更新 Read Model；查询操作则直接从包含预计算投影的 Read Database 获取数据，不影响写入模型。\n4.  **Docker 架构**：Docker 平台由 Docker Client、Docker Host 和 Docker Registry 三大核心组件构成，协同完成容器的构建、分发与运行。\n5.  **Docker 组件职责**：Client 作为用户接口，Host 运行 Daemon 管理容器资源，Registry 负责镜像存储与共享。\n6.  **AWS Lambda 应用模式**：AWS Lambda 开创无服务器范式，提供多种实用模式，如按需媒体转换、多种数据格式处理、实时数据处理、变更数据捕获、无服务器图像处理和自动化存储过程。\n7.  **容器化承诺**：“一次构建，随处运行”是容器化的核心优势，通过 Dockerfile 构建出包含代码、依赖和库的可移植 Docker Image。\n8.  **容器运行时**：Docker Image 运行时转变为 Container，一个独立的隔离环境，共享宿主操作系统的内核但拥有独立的文件系统、进程空间和网络栈。\n9.  **容器引擎作用**：容器引擎（如 Docker, containerd, Podman）负责管理容器的生命周期、网络配置、隔离机制和资源分配。\n10. **容器化优势**：容器化兼具进程的轻量与虚拟机的隔离性，从而实现应用部署的一致性和运行效率。\n\n## 你可以从这篇文章学到什么\n\n对于一位拥有数年经验的后端/系统设计工程师而言，这篇文章提供了一个宝贵的系统设计概念速查与回顾。其价值体现在以下几个方面：\n\n1.  **巩固基础知识**：即使是经验丰富的工程师，也需要定期回顾负载均衡、CQRS、Docker 架构和容器化等核心概念。这篇文章可以帮助工程师梳理和巩固这些基础知识，确保对系统基石的理解牢固且全面。\n\n2.  **拓宽设计思路**：文章涵盖了多个技术领域，提醒工程师在系统设计中可用的丰富工具和模式。例如，AWS Lambda 的具体应用模式，为工程师提供了无服务器函数在基础事件触发之外的更多实际用例，有助于在适当场景下选择更优的解决方案。\n\n3.  **启发式自我评估**：文章中散布的“轮到你了”问题，实则是一种隐性的自我评估机制。工程师在思考这些问题时，可能会发现自己在某些方面理解不够深入，或没有充分考虑特定权衡（例如，选择负载均衡器的关键因素、CQRS 实现的细微之处或不同容器运行时的偏好）。这有助于工程师查漏补缺，促使他们进行更深层次的思考和学习。\n\n4.  **实际应用指导**：\n    *   **负载均衡**：文中对流量模式、可伸缩性和安全性的考虑，直接应用于微服务设计或现有服务扩容。它鼓励工程师重新审视当前的负载均衡策略（如 L4 vs L7、全局 vs 区域负载均衡）。\n    *   **CQRS**：对于高读写负载或复杂领域模型的系统，CQRS 是一种强大的模式。文章的解释有助于评估 CQRS 是否适合系统的特定部分，以提高性能和可维护性，指导架构师对最终一致性和事件溯源做出决策。\n    *   **Docker/容器化**：理解 Docker 的组件和构建/运行流程对于设计 CI/CD 流水线、高效部署应用程序以及故障排除容器化环境至关重要。Docker、containerd 和 Podman 之间的区别与优化运行时环境以及理解 Kubernetes 等编排平台密切相关。\n    *   **AWS Lambda 模式**：这些模式是实现无服务器解决方案的直接“食谱”。工程师可以从中汲取灵感，设计事件驱动架构，用于媒体处理、数据转换、实时分析或数据库变更流处理，从而可能降低特定工作负载的运营开销并提高可伸缩性。\n\n总而言之，这篇文章虽然以“备忘录”或“回顾”的形式呈现，却为经验丰富的工程师提供了可操作的见解，帮助他们验证理解、探索新模式并在日常工作中做出更明智的架构选择。",
    "url": "https://blog.bytebytego.com/p/ep196-cloud-load-balancer-cheat-sheet"
  },
  {
    "id": "2026-01-03-message-brokers-101-storage-replication-and-delivery-guarantees",
    "title": "Message Brokers 101: Storage, Replication, and Delivery Guarantees",
    "date": "2026-01-03",
    "preview": "# 消息代理 101: 存储、复制和交付保证  消息代理（Message Broker）是一种中间件系统，它通过消息促进应用程序和服务之间的异步通信。  其核心作用在于，消息代理将信息的生产者（producer）与消费者（consumer）解耦，使它们能够独立运行，而无需直接了解...",
    "content": "# 消息代理 101: 存储、复制和交付保证\n\n消息代理（Message Broker）是一种中间件系统，它通过消息促进应用程序和服务之间的异步通信。\n\n其核心作用在于，消息代理将信息的生产者（producer）与消费者（consumer）解耦，使它们能够独立运行，而无需直接了解彼此。这种解耦是现代分布式架构的基础，在这种架构中，服务通过消息代理而不是直接相互通信，从而能够独立演进，避免紧密耦合。\n\n为了在实践中理解这一点，考虑一个订单处理服务，它在消息代理上放置一条“订单已下达”（Order Placed）消息。库存、账单和发货等下游服务将在准备好处理时从消息代理获取该消息，而不是由订单服务同步调用它们。这种方法消除了订单服务需要了解或等待这些下游系统的必要性。\n\n消息代理不仅仅是数据传输的管道。它们是专门用于流处理（stream processing）和任务分发（task distribution）等功能的复杂分布式数据库。消息代理的核心价值主张在于它能够在不同系统之间引入一个时间缓冲区（temporal buffer）。通过允许生产者在不等待消费者处理的情况下发送消息，消息代理促进了时间解耦（temporal decoupling）。这确保了入口点（ingress point）的流量激增不会立即压垮下游服务。\n\n在本文中，我们将详细探讨消息代理的工作原理，并探索它们在分布式系统设计中启用的各种模式。\n\n## 要点总结\n\n*   消息代理是实现应用程序和服务之间异步通信的中间件。\n*   其核心价值在于解耦生产者和消费者，使它们独立运作，无需直接了解彼此。\n*   解耦是现代分布式架构的关键，支持服务独立演进和松耦合。\n*   通过将“订单已下达”等消息发布到代理，下游服务（如库存、账单、发货）可在准备就绪时处理，避免订单服务同步等待。\n*   消息代理不仅是数据管道，更是专门用于流处理和任务分发的分布式数据库。\n*   它们引入了时间缓冲区，实现了时间解耦，生产者无需等待消费者即可发送消息。\n*   这种机制有效防止了入口流量高峰对下游服务的瞬时冲击，提高了系统韧性。\n*   文章将深入探讨消息代理的工作原理及其在分布式系统设计中的应用模式。\n\n## 你可以从这篇文章学到什么\n\n对于一个拥有几年经验的后端/系统设计工程师来说，这篇文章提供了一个对消息代理核心价值的精炼介绍，能够帮助你巩固和深化对分布式系统设计中异步通信模式的理解。\n\n1.  **理解解耦的深层意义**：文章强调了消息代理如何通过“时间解耦”（temporal decoupling）实现生产者和消费者的独立运行。这不仅仅是技术实现上的分离，更是业务流程上并行和容错的基础。在设计微服务或大型分布式系统时，你需要考虑哪些组件需要强一致性，哪些可以通过消息代理实现最终一致性，从而提高系统的整体吞吐量和可用性。\n2.  **消息代理的“数据库”属性**：将消息代理视为“专用于流处理和任务分发的分布式数据库”，这个视角非常重要。它提醒我们，消息代理不仅仅是传输数据的管道，更负责消息的持久化、复制和保证（如交付保证）。这对于你选择合适的消息队列（例如 Kafka、RabbitMQ）以及设计消息处理的幂等性、顺序性等高级特性时，具有指导意义。\n3.  **流量削峰与系统韧性**：文章明确指出消息代理能够作为“时间缓冲区”来防止流量激增压垮下游服务。这在处理高并发、突发流量或不同服务处理能力不匹配的场景中至关重要。你可以在实际项目中应用这一理念，通过引入消息队列来缓冲请求，保护核心服务，避免雪崩效应。\n4.  **架构模式的启发**：虽然文章内容是入门级的，但它为理解后续更复杂的分布式系统模式（如事件驱动架构、Saga 模式、CQRS 等）奠定了基础。理解消息代理如何支持异步通信，将帮助你更好地设计可扩展、高可用的系统，并应对各种分布式事务和数据一致性挑战。\n\n总之，这篇文章为你提供了一个理解消息代理在现代分布式架构中不可或缺作用的起点，并指明了其在提高系统解耦性、韧性和可扩展性方面的关键价值。",
    "url": "https://blog.bytebytego.com/p/message-brokers-101-storage-replication"
  },
  {
    "id": "2026-01-02-message-brokers-101-storage-replication-and-delivery-guarantees",
    "title": "Message Brokers 101: Storage, Replication, and Delivery Guarantees",
    "date": "2026-01-02",
    "preview": "# 消息队列 101：存储、复制与投递保证  消息队列（Message Broker）是一种中间件系统，它通过消息促进应用程序和服务之间的异步通信。  其核心在于，消息队列将信息生产者（producers）与消费者（consumers）解耦，使它们能够独立运行，无需直接了解彼此。...",
    "content": "# 消息队列 101：存储、复制与投递保证\n\n消息队列（Message Broker）是一种中间件系统，它通过消息促进应用程序和服务之间的异步通信。\n\n其核心在于，消息队列将信息生产者（producers）与消费者（consumers）解耦，使它们能够独立运行，无需直接了解彼此。这种解耦是现代分布式架构的基础，其中服务通过消息队列而非直接相互通信，从而使它们能够独立演进，避免紧密耦合。\n\n为了在实践中理解这一点，考虑一个订单处理服务，它将一条“订单已下达”（Order Placed）消息放置在消息队列中。库存、计费和发货等下游服务将在准备好处理时从消息队列中获取该消息，而不是由订单服务同步调用每个服务。这种方法消除了订单服务需要了解或等待这些下游系统的需求。\n\n消息队列不仅仅是数据传输的管道。它们是复杂的分布式数据库，专门用于流处理（stream processing）和任务分发（task distribution）等功能。消息队列的核心价值主张在于其能够在不同系统之间引入一个时间缓冲区（temporal buffer）。通过允许生产者发送消息而无需等待消费者处理，消息队列促进了时间解耦（temporal decoupling）。这确保了入口点（ingress point）的流量激增不会立即压垮下游服务。\n\n在本文中，我们将详细探讨消息队列的工作原理，并探究它们在分布式系统设计中启用的各种模式。\n\n## 要点总结\n\n*   消息队列是一种中间件系统，用于实现应用程序和服务之间的异步通信。\n*   其核心功能是将信息生产者与消费者解耦，允许它们独立运行，无需直接了解彼此。\n*   这种解耦是现代分布式架构的基石，能够促进服务的独立演进并避免紧密耦合。\n*   通过消息队列，上游服务（如订单处理）无需同步等待下游服务（如库存、计费、发货），从而提高系统响应速度和弹性。\n*   消息队列不仅仅是数据传输管道，更是专为流处理和任务分发等功能设计的复杂分布式数据库。\n*   消息队列的关键价值在于引入一个时间缓冲区，实现系统间的时间解耦。\n*   时间解耦能够确保在入口点出现流量激增时，下游服务不会立即被压垮，从而提高系统的韧性。\n\n## 你可以从这篇文章学到什么\n\n对于拥有数年经验的后端或系统设计工程师来说，这篇文章提供了一个深入理解消息队列核心价值和工作原理的机会，不仅仅停留在其作为“异步通信工具”的表面认知上。\n\n你可以从中学到：\n\n1.  **深化对解耦的理解**：文章强调了消息队列在**空间解耦**（服务互不感知）和**时间解耦**（生产者无需等待消费者）方面的关键作用。这对于设计高度可伸缩、容错和易于维护的微服务架构至关重要。\n2.  **消息队列的本质定位**：将消息队列视为“复杂的分布式数据库，专门用于流处理和任务分发”，这改变了其简单的“管道”形象。这种视角提示我们在设计系统时，需要像对待数据库一样考虑消息队列的**存储、持久性、复制和数据一致性**，尤其在处理关键业务数据时。\n3.  **流量削峰填谷的能力**：文中提到的“时间缓冲区”和“避免压垮下游服务”直指消息队列在应对突发流量方面的核心价值。工程师可以学习如何利用这一特性，设计更具韧性和弹性的系统，有效管理入口流量，防止雪崩效应。\n4.  **实际应用场景的启发**：通过订单处理服务的例子，具体展示了消息队列在复杂业务流程中的应用，提示工程师在设计事件驱动型架构时，可以如何将业务操作分解为独立的消息事件，并由不同的服务异步处理。\n5.  **为深入研究打下基础**：虽然文章是“101”系列，但其标题中的“存储、复制与投递保证”以及文中对“分布式数据库”的提及，都为工程师指明了进一步深入学习消息队列的关键技术点，例如消息的持久化机制、集群复制策略、死信队列（DLQ）、幂等性处理以及各种投递语义（至少一次、至多一次、恰好一次）等，这些都是在生产环境中设计高可靠消息系统时必须考虑的问题。",
    "url": "https://blog.bytebytego.com/p/message-brokers-101-storage-replication"
  },
  {
    "id": "2026-01-01-openai-clip-the-model-that-learnt-zero-shot-image-recognition-using-text",
    "title": "OpenAI CLIP: The Model That Learnt Zero-Shot Image Recognition Using Text",
    "date": "2026-01-01",
    "preview": "# OpenAI CLIP：通过文本学习零样本图像识别的模型  想象一下，教计算机识别物体，不是通过向它展示数百万张带标签的照片，而是让它浏览互联网，并从人们自然描述图像的方式中学习。这正是 OpenAI 的 CLIP 所做的，它代表了我们教机器理解视觉内容方式的根本性转变。  ...",
    "content": "# OpenAI CLIP：通过文本学习零样本图像识别的模型\n\n想象一下，教计算机识别物体，不是通过向它展示数百万张带标签的照片，而是让它浏览互联网，并从人们自然描述图像的方式中学习。这正是 OpenAI 的 CLIP 所做的，它代表了我们教机器理解视觉内容方式的根本性转变。\n\nCLIP (Contrastive Language-Image Pre-training) 是一个连接视觉和语言的神经网络。它于 2021 年 1 月发布，能够将图像分类到任何你想要的类别中，而无需专门为该任务进行训练。只需用简单的英语告诉它你在寻找什么，它就能识别出来。这种“零样本”（zero-shot）能力使 CLIP 不同于几乎所有之前的计算机视觉系统。\n\n在本文中，我们将探讨 CLIP 的工作原理以及它试图解决的问题。\n\n## CLIP 解决的问题\n\n传统的计算机视觉遵循僵化的模式。如果你想让一个模型区分猫和狗，你需要数千张带标签的照片。对于不同的汽车型号，你需要另一个昂贵的数据集。举例来说，ImageNet 是最著名的图像数据集之一，它需要超过 25,000 名工人来标注 1400 万张图像。\n\n这种方法产生了三个主要问题：\n\n首先，数据集的构建成本高昂且耗时。\n\n其次，模型成为狭隘的专业领域专家。一个 ImageNet 模型可以识别 1,000 个类别，但要适应新任务需要收集更多数据并重新训练。\n\n第三，模型可以通过优化特定基准来“作弊”。\n\n例如，一个在 ImageNet 上达到 76% 准确率的模型，在相同物体的草图上可能会下降到 37%，或者在略微修改的图像上骤降到 2.7%。模型学会了 ImageNet 的“怪癖”，而不是真正理解视觉概念。\n\nCLIP 的方法则截然不同。它不是在精心标注的数据集上进行训练，而是从互联网上收集的 4 亿个图像-文本对中学习。这些对在网上随处可见：带有描述的 Instagram 照片、带有图像的新闻文章、带有描述的产品列表以及带有图片的维基百科条目。人们自然会编写描述、解释或评论图像的文本，从而产生了巨大的训练数据源。\n\n然而，CLIP 并不试图预测特定的类别标签。相反，它学习将图像与其对应的文本描述进行匹配。在训练期间，CLIP 会看到一张图像和一大批文本片段（一次 32,768 个）。它的任务是确定哪个文本片段最能匹配该图像。\n\n可以把它想象成一个大型匹配游戏。例如，我们向系统展示一张金毛犬在公园玩耍的照片。在 32,768 个文本选项中，只有一个是正确的：可能是“一只金毛犬在公园里玩接球”。其他 32,767 个选项可能包括“一只黑猫在睡觉”、“日落时的山景”、“一个人在吃披萨”以及数千种其他描述。为了在数百万个此类示例中始终选择正确的匹配，CLIP 必须学习物体、场景、动作和属性的外观以及它们如何与语言对应。\n\n通过一遍又一遍地使用极其多样化的互联网数据解决这个匹配任务，CLIP 形成了对视觉概念及其语言描述的深刻理解。例如，它可能学会了毛茸茸、四条腿、摇着尾巴的动物对应着“狗”和“小狗”等词汇。它可能学会了水面上橙色和粉红色的天空与“日落”和“海滩”相关。换句话说，它建立了一个连接视觉和语言世界的丰富心智模型。\n\n## 技术基础\n\n在底层，CLIP 使用两个独立的神经网络协同工作：一个图像编码器（image encoder）和一个文本编码器（text encoder）。\n\n图像编码器接收原始像素并将其转换为数值向量（称为嵌入，embedding）。文本编码器接收单词和句子，也输出一个向量。关键的见解是，两个编码器都在相同的维度空间中输出向量，这使得它们可以直接比较。\n\n最初，这些编码器可能会产生完全随机、无意义的向量。例如，一张狗的图像可能变为 [0.2, -0.7, 0.3, ...]，而文本“狗”变为 [-0.5, 0.1, 0.9, ...]。这些数字之间没有任何关系。但这就是训练发挥魔力的地方。\n\n训练过程使用所谓的对比损失函数（contrastive loss function）。这只是一种衡量模型当前错误程度的数学方法。对于正确的图像-文本对（例如狗的图像与“狗在玩接球”），损失函数表示这些嵌入应该非常相似。对于不正确的对（例如狗的图像与“猫在睡觉”），它表示它们应该非常不同。损失函数产生一个数字，代表一个批次中所有图像和文本的总误差。\n\n如下图所示：\n\nSource: OpenAI Research Blog\n\n接下来是反向传播（backpropagation），这是神经网络中的基本学习机制。它精确计算每个编码器中的每个权重应该如何改变以减少这个误差。权重会轻微更新，然后这个过程会用不同的数据批次重复数百万次。逐渐地，两个编码器都学会为匹配的概念生成相似的向量。例如，狗的图像开始生成接近文本编码器放置“狗”一词的向量。\n\n换句话说，通过在数百万个不同示例中持续承受匹配正确对和分离不正确对的压力，编码器进化出能够“说”相同语言的能力。\n\n## 零样本分类实战\n\n一旦 CLIP 训练完成，其零样本能力便显而易见。假设我们要将图像分类为包含狗或猫。我们不需要重新训练 CLIP 或向其展示带标签的示例。\n\n相反，我们可以简单地获取图像，通过图像编码器获取其嵌入（embedding）。接下来，我们可以将文本“一只狗的照片”通过文本编码器获取另一个嵌入。然后，我们可以将文本“一只猫的照片”获取第三个嵌入。比较哪个文本嵌入与图像嵌入更接近，这就是答案。\n\n如下图所示：\n\nSource: OpenAI Research Blog\n\nCLIP 本质上是在问：“根据从互联网上学到的一切，这张图像更可能与描述狗的文本一起出现，还是与描述猫的文本一起出现？”\n\n由于它从如此多样化的数据中学习，这种方法适用于您可以用文字描述的几乎任何分类任务。\n\n想对食物类型进行分类吗？使用“一张披萨的照片”、“一张寿司的照片”、“一张玉米饼的照片”作为您的类别。需要分析卫星图像吗？尝试“一张森林的卫星照片”、“一张城市的卫星照片”、“一张农田的卫星照片”。处理医学图像？您可以使用“一张显示肺炎的 X 光片”与“一张健康肺部的 X 光片”。您只需更改文本描述。无需重新训练。\n\n这种灵活性是变革性的。传统模型需要针对每个新任务提供大量的带标签数据集。CLIP 可以立即处理新任务，其唯一限制是您用自然语言描述类别的能力。\n\n## 使 CLIP 成为可能的设计选择\n\nCLIP 的成功不仅仅在于核心思想。OpenAI 做出了两个关键的技术决策，使训练在计算上变得可行。\n\n首先，他们选择了对比学习（contrastive learning），而不是更显而易见的训练模型生成图像描述的方法。早期的实验尝试教系统看图像并逐字生成完整的文本描述，类似于语言模型生成文本的方式。虽然直观，但这种方法被证明速度极慢且计算成本高昂。生成整个句子所需的计算量远多于简单地学习将图像与文本进行匹配。对比学习在实现良好零样本性能方面，效率是其 4 到 10 倍。\n\n其次，他们对图像编码器采用了 Vision Transformers（视觉 Transformer）。Transformers 是 GPT 和 BERT 背后的架构，已经彻底改变了自然语言处理。将其应用于图像（将图像块视为句子中的单词）相比传统卷积神经网络（如 ResNet）又提供了 3 倍的计算效率提升。\n\nSource: OpenAI Research Blog\n\n这些选择的结合意味着 CLIP 可以在 256 个 GPU 上训练两周，这与当时其他大规模视觉模型所需的时间相似，而不是需要天文数字般的计算量。\n\n## 结论\n\nOpenAI 在 30 多个不同的数据集上测试了 CLIP，涵盖了各种任务：细粒度分类、光学字符识别（OCR）、动作识别、地理定位和卫星图像分析。\n\n结果验证了 CLIP 的方法。虽然在标准 ImageNet 上与 ResNet-50 的 76.2% 准确率持平，但 CLIP 在 26 个迁移学习基准测试中的 20 个上优于现有最好的公开 ImageNet 模型。更重要的是，在传统模型崩溃的压力测试中，CLIP 保持了强大的性能。在 ImageNet Sketch 上，CLIP 达到了 60.2% 的准确率，而 ResNet 只有 25.2%。在对抗性示例上，CLIP 得分为 77.1%，而 ResNet 为 2.7%。\n\nSource: OpenAI Research Blog\n\n然而，该模型在某些方面仍然存在不足，例如：\n\n*   需要精确空间推理或计数的任务。它在非常细微的区分上也有困难，例如区分相似的汽车型号或飞机变体，这些地方微妙的细节很重要。\n*   在 MNIST 数据集（在计算机视觉领域被认为是微不足道的任务）上的手写数字测试中，CLIP 仅达到 88% 的准确率，远低于人类 99.75% 的表现。\n*   CLIP 对文本提示的措辞方式很敏感。有时需要反复试验（“提示工程”，prompt engineering）才能找到效果良好的措辞。\n*   CLIP 继承了其互联网训练数据中的偏差。我们措辞类别的方式可能会以有问题的​​方式显著影响模型的行为。\n\n然而，尽管存在局限性，CLIP 证明了驱动近期自然语言处理突破（从大量互联网文本中学习）的方法可以迁移到计算机视觉领域。正如 GPT 模型通过训练互联网文本学习执行各种语言任务一样，CLIP 通过训练互联网图像-文本对学习执行各种视觉任务。\n\n自发布以来，CLIP 已成为人工智能行业的基础设施。它完全开源，促进了广泛的采用。像 Stable Diffusion 和 DALL-E 这样的现代文本到图像系统使用 CLIP 类的模型来理解文本提示。公司将其用于图像搜索、内容审核和推荐。\n\n## 参考文献\n\n*   CLIP: Connecting Text and Images\n*   What is ImageNet\n\n---\n\n## 要点总结\n\n*   **零样本图像识别**：CLIP 通过从互联网上学习海量图像-文本对，实现了无需特定训练即可进行图像分类的“零样本”能力。\n*   **解决传统模型局限**：它克服了传统计算机视觉模型对昂贵、耗时数据集的依赖、模型专业性狭隘以及模型可能“作弊”优化基准的问题。\n*   **对比学习机制**：CLIP 不预测具体的类别标签，而是学习将图像与其对应的文本描述进行匹配，其核心是对比学习（contrastive learning），通过使匹配对的嵌入相似、不匹配对的嵌入相异来训练模型。\n*   **双编码器架构**：模型包含独立的图像编码器和文本编码器，它们将输入转换为相同维度空间的向量（embeddings），从而实现直接比较。\n*   **Transformer 应用**：图像编码器采用了 Vision Transformer 架构，相较于传统的卷积神经网络，进一步提升了计算效率。\n*   **训练效率提升**：对比学习和 Vision Transformer 的结合，使得 CLIP 可以在相对可接受的计算资源下进行大规模训练。\n*   **广泛适用性**：经过训练的 CLIP 模型能够灵活应用于各种分类任务，只需通过自然语言描述类别，无需重新训练。\n*   **优异的泛化能力**：CLIP 在 ImageNet Sketch 和对抗性示例等压力测试中表现出比传统模型更强的泛化能力和鲁棒性。\n*   **当前局限性**：模型在精确空间推理、细粒度区分、对提示（prompt）措辞的敏感性以及继承训练数据的偏见方面仍有待改进。\n*   **AI 基础设施**：CLIP 已成为 AI 领域的基础设施，广泛应用于文本到图像生成、图像搜索、内容审核和推荐等场景。\n\n## 你可以从这篇文章学到什么\n\n对于一个有几年经验的后端/系统设计工程师来说，这篇文章不仅介绍了 OpenAI CLIP 这一革命性的 AI 模型，更重要的是，它揭示了几个重要的系统设计和机器学习工程思想，可以启发你在实际工作中：\n\n1.  **大规模数据利用的范式转变**：CLIP 的成功在于它从“噪声”中学习，即从互联网上非结构化的海量图像-文本对中提炼知识。这与传统机器学习依赖于精心标注的干净数据集形成鲜明对比。这启发我们，在设计数据密集型系统时，可以考虑如何利用更大规模、更自然的“弱监督”数据源，而不是过度依赖高成本的人工标注。这对于构建高扩展性、低成本的数据管道至关重要。\n2.  **多模态融合设计**：CLIP 通过图像编码器和文本编码器将视觉和语言映射到同一个嵌入空间。这种多模态（multi-modal）融合的设计思想在现代系统中越来越常见。作为后端工程师，当面对需要处理多种数据类型（如文本、图像、视频、传感器数据）的系统时，可以考虑设计统一的嵌入（embedding）层，从而实现不同模态数据之间的关联、检索和推理。这对于推荐系统、搜索服务、内容理解等领域都有很高的应用价值。\n3.  **对比学习与表征学习**：对比学习是 CLIP 的核心训练范式，它通过“区分”正确与错误配对来学习高质量的特征表示。这种“无监督”或“自监督”的表征学习方法在数据标注成本高昂的场景下非常有用。在设计数据平台或特征工程管道时，可以思考如何利用这种方法，从大量未标注数据中学习出有意义的特征，减少对昂贵标签数据的依赖，从而为下游任务提供更强大的输入。\n4.  **模型架构的选择与效率**：文章提到 CLIP 成功得益于选择了对比学习而非序列生成，并采用了 Vision Transformer。这强调了在大型模型设计中，架构选择对计算效率和性能的巨大影响。作为系统工程师，在评估和集成 AI 模型时，除了关注模型效果，更要深入理解其底层计算复杂度、资源需求（GPU、内存）以及训练/推理效率。选择合适的模型架构和训练范式，直接决定了系统是否能在生产环境中可行和经济。\n5.  **零样本/少样本能力的重要性**：CLIP 的零样本能力意味着模型可以在没有新任务特定训练数据的情况下，直接处理新任务。这种能力对于快速迭代、面对不断变化的业务需求的系统至关重要。在设计通用 AI 服务平台时，如何构建具备强大泛化能力和零样本学习潜力的模型，将大大降低新功能开发的成本和时间。\n6.  **Prompt Engineering 的概念**：CLIP 对文本提示的敏感性引入了“提示工程”（Prompt Engineering）的概念。这表明即使是强大的基础模型，其性能也可能受到用户输入方式的显著影响。在设计基于大模型的应用时，我们需要考虑如何引导用户提供清晰有效的提示，或者在后端进行提示的优化和标准化，以确保模型的稳定性和准确性。\n\n总的来说，CLIP 不仅是一个图像识别模型，它更是一个关于如何从大规模非结构化数据中学习、如何进行多模态融合、如何平衡效率与性能的系统性思考的典范。理解这些深层设计理念，能够帮助后端和系统工程师在构建更智能、更高效、更具扩展性的 AI 驱动系统时做出更明智的决策。",
    "url": "https://blog.bytebytego.com/p/openai-clip-the-model-that-learnt"
  },
  {
    "id": "2025-12-31-openai-clip-the-model-that-learnt-zero-shot-image-recognition-using-text",
    "title": "OpenAI CLIP: The Model That Learnt Zero-Shot Image Recognition Using Text",
    "date": "2025-12-31",
    "preview": "# OpenAI CLIP：通过文本学习零样本图像识别的模型  想象一下，教计算机识别物体，不是通过向它展示数百万张带标签的照片，而是让它浏览互联网，并从人们自然描述图像的方式中学习。这正是 OpenAI 的 CLIP 所做的事情，它代表了我们教机器理解视觉内容方式的根本性转变。...",
    "content": "# OpenAI CLIP：通过文本学习零样本图像识别的模型\n\n想象一下，教计算机识别物体，不是通过向它展示数百万张带标签的照片，而是让它浏览互联网，并从人们自然描述图像的方式中学习。这正是 OpenAI 的 CLIP 所做的事情，它代表了我们教机器理解视觉内容方式的根本性转变。\n\nCLIP（Contrastive Language-Image Pre-training，对比语言-图像预训练）是一个连接视觉和语言的神经网络。它于 2021 年 1 月发布，能够将图像分类到你想要的任何类别中，而无需专门为此任务进行训练。你只需用通俗易懂的英语告诉它你在寻找什么，它就能识别出来。这种“零样本”（zero-shot）能力使 CLIP 不同于几乎所有之前的计算机视觉系统。\n\n本文将探讨 CLIP 的工作原理以及它试图解决的问题。\n\n## CLIP 解决的问题\n\n传统的计算机视觉遵循严格的公式。如果你想让一个模型区分猫和狗，你需要数千张带标签的照片。对于不同的汽车型号，你需要另一个昂贵的数据集。举例来说，ImageNet 是最著名的图像数据集之一，它需要超过 25,000 名工作人员标注 1400 万张图像。\n\n这种方法带来了三个主要问题：\n\n*   首先，数据集的构建成本高昂且耗时。\n*   其次，模型变成了狭隘的专家。一个 ImageNet 模型可以识别 1,000 个类别，但要使其适应新任务，就需要收集更多数据并重新训练。\n*   第三，模型可能会通过针对特定基准进行优化来“作弊”。\n\n例如，一个在 ImageNet 上达到 76% 准确率的模型，在相同物体的草图上可能会下降到 37%，或者在略微修改的图像上骤降到 2.7%。模型学会了 ImageNet 的特性，而不是真正理解视觉概念。\n\nCLIP 的方法则截然不同。它不是在精心标注的数据集上进行训练，而是从互联网上收集的 4 亿个图像-文本对中学习。这些对在网上随处可见：带有标题的 Instagram 照片、带有图像的新闻文章、带有描述的产品列表以及带有图片的维基百科条目。人们自然会编写描述、解释或评论图像的文本，这创造了一个巨大的训练数据来源。\n\n然而，CLIP 并不试图预测特定的类别标签。相反，它学习将图像与其对应的文本描述进行匹配。在训练过程中，CLIP 会看到一张图像和一大批文本片段（一次 32,768 个）。它的任务是确定哪个文本片段最能匹配该图像。\n\n可以将其想象成一个大型的配对游戏。例如，我们向系统展示一张金毛犬在公园玩耍的照片。在 32,768 个文本选项中，只有一个是正确的：可能​​是“一只金毛犬在公园里玩耍”。其他 32,767 个选项可能包括“一只黑猫在睡觉”、“日落时分的山景”、“一个人在吃披萨”以及成千上万的其他描述。为了在数百万个此类示例中始终选择正确的匹配项，CLIP 必须学习物体、场景、动作和属性的外观以及它们如何与语言对应。\n\n通过一遍又一遍地使用极其多样化的互联网数据解决这个匹配任务，CLIP 对视觉概念及其语言描述形成了深刻的理解。例如，它可能学习到毛茸茸、四条腿、摇着尾巴的动物与“狗”和“小狗”等词汇对应。它可能学习到水面上的橙色和粉红色天空与“日落”和“海滩”相关。换句话说，它建立了一个连接视觉世界和语言世界的丰富心智模型。\n\n## 技术基础\n\n在底层，CLIP 使用两个独立的神经网络协同工作：一个图像编码器（image encoder）和一个文本编码器（text encoder）。\n\n图像编码器将原始像素转换为一个数值向量（称为嵌入，embedding）。文本编码器将单词和句子也输出为一个向量。关键的洞察是，两个编码器都在相同的维度空间中输出向量，这使得它们可以直接进行比较。\n\n最初，这些编码器可能会产生完全随机、毫无意义的向量。例如，一张狗的图像可能变成 [0.2, -0.7, 0.3, ...]，而文本“dog”变成 [-0.5, 0.1, 0.9, ...]。这些数字之间没有任何关系。但这就是训练发挥魔力的地方。\n\n训练过程使用了一种称为对比损失函数（contrastive loss function）的方法。这仅仅是一种衡量模型当前错误程度的数学方法。对于正确的图像-文本对（例如狗的图像与“狗在玩耍”），损失函数会说这些嵌入应该非常相似。对于不正确的对（例如狗的图像与“猫在睡觉”），它会说它们应该非常不同。损失函数会产生一个单一的数字，表示批次中所有图像和文本的总误差。\n\n参见下图：\nSource: OpenAI Research Blog\n\n然后是反向传播（backpropagation），这是神经网络中的基本学习机制。它精确计算出两个编码器中每个权重应该如何改变以减少这个误差。权重会轻微更新，这个过程会随着不同批次的数据重复数百万次。逐渐地，两个编码器都学会了为匹配的概念生成相似的向量。例如，狗的图像开始生成接近文本编码器放置“狗”这个词的向量。\n\n换句话说，通过在数百万个多样化示例中不断施加压力以匹配正确的对并分离不正确的对，编码器逐渐演化出能够“说”相同语言的能力。\n\n## 零样本分类实战\n\n一旦 CLIP 训练完成，其零样本能力就变得显而易见。假设我们想将图像分类为包含狗或猫。我们不需要重新训练 CLIP 或向其展示带标签的示例。\n\n相反，我们可以简单地获取图像，并通过图像编码器将其转换为嵌入。接下来，我们可以获取文本“一只狗的照片”，并通过文本编码器获取另一个嵌入。然后，我们可以获取文本“一只猫的照片”，获取第三个嵌入。比较哪个文本嵌入与图像嵌入更接近，这就是答案。\n\n参见下图：\nSource: OpenAI Research Blog\n\nCLIP 本质上是在问：“根据从互联网上学到的一切，这张图像更可能与关于狗的文本一起出现，还是与关于猫的文本一起出现？”\n\n因为它从如此多样化的数据中学习，所以这种方法适用于你能够用语言描述的几乎任何分类任务。\n\n想要对食物类型进行分类？使用“一张披萨的照片”、“一张寿司的照片”、“一张玉米饼的照片”作为你的类别。需要分析卫星图像？尝试“一张森林的卫星照片”、“一张城市的卫星照片”、“一张农田的卫星照片”。处理医学图像？你可以使用“一张显示肺炎的 X 射线”与“一张健康肺部的 X 射线”。你只需更改文本描述。无需重新训练。\n\n这种灵活性具有变革性。传统模型需要为每个新任务准备大量的带标签数据集。CLIP 可以立即处理新任务，唯一受限的是你用自然语言描述类别的能力。\n\n## 使 CLIP 成为可能的设计选择\n\nCLIP 的成功不仅仅在于核心思想。OpenAI 做出了两个关键的技术决策，使得训练在计算上变得可行。\n\n首先，他们选择了对比学习（contrastive learning），而不是更明显的训练模型生成图像标题的方法。早期的实验尝试教系统看图像并逐字生成完整的文本描述，类似于语言模型生成文本的方式。虽然直观，但这种方法被证明速度极慢且计算成本极高。生成完整的句子比简单地学习匹配图像和文本需要更多的计算。事实证明，对比学习在实现良好零样本性能方面效率高出 4 到 10 倍。\n\n其次，他们为图像编码器采用了 Vision Transformers（视觉 Transformer）。Transformers 架构是 GPT 和 BERT 背后的技术，已经彻底改变了自然语言处理。将其应用于图像（将图像块视为句子中的单词）比传统的卷积神经网络（如 ResNet）又带来了 3 倍的计算效率提升。\n\nSource: OpenAI Research Blog\n\n这些选择的结合意味着 CLIP 可以在 256 个 GPU 上训练两周，与当时其他大型视觉模型所需的时间相似，而不需要天文数字般的更多计算资源。\n\n## 结论\n\nOpenAI 在 30 多个不同的数据集上测试了 CLIP，涵盖了各种任务：细粒度分类、光学字符识别（OCR）、动作识别、地理定位和卫星图像分析。\n\n结果验证了 CLIP 的方法。CLIP 在标准 ImageNet 上达到了 ResNet-50 的 76.2% 准确率，同时在 26 个迁移学习基准测试中的 20 个上超越了最佳公开 ImageNet 模型。更重要的是，在传统模型崩溃的压力测试中，CLIP 保持了强大的性能。在 ImageNet Sketch 上，CLIP 达到了 60.2% 的准确率，而 ResNet 只有 25.2%。在对抗性示例上，CLIP 得分为 77.1%，而 ResNet 为 2.7%。\n\nSource: OpenAI Research Blog\n\n然而，该模型在某些方面仍然存在困难，例如：\n\n*   需要精确空间推理或计数的任务。它在非常细粒度的区分上也存在困难，例如区分相似的汽车型号或飞机变体，其中微妙的细节至关重要。\n*   在 MNIST 数据集上的手写数字测试中（在计算机视觉中被认为是微不足道的任务），CLIP 仅达到了 88% 的准确率，远低于人类 99.75% 的表现。\n*   CLIP 对你文本提示的措辞敏感。有时需要反复试验（“提示工程”，prompt engineering）才能找到效果好的措辞。\n*   CLIP 继承了其互联网训练数据中的偏差。我们措辞类别的方式可能会以有问题的方式极大地影响模型行为。\n\n然而，尽管存在这些局限性，CLIP 证明了驱动近期自然语言处理突破的方法（从海量互联网文本中学习）可以迁移到计算机视觉领域。正如 GPT 模型通过在互联网文本上训练来执行各种语言任务一样，CLIP 通过在互联网图像-文本对上训练来学习各种视觉任务。\n\n自发布以来，CLIP 已成为整个 AI 行业的基础设施。它是完全开源的，促进了广泛的应用。像 Stable Diffusion 和 DALL-E 这样的现代文本到图像系统使用 CLIP 类似的模型来理解文本提示。公司将其用于图像搜索、内容审核和推荐。\n\n## References:\n*   CLIP: Connecting Text and Images\n*   What is ImageNet\n\n---\n\n## 要点总结\n\n*   **零样本图像识别**：CLIP 通过学习图像与自然语言描述之间的关联，实现了无需专门训练即可对新类别进行图像识别的能力（Zero-Shot Image Recognition）。\n*   **对比语言-图像预训练（CLIP）**：模型的核心在于使用对比学习，将图像与其对应的文本描述进行匹配，而非传统的分类或生成图像标题。\n*   **大规模互联网数据**：CLIP 突破了传统计算机视觉模型对昂贵、耗时且狭窄的标注数据集的依赖，利用从互联网收集的 4 亿个图像-文本对进行训练，显著提高了泛化能力。\n*   **双编码器架构**：模型由独立的图像编码器（Image Encoder）和文本编码器（Text Encoder）组成，它们将图像和文本分别转换为相同维度空间中的嵌入向量。\n*   **对比损失函数**：训练目标是使匹配的图像-文本对的嵌入向量尽可能相似，而不匹配的对则尽可能不同。\n*   **学习机制**：通过反向传播和持续的权重更新，编码器逐渐学会将视觉概念和语言描述映射到同一语义空间。\n*   **Vision Transformers**：在图像编码器中采用 Transformer 架构（类似 GPT 和 BERT），提高了计算效率。\n*   **高效训练**：对比学习和 Vision Transformers 的结合，使得 CLIP 能以相对可控的计算资源（256 个 GPU 训练两周）实现高性能。\n*   **广泛应用**：CLIP 成为许多现代 AI 应用（如文生图模型 Stable Diffusion、DALL-E、图像搜索、内容审核）的基础。\n*   **局限性**：尽管能力强大，CLIP 在精确空间推理、细粒度区分、手写数字识别等任务上仍有不足，且存在对提示词措辞敏感和继承训练数据偏差的问题。\n\n## 你可以从这篇文章学到什么\n\n对于一个有几年经验的后端/系统设计工程师来说，这篇文章不仅介绍了 CLIP 这一开创性 AI 模型，更重要的是，它提供了关于大规模系统如何通过巧妙的设计选择解决复杂问题的深刻洞察。\n\n1.  **从数据到智能的范式转变**：文章展示了 AI 领域从“小数据、精标注”向“大数据、弱标注（或自监督）”训练范式转变的案例。在你的系统中，如果面临数据标注成本高昂或数据多样性不足的问题，可以思考如何利用现有非结构化或弱关联数据，通过自监督或对比学习的方式来训练模型，从而降低人工成本并提升模型鲁棒性。\n2.  **多模态数据融合的潜力**：CLIP 将图像和文本两种模态连接起来，创建了一个统一的语义空间。在系统设计中，如果你需要处理多种类型的数据（例如日志、用户行为、图像、视频），可以借鉴这种思路，设计统一的嵌入空间来表示不同模态的信息，从而实现更深层次的关联分析、推荐或搜索功能。\n3.  **效率与效果的权衡和创新**：OpenAI 团队选择对比学习而非图像标题生成，以及采用 Vision Transformers，都是为了在保证零样本性能的同时，大幅提高训练效率。这提醒我们在设计复杂系统时，要时刻考虑计算资源、延迟和用户体验的权衡，并通过技术创新（如选择更高效的算法、架构或分布式策略）来优化系统性能。\n4.  **大规模预训练模型的价值**：CLIP 作为一个在海量数据上预训练的模型，能够通过简单的提示词适应多种下游任务，体现了通用模型作为“基础设施”的巨大价值。在构建你的系统时，可以考虑是否能利用或集成这类大型预训练模型（无论是现成的还是自研的），将其作为核心组件，以加速开发、降低维护成本并提升功能边界。例如，你可以用 CLIP 来增强你系统的图像搜索能力、内容标签自动化或跨模态推荐。\n5.  **理解模型局限性和偏差的重要性**：文章清晰地指出了 CLIP 的局限性，如对空间推理、细粒度区分的不足，以及继承训练数据偏差的问题。这对于任何将 AI 模型集成到生产系统中的工程师都至关重要。你需要深入了解所用模型的优缺点，在系统设计时考虑如何规避或减轻这些限制，例如通过额外的规则引擎、人工审核或专门的后处理模块来弥补模型不足，确保系统的健壮性和公平性。\n6.  **架构选择对性能的影响**：对比学习和 Transformer 架构的选择，直接提升了 CLIP 的训练效率和泛化能力。对于后端工程师而言，这意味着在设计微服务架构、数据管道或选择数据库时，对底层技术（如消息队列、缓存、RPC 框架、数据存储类型）的选择同样至关重要，它们会深刻影响系统的可伸缩性、性能和成本。理解每种技术背后的设计哲学和权衡，能够帮助你做出更明智的决策。",
    "url": "https://blog.bytebytego.com/p/openai-clip-the-model-that-learnt"
  },
  {
    "id": "2025-12-30-openai-clip-the-model-that-learnt-zero-shot-image-recognition-using-text",
    "title": "OpenAI CLIP: The Model That Learnt Zero-Shot Image Recognition Using Text",
    "date": "2025-12-30",
    "preview": "# OpenAI CLIP：通过文本学习零样本图像识别的模型  想象一下，教计算机识别物体，不是通过向它展示数百万张带标签的照片，而是让它浏览互联网，从人们自然描述图像的方式中学习。这正是 OpenAI 的 CLIP 所做的工作，它代表了我们教机器理解视觉内容的根本性转变。  C...",
    "content": "# OpenAI CLIP：通过文本学习零样本图像识别的模型\n\n想象一下，教计算机识别物体，不是通过向它展示数百万张带标签的照片，而是让它浏览互联网，从人们自然描述图像的方式中学习。这正是 OpenAI 的 CLIP 所做的工作，它代表了我们教机器理解视觉内容的根本性转变。\n\nCLIP（Contrastive Language-Image Pre-training，对比语言-图像预训练）是一个连接视觉和语言的神经网络。它于 2021 年 1 月发布，能够将图像分类到你想要的任何类别中，而无需为此任务进行专门训练。你只需用通俗易懂的语言告诉它你在寻找什么，它就能识别出来。这种“零样本”（zero-shot）能力使 CLIP 不同于之前几乎所有的计算机视觉系统。\n\n在本文中，我们将探讨 CLIP 的工作原理以及它试图解决的问题。\n\n## CLIP 解决的问题\n\n传统的计算机视觉遵循僵化的模式。如果你想让模型区分猫和狗，你需要数千张带标签的照片。对于不同的汽车型号，你需要另一个昂贵的数据集。举例来说，ImageNet 是最著名的图像数据集之一，它需要超过 25,000 名工人标记 1400 万张图像。\n\n这种方法带来了三个主要问题：\n\n首先，数据集的构建成本高昂且耗时。\n\n其次，模型变成了狭隘的“专家”。一个 ImageNet 模型可以识别 1,000 个类别，但要使其适应新任务，需要收集更多数据并重新训练。\n\n第三，模型可能通过优化特定基准来“作弊”。\n\n例如，一个在 ImageNet 上达到 76% 准确率的模型，在同一物体的草图上可能下降到 37%，或者在略微修改的图像上骤降到 2.7%。模型学到的是 ImageNet 的怪癖，而不是真正理解视觉概念。\n\nCLIP 的方法则截然不同。它不是在精心标记的数据集上进行训练，而是从互联网上收集的 4 亿个图像-文本对中学习。这些图像-文本对在网上随处可见：带有描述的 Instagram 照片、配有图像的新闻文章、带有描述的产品列表以及配有图片的维基百科条目。人们自然会编写描述、解释或评论图像的文本，这创造了一个巨大的训练数据来源。\n\n然而，CLIP 并不试图预测特定的类别标签。相反，它学习将图像与其对应的文本描述进行匹配。在训练过程中，CLIP 会看到一张图像和一大批文本片段（一次 32,768 个）。它的任务是确定哪个文本片段与图像最匹配。\n\n可以把它想象成一个巨大的配对游戏。例如，我们向系统展示一张金毛犬在公园里玩耍的照片。在 32,768 个文本选项中，只有一个是正确的：也许是“一只金毛犬在公园里玩耍”。其他 32,767 个选项可能包括“一只黑猫在睡觉”、“日落时分的山景”、“一个人在吃披萨”以及数千种其他描述。为了在数百万个这样的例子中始终选择正确的匹配项，CLIP 必须了解物体、场景、动作和属性的外观以及它们如何与语言对应。\n\n通过一遍又一遍地解决这个匹配任务，利用极其多样化的互联网数据，CLIP 发展出对视觉概念及其语言描述的深刻理解。例如，它可能学到毛茸茸、四条腿、摇着尾巴的动物对应着“狗”和“小狗”等词。它可能学到水面上橙色和粉红色的天空与“日落”和“海滩”相关。换句话说，它建立了一个连接视觉世界和语言世界的丰富心智模型。\n\n## 技术基础\n\nCLIP 在底层使用了两个独立的神经网络协同工作：一个图像编码器（image encoder）和一个文本编码器（text encoder）。\n\n图像编码器将原始像素转换为数值向量（称为嵌入，embedding）。文本编码器将单词和句子也输出为向量。关键的洞察是，两个编码器都在相同的维度空间中输出向量，使得它们可以直接比较。\n\n最初，这些编码器可能会产生完全随机、毫无意义的向量。例如，一张狗的图像可能变成 [0.2, -0.7, 0.3, ...]，而文本“狗”可能变成 [-0.5, 0.1, 0.9, ...]。这些数字之间没有任何关系。但这就是训练发挥魔力的地方。\n\n训练过程使用了所谓的对比损失函数（contrastive loss function）。这只是一种衡量模型当前错误程度的数学方法。对于正确的图像-文本对（比如狗的图像配上“狗在玩耍”），损失函数会说这些嵌入应该非常相似。对于不正确的对（比如狗的图像配上“猫在睡觉”），它会说它们应该非常不同。损失函数会产生一个单一的数字，代表一批所有图像和文本的总误差。\n\n请看下面的图：\nSource: OpenAI Research Blog\n![CLIP contrastive learning diagram](https://openaicom.files.wordpress.com/2021/02/clip_blog_image_2.gif?w=1024)\n\n然后是反向传播（backpropagation），这是神经网络中的基本学习机制。它精确计算出两个编码器中的每个权重应该如何变化以减少这个误差。权重会略微更新，这个过程会用不同的数据批次重复数百万次。逐渐地，两个编码器都学会为匹配的概念生成相似的向量。例如，狗的图像开始产生接近文本编码器放置“狗”这个词的位置的向量。\n\n换句话说，通过在数百万个多样化示例中持续承受匹配正确对和分离不正确对的压力，编码器不断演进，学会了“说”相同的语言。\n\n## 零样本分类实战\n\n一旦 CLIP 训练完成，其零样本能力就显而易见了。假设我们想将图像分类为包含狗或猫。我们不需要重新训练 CLIP 或向其展示带标签的示例。\n\n相反，我们可以简单地将图像通过图像编码器（image encoder）获得一个嵌入（embedding）。接下来，我们可以将文本“一张狗的照片”通过文本编码器（text encoder）获得另一个嵌入。进一步地，我们可以将文本“一张猫的照片”获得第三个嵌入。比较哪个文本嵌入与图像嵌入更接近，这就是答案。\n\n请看下面的图：\nSource: OpenAI Research Blog\n![CLIP zero-shot classification diagram](https://openaicom.files.wordpress.com/2021/02/clip_blog_image_3.gif?w=1024)\n\nCLIP 本质上是在问：“根据从互联网上学到的一切，这张图片更有可能与关于狗的文本出现，还是与关于猫的文本出现？”\n\n由于它从如此多样化的数据中学习，这种方法适用于您可以用语言描述的几乎任何分类任务。\n\n想对食物类型进行分类？使用“一张披萨的照片”、“一张寿司的照片”、“一张玉米饼的照片”作为您的类别。需要分析卫星图像？尝试“一张森林的卫星照片”、“一张城市的卫星照片”、“一张农田的卫星照片”。处理医学图像？您可以使用“一张显示肺炎的 X 射线”与“一张健康肺部的 X 射线”。您只需更改文本描述。无需重新训练。\n\n这种灵活性是革命性的。传统模型需要为每个新任务准备大量的带标签数据集。CLIP 可以立即处理新任务，其唯一限制是您用自然语言描述类别的能力。\n\n## 使 CLIP 成为可能的设计选择\n\nCLIP 的成功不仅仅是核心思想。OpenAI 做出了两个关键的技术决策，使得训练在计算上变得可行。\n\n首先，他们选择了对比学习（contrastive learning），而不是更明显的训练模型生成图像描述的方法。早期的实验尝试教系统通过逐词生成完整的文本描述来理解图像，类似于语言模型生成文本的方式。虽然直观，但这种方法被证明极其缓慢且计算成本高昂。生成完整的句子比简单地学习匹配图像和文本需要更多的计算。对比学习在实现良好的零样本性能方面，效率是其 4 到 10 倍。\n\n其次，他们为图像编码器采用了 Vision Transformers（视觉 Transformer）。Transformer 架构是 GPT 和 BERT 背后的技术，已经彻底改变了自然语言处理。将其应用于图像（将图像块视为句子中的单词）比传统卷积神经网络（如 ResNet）又提供了 3 倍的计算效率提升。\n\nSource: OpenAI Research Blog\n![CLIP architecture detail](https://openaicom.files.wordpress.com/2021/02/clip_blog_image_6.gif?w=1024)\n\n综合来看，这些选择意味着 CLIP 可以在 256 个 GPU 上训练两周，与当时其他大规模视觉模型所需的计算量相似，而无需天文数字般的额外计算。\n\n## 结论\n\nOpenAI 在 30 多个不同数据集上测试了 CLIP，涵盖了各种任务：细粒度分类、光学字符识别、动作识别、地理定位和卫星图像分析。\n\n结果验证了 CLIP 的方法。虽然在标准 ImageNet 上与 ResNet-50 的 76.2% 准确率持平，但 CLIP 在 26 个迁移学习（transfer learning）基准中的 20 个上都超越了当时公开可用的最佳 ImageNet 模型。更重要的是，CLIP 在传统模型崩溃的压力测试中保持了强大的性能。在 ImageNet Sketch 上，CLIP 达到了 60.2%，而 ResNet 为 25.2%。在对抗性示例上，CLIP 得分为 77.1%，而 ResNet 为 2.7%。\n\nSource: OpenAI Research Blog\n![CLIP performance comparison](https://openaicom.files.wordpress.com/2021/02/clip_blog_image_8.gif?w=1024)\n\n然而，该模型仍然存在一些不足，例如：\n\n*   需要精确空间推理或计数的任务。它在非常细微的区分上也存在困难，比如区分相似的汽车型号或飞机变体，这些任务需要关注微妙的细节。\n*   在 MNIST 手写数字数据集上进行测试时（这在计算机视觉中被认为是微不足道的任务），CLIP 仅达到 88% 的准确率，远低于人类 99.75% 的表现。\n*   CLIP 对您文本提示的措辞方式很敏感。有时需要反复试验（“提示工程”，prompt engineering）才能找到效果良好的措辞。\n*   CLIP 继承了其互联网训练数据中的偏见。我们对类别进行措辞的方式可能会以有问题的方式极大地影响模型行为。\n\n然而，尽管存在局限性，CLIP 证明了推动自然语言处理近期突破的方法（从大量互联网文本中学习）可以迁移到计算机视觉领域。正如 GPT 模型通过训练互联网文本学习执行各种语言任务一样，CLIP 通过训练互联网图像-文本对学习执行各种视觉任务。\n\n自发布以来，CLIP 已成为整个 AI 行业的基础设施。它是完全开源的，促进了广泛的采用。现代文本到图像系统，如 Stable Diffusion 和 DALL-E，都使用 CLIP 类似的模型来理解文本提示。公司将其用于图像搜索、内容审核和推荐。\n\n## 参考文献:\n\n*   CLIP: Connecting Text and Images\n*   What is ImageNet\n\n---\n\n## 要点总结\n\n*   **痛点与革新**：传统计算机视觉模型依赖昂贵且耗时的大规模标注数据集，且模型专一性强、容易过拟合基准。CLIP 通过学习互联网上的海量“图像-文本对”解决了这些问题，实现了零样本（zero-shot）图像识别。\n*   **零样本能力**：CLIP 可以在未见过特定分类任务的情况下，仅通过文本描述就能对图像进行分类，极大地提升了模型的泛化性和灵活性。\n*   **对比学习核心**：CLIP 的训练核心是对比学习（contrastive learning）。它不直接预测标签，而是学习将图像嵌入（image embedding）与其对应的文本嵌入（text embedding）在同一向量空间中拉近，将不匹配的拉远。\n*   **双编码器架构**：CLIP 包含一个图像编码器和一个文本编码器，它们分别将图像和文本转换为高维向量。训练目标是使匹配的图像和文本在嵌入空间中彼此靠近。\n*   **Transformers 架构**：图像编码器采用了 Vision Transformers，将 Transformer 架构从自然语言处理扩展到图像领域，提高了计算效率。\n*   **计算效率**：相比于直接生成图像描述，对比学习效率高出 4-10 倍；Vision Transformers 相比传统 CNN 又提高了 3 倍效率，使得 CLIP 的大规模训练变得可行。\n*   **广泛适用性**：CLIP 的零样本能力使其适用于各种场景，从通用物体识别到卫星图像分析、医疗影像等，只需提供恰当的文本描述即可。\n*   **鲁棒性提升**：CLIP 在应对 ImageNet Sketch 和对抗性示例等压力测试时，表现出比传统模型更强的鲁棒性。\n*   **局限性**：CLIP 在精细的空间推理、计数、区分细微差异（如相似车模）以及 MNIST 等简单任务上仍有不足，且对文本提示（prompt engineering）敏感，并可能继承训练数据的偏见。\n*   **行业影响**：CLIP 模型是开源的，已成为 AI 行业的基础设施，被广泛应用于文本到图像生成（如 Stable Diffusion）、图像搜索、内容审核和推荐等领域。\n\n---\n\n## 你可以从这篇文章学到什么\n\n作为一名有几年经验的后端/系统设计工程师，这篇文章为我们提供了一些关于深度学习模型设计和大规模数据利用的深刻见解，这些思想可以启发我们在设计复杂系统时解决通用性和效率问题：\n\n1.  **大规模非结构化数据利用**：CLIP 证明了互联网上看似“无序”的“图像-文本对”能够成为强大模型的训练数据。这提示我们，在系统设计中，对于用户生成内容（UGC）或通过爬虫获取的大量非结构化数据，不一定需要进行昂贵的精细标注，而是可以探索通过弱监督或自监督的方式，从中挖掘出巨大的价值。例如，在构建内容推荐系统或内部知识库时，可以考虑利用标题、描述、标签等元数据与内容本身的关联性进行模型预训练。\n\n2.  **通用性与泛化能力**：CLIP 的零样本能力是其最大的亮点。它通过学习“视觉-语言”的通用对应关系，使得模型无需针对特定任务重新训练。对于系统设计而言，这意味着我们应该思考如何构建更具通用性的服务或组件，而不是为每个特定需求都从头开始。例如，在构建微服务时，一个通用的内容理解服务（基于 CLIP 思想）可以替代多个针对特定类别训练的分类服务，从而降低维护成本和开发周期。\n\n3.  **编码器（Encoder）模式的威力**：文章中强调了图像编码器和文本编码器将不同模态的数据映射到同一个嵌入空间。这种“多模态嵌入”（multimodal embedding）的思想在许多现代系统中都非常有用。例如，在搜索系统中，可以将不同类型的数据（如商品描述、用户评论、图片特征）编码成统一的向量，从而实现跨模态的检索或推荐。用户输入的查询文本可以直接与图片或商品描述的向量进行距离比较，实现更智能的搜索。\n\n4.  **对比学习（Contrastive Learning）的适用性**：对比学习作为一种强大的自监督学习范式，不仅限于 CLIP。当我们在系统中存在大量未标记数据，但可以轻松构建“正例对”（相似或匹配的数据）和“负例对”（不相似的数据）时，对比学习是一种非常有效的特征学习方法。这可以应用于用户行为模式识别（例如，用户 A 购买了商品 X，用户 B 浏览了商品 X，这可能是一个正例对）、日志异常检测或分布式跟踪中的相似性分析等场景。\n\n5.  **工程效率的考量**：CLIP 的成功得益于选择对比学习和 Vision Transformers 带来的计算效率提升。这提醒系统工程师，在选择算法和架构时，不仅要考虑模型效果，更要重视训练和推理的效率。在资源有限或需要快速迭代的场景下，一个效率更高但效果略差的模型，可能比一个效果顶尖但资源消耗巨大的模型更具实际价值。性能与成本的权衡始终是系统设计中的重要一环。\n\n6.  **模型局限性和“提示工程”**：CLIP 即使如此强大，仍有其局限性，例如对“提示词”（prompt）敏感，并可能存在偏见。这告诉我们在将 AI 模型集成到系统中时，不能盲目相信其完美性，需要设计健壮的错误处理、结果校验机制，并可能需要引入“提示工程”的概念，让非技术人员也能通过优化输入来提升系统表现。同时，对于 AI 模型的偏见问题，系统设计时需考虑数据来源、模型公平性评估和结果校正机制。",
    "url": "https://blog.bytebytego.com/p/openai-clip-the-model-that-learnt"
  },
  {
    "id": "2025-12-29-ep195-common-network-protocols-every-engineer-should-know",
    "title": "EP195: Common Network Protocols Every Engineer Should Know",
    "date": "2025-12-29",
    "preview": "## EP195: 每个工程师都应该了解的常见网络协议  ByteByteGo 2025年12月27日  本周系统设计回顾： 每个工程师都应该了解的常见网络协议  你是否曾好奇，当你点击电子邮件的“发送”按钮或加入视频通话时，究竟发生了什么？互联网上的每一次点击、每一条消息、每一...",
    "content": "## EP195: 每个工程师都应该了解的常见网络协议\n\nByteByteGo\n2025年12月27日\n\n本周系统设计回顾：\n每个工程师都应该了解的常见网络协议\n\n你是否曾好奇，当你点击电子邮件的“发送”按钮或加入视频通话时，究竟发生了什么？互联网上的每一次点击、每一条消息、每一次 API 调用都依赖于网络协议。它们定义了数据如何传输、谁可以进行通信以及通信的安全性如何。\n\n基础层是传输协议：TCP 确保可靠交付，UDP 优先考虑速度，而 QUIC 则通过 UDP 将两者结合起来。\n在此之上，HTTP 驱动着网络，TLS 确保其安全，而 DNS 将名称转换为地址。\n需要远程访问？那是 SSH。文件传输？SFTP 或 SMB。\n实时聊天和媒体？WebSocket、WebRTC 和 MQTT 保持数据实时流动。\n对于身份和访问管理，OAuth 和 OpenID 处理授权和身份验证。\n在后端，DHCP、NTP、ICMPv6 和 LDAP 默默地保持着一切同步、寻址和可发现。\n从简单的电子邮件 (SMTP, IMAP) 到加密的 VPN (WireGuard, IPsec)，这些协议构成了连接和保护互联网的无形语言。\n\n轮到你了：如果某个协议在全球范围内突然停止工作，哪一个会首先使互联网瘫痪？\n\n### 8 种常见的网络协议\n\n网络协议是网络中两个系统之间数据传输的关键。\n\n**FTP (File Transfer Protocol)**\n使用独立的控制和数据通道在客户端和服务器之间上传和下载文件。\n\n**TCP (Transmission Control Protocol)**\n通过三次握手 (SYN, SYN+ACK, ACK) 建立可靠连接，以实现准确的数据传输。\n\n**UDP (User Datagram Protocol)**\n发送轻量级、无连接的数据包（请求和响应），延迟最小。是快速传输的理想选择。\n\n**HTTP (HyperText Transfer Protocol)**\n使用 TCP 通过 HTTP 请求和响应来请求和接收 Web 资源（HTML、图片）。\n\n**HTTP/3 (QUIC)**\n构建在 UDP 之上，通过多路复用数据流和降低延迟，实现更快、更可靠的连接。\n\n**HTTPS (Secure HTTP)**\n通过使用公共密钥和会话密钥在 TCP 连接上进行加密来保护 HTTP，从而保护 Web 数据。\n\n**SMTP (Simple Mail Transfer Protocol)**\n通过 SMTP 服务器将电子邮件从发件人传输到收件人。常用于电子邮件投递。\n\n**WebSocket**\n将 HTTP 连接升级为全双工通道，用于实时、双向通信，例如实时聊天。\n\n### 一图胜千言：微服务开发的 9 大最佳实践\n\n在开发微服务时，我们需要遵循以下最佳实践：\n\n1.  为每个微服务使用独立的数据存储\n2.  保持代码成熟度水平相似\n3.  为每个微服务单独构建\n4.  为每个微服务分配单一职责\n5.  部署到容器中\n6.  设计无状态服务\n7.  采用领域驱动设计 (Domain-Driven Design)\n8.  设计微前端 (Micro Frontend)\n9.  编排微服务 (Orchestrating microservices)\n\n---\n\n### 要点总结\n\n*   网络协议是互联网运行的基础，定义了数据传输、通信安全等核心机制。\n*   传输层协议包括 TCP（可靠传输）、UDP（高速无连接）和 QUIC（兼顾速度和可靠性，基于 UDP）。\n*   应用层协议涵盖了 Web (HTTP/HTTPS)、远程访问 (SSH)、文件传输 (SFTP/SMB)、实时通信 (WebSocket/WebRTC/MQTT)、身份验证 (OAuth/OpenID)、邮件 (SMTP/IMAP) 等多种场景。\n*   DNS 负责域名解析，TLS 负责网络安全，DHCP、NTP、ICMPv6、LDAP 等则在后端提供基础设施服务。\n*   文章详细介绍了 8 种常见协议，包括 FTP、TCP、UDP、HTTP、HTTP/3 (QUIC)、HTTPS、SMTP 和 WebSocket 的基本功能。\n*   微服务开发应遵循 9 大最佳实践，包括独立数据存储、单一职责、容器化部署、无状态服务设计、领域驱动设计、微前端和有效的微服务编排。\n\n### 你可以从这篇文章学到什么\n\n对于一个有几年经验的后端/系统设计工程师来说，这篇文章提供了一个全面且精炼的网络协议知识回顾，以及微服务设计的实用指导。\n\n1.  **协议体系的宏观理解**：文章帮助工程师巩固对网络协议分层和各自作用的理解，从传输层到应用层，涵盖了日常工作中常用的协议，例如 TCP/UDP/QUIC、HTTP/HTTPS、SSH、WebSocket、OAuth 等。这有助于在系统设计时，选择最适合特定场景的通信协议，例如需要可靠性还是低延迟。\n2.  **核心协议的工作原理**：简明扼要地解释了 FTP、TCP 三次握手、UDP 的特点、HTTP/3 (QUIC) 的优势等，这些是面试和实际问题排查时的关键知识点。对这些基础的深入理解，能帮助工程师更好地诊断网络问题，优化系统性能。\n3.  **微服务设计原则的温故知新**：文章列出的 9 大微服务最佳实践是工程师在设计和实现微服务架构时应该时刻牢记的指导原则。例如，“为每个微服务使用独立的数据存储”、“分配单一职责”、“设计无状态服务”等，这些都是避免微服务陷阱，构建高内聚、低耦合、可扩展系统的关键。\n4.  **实际应用指导**：例如，在需要实时通信的场景（如聊天、协作工具），自然会想到使用 WebSocket；在需要可靠数据传输但对延迟敏感度不高时，会选择 TCP；而在对速度要求极高且少量数据丢失可接受时，UDP 更合适。而微服务的最佳实践则直接指导了如何将一个复杂系统拆分为可管理、可独立部署的服务，并确保它们之间的良好协作。\n\n总之，这篇文章不仅是知识的复习，更是系统设计决策和日常开发实践的有力参考，帮助工程师构建更健壮、高效和可维护的分布式系统。",
    "url": "https://blog.bytebytego.com/p/ep195-common-network-protocols-every"
  },
  {
    "id": "2025-12-28-ep195-common-network-protocols-every-engineer-should-know",
    "title": "EP195: Common Network Protocols Every Engineer Should Know",
    "date": "2025-12-28",
    "preview": "# 工程师应了解的常见网络协议  你是否曾好奇，当你点击邮件的“发送”按钮或加入视频通话时，究竟发生了什么？互联网上的每一次点击、每一条消息和每一次 API 调用都依赖于网络协议。它们定义了数据如何移动、谁可以通信以及这一切如何安全进行。  其基础是传输协议：TCP 确保可靠传输...",
    "content": "# 工程师应了解的常见网络协议\n\n你是否曾好奇，当你点击邮件的“发送”按钮或加入视频通话时，究竟发生了什么？互联网上的每一次点击、每一条消息和每一次 API 调用都依赖于网络协议。它们定义了数据如何移动、谁可以通信以及这一切如何安全进行。\n\n其基础是传输协议：TCP 确保可靠传输，UDP 优先考虑速度，而 QUIC 则通过 UDP 将两者结合。\n\n在此之上，HTTP 驱动着网络，TLS 确保其安全，而 DNS 则将域名解析为地址。\n\n需要远程访问？那是 SSH。文件传输？SFTP 或 SMB。\n\n实时聊天和媒体？WebSocket、WebRTC 和 MQTT 确保数据实时流动。\n\n对于身份和访问管理，OAuth 和 OpenID 处理授权和身份验证。\n\n在后端，DHCP、NTP、ICMPv6 和 LDAP 则默默地保持着一切同步、寻址和可发现。\n\n从简单的电子邮件 (SMTP, IMAP) 到加密的 VPN (WireGuard, IPsec)，这些协议构成了无形的语言，使互联网保持连接和安全。\n\n问问你自己：如果全球范围内的某个协议突然停止工作，哪一个会首先导致互联网崩溃？\n\n## 8 种常用网络协议\n\n网络协议是网络中两个系统之间传输数据的关键。\n\n**FTP (File Transfer Protocol)**\n使用单独的控制和数据通道在客户端和服务器之间上传和下载文件。\n\n**TCP (Transmission Control Protocol)**\n通过三次握手 (SYN, SYN+ACK, ACK) 建立可靠连接，以确保数据准确传输。\n\n**UDP (User Datagram Protocol)**\n发送轻量级、无连接的数据包（请求和响应），延迟极低。适用于快速传输。\n\n**HTTP (HyperText Transfer Protocol)**\n通过 HTTP 请求和响应，使用 TCP 来请求和接收网页资源 (HTML, 图像)。\n\n**HTTP/3 (QUIC)**\n构建在 UDP 之上，通过多路复用数据流和减少延迟，实现更快、更可靠的连接。\n\n**HTTPS (Secure HTTP)**\n通过基于 TCP 连接使用公共密钥和会话密钥进行加密，来保护 HTTP，从而保护网络数据。\n\n**SMTP (Simple Mail Transfer Protocol)**\n通过 SMTP 服务器将电子邮件从发送方传输到接收方。它通常用于邮件投递。\n\n**WebSocket**\n将 HTTP 连接升级为全双工通道，用于实时、双向通信，例如实时聊天。\n\n---\n\n## 要点总结\n\n*   网络协议是互联网运行的基础，定义了数据传输、通信和安全性。\n*   传输层协议如 TCP 提供可靠传输，UDP 追求速度，QUIC 则试图结合两者的优点。\n*   应用层协议涵盖了广泛的功能，包括网页访问 (HTTP/HTTPS)、安全 (TLS)、域名解析 (DNS)、远程访问 (SSH) 和文件传输 (SFTP/SMB)。\n*   实时通信协议如 WebSocket、WebRTC 和 MQTT 支持即时数据流和双向通信。\n*   身份验证和授权协议如 OAuth 和 OpenID 是现代系统访问控制的关键。\n*   后端服务依赖 DHCP、NTP、ICMPv6、LDAP 等协议进行网络配置、时间同步和目录服务。\n*   理解这些协议对于构建、维护和调试复杂的分布式系统至关重要。\n*   文章列举并简要介绍了 FTP、TCP、UDP、HTTP、HTTP/3 (QUIC)、HTTPS、SMTP 和 WebSocket 这 8 种常用协议的功能和特点。\n\n---\n\n## 你可以从这篇文章学到什么\n\n对于一个有几年经验的后端/系统设计工程师来说，这篇文章提供了一个简洁而全面的网络协议回顾，这对于巩固基础知识、提升系统设计能力非常有价值。\n\n1.  **系统性知识回顾与补充：** 即使是经验丰富的工程师，也可能对某些协议的底层机制或最新发展（如 HTTP/3 的 QUIC）了解不深。这篇文章能帮助你快速梳理不同层级的核心协议及其主要功能和应用场景，填补知识盲区。\n2.  **选择合适协议的决策依据：** 文章清晰地对比了 TCP 的可靠性和 UDP 的速度，以及 QUIC 如何结合两者。在设计系统时，你需要根据业务需求（如数据一致性、实时性、传输效率）来选择最合适的传输协议。例如，视频流倾向于 UDP 或 QUIC 以减少延迟，而数据库事务则必须依赖 TCP 的可靠性。\n3.  **理解系统性能瓶颈：** 熟悉各种协议的特点能帮助你分析和优化系统性能。例如，理解 HTTP/3 (QUIC) 如何通过多路复用和减少握手来降低延迟，可以指导你在高并发、低延迟要求的服务中考虑采用新协议。\n4.  **安全性和可观测性考量：** 文章提到了 TLS 对 HTTP 的加密以及 VPN 协议 (WireGuard, IPsec) 的作用。在设计系统时，你需要考虑数据在传输过程中的安全性，并选择合适的协议（如 HTTPS 而非 HTTP）和安全机制。此外，理解协议的工作原理也有助于更好地监控和调试网络问题。\n5.  **构建分布式系统的基石：** 无论是微服务间的 API 调用、消息队列的通信、文件上传下载、实时通知还是身份认证，都离不开这些基础协议。深入理解它们能让你在设计复杂的分布式系统架构时，更自信地选择和集成不同的组件，并预见到潜在的网络问题。\n6.  **面试准备：** 文章涵盖了系统设计面试中常见的基础网络协议知识点，是很好的复习材料。理解这些协议的应用场景和优缺点，能让你在面对相关问题时游刃有余。",
    "url": "https://blog.bytebytego.com/p/ep195-common-network-protocols-every"
  },
  {
    "id": "2025-12-27-learn-ai-in-the-new-year-become-an-ai-engineer-cohort-3-now-open",
    "title": "🚀 Learn AI in the New Year: Become an AI Engineer Cohort 3 Now Open",
    "date": "2025-12-27",
    "preview": "在第1期和第2期（近1000名工程师加入并掌握了真实的AI技能）取得巨大成功之后，我们很高兴地宣布“成为AI工程师”第3期现已启动！  这不仅仅是另一个关于AI框架和工具的课程。我们的目标是帮助工程师建立基础和端到端的技能集，以便他们能够作为AI工程师蓬勃发展。  以下是本期项目...",
    "content": "在第1期和第2期（近1000名工程师加入并掌握了真实的AI技能）取得巨大成功之后，我们很高兴地宣布“成为AI工程师”第3期现已启动！\n\n这不仅仅是另一个关于AI框架和工具的课程。我们的目标是帮助工程师建立基础和端到端的技能集，以便他们能够作为AI工程师蓬勃发展。\n\n以下是本期项目的特别之处：\n*   通过实践学习：构建真实世界的AI应用，而不仅仅是观看视频。\n*   结构化、系统化的学习路径：遵循精心设计的课程，带领你一步步从基础知识走向高级主题。\n*   实时反馈和指导：从讲师和同行那里获得直接反馈。\n*   社区驱动：独自学习很困难。与社区一起学习则很容易！\n\n我们专注于技能培养，而不仅仅是理论或被动学习。我们的目标是让每位参与者都能掌握构建AI系统的坚实基础。\n\n如果你想从零开始学习AI，现在是最佳时机。\n\n### 要点总结\n\n*   课程强调实践学习，鼓励学员通过构建真实世界的AI应用来掌握技能。\n*   提供结构化、系统化的学习路径，确保从基础到高级主题的循序渐进。\n*   包含实时反馈和专家指导，帮助学员及时修正方向并深入理解。\n*   倡导社区驱动的学习模式，促进学员间的交流、协作与共同进步。\n*   旨在帮助工程师建立全面的端到端AI技能集，以适应AI工程师的角色需求。\n*   目标是为学员打下构建AI系统的坚实基础，而非仅限于理论知识。\n\n### 你可以从这篇文章学到什么\n\n对于有几年经验的后端/系统设计工程师来说，这篇文章虽然直接宣传AI课程，但其中所阐述的学习方法论和对技能培养的理念，对系统设计和后端开发工作同样具有深刻的借鉴意义：\n\n1.  **重视实践与项目驱动**：文章强调“通过实践学习，构建真实世界的AI应用”。这对于系统设计工程师而言，意味着不仅要掌握理论知识和设计模式，更要通过实际项目、代码实现和系统部署来验证和深化理解。纸上谈兵的架构很难经受住真实世界的考验。\n2.  **结构化与系统化思维**：课程采用“结构化、系统化的学习路径，从基础到高级主题”逐步深入。这与优秀的系统设计实践异曲同工。设计复杂系统时，工程师必须从核心功能、数据流等基础出发，逐步考虑可扩展性、可靠性、安全性等高级特性，而非一开始就追求所有最优解。\n3.  **持续的反馈与迭代**：文中提到的“实时反馈和指导”在系统设计中表现为设计评审（Design Review）、代码评审（Code Review）以及上线后的监控与复盘。通过及时获取同事、领导或生产环境的反馈，我们可以不断迭代和优化系统设计，及早发现并解决潜在问题，降低风险。\n4.  **社区与协作的力量**：文章指出“独自学习很困难，与社区一起学习则很容易”。在系统设计中，这意味着团队协作、知识共享和跨职能沟通至关重要。一个开放、协作的团队文化能够汇集多方智慧，共同解决复杂的系统难题，比单打独斗更有效率和质量。\n5.  **构建端到端（End-to-End）能力**：AI工程师需要端到端的技能集。对于后端/系统设计工程师而言，这意味着不仅要专注于某个模块或服务的设计，还要理解整个系统的生命周期，包括前端交互、数据存储、API设计、部署运维、性能监控等，从而设计出更健壮、更易于维护的整体解决方案。\n6.  **打好坚实的基础**：无论学习AI还是进行系统设计，打好坚实的基础都是关键。深入理解计算机科学原理、数据结构、算法、网络协议、操作系统等，能让工程师在面对各种技术挑战时游刃有余，设计出更加高效和可靠的系统，这在应对未来技术演进中也至关重要。",
    "url": "https://blog.bytebytego.com/p/learn-ai-in-the-new-year-become-an"
  },
  {
    "id": "2025-12-26-how-shopify-prepares-for-black-friday",
    "title": "How Shopify Prepares for Black Friday",
    "date": "2025-12-26",
    "preview": "Shopify 如何为黑色星期五做准备  黑色星期五网购星期一（BFCM）2024 对 Shopify 来说是巨大的一年。该平台处理了 57.3 PB (petabytes) 的数据，处理了 10.5 万亿次数据库查询，其边缘网络峰值达到每分钟 2.84 亿次请求。仅在应用服务器...",
    "content": "Shopify 如何为黑色星期五做准备\n\n黑色星期五网购星期一（BFCM）2024 对 Shopify 来说是巨大的一年。该平台处理了 57.3 PB (petabytes) 的数据，处理了 10.5 万亿次数据库查询，其边缘网络峰值达到每分钟 2.84 亿次请求。仅在应用服务器上，他们在黑色星期五每分钟处理 8000 万次请求，同时每分钟推送 12 TB (terabytes) 的数据。\n\n有趣的是：这种流量水平现在已成为 Shopify 的基线。而 BFCM 2025 的规模甚至更大，处理了 90 PB 的数据，处理了 1.75 万亿次数据库写入，峰值性能达到每分钟 4.89 亿次请求。这就是为什么 Shopify 从零开始重建其整个 BFCM 准备计划的原因。\n\n这项准备工作涉及数千名工程师九个月的工作，运行了五次大规模的扩展测试。\n\n在本文中，我们将探讨 Shopify 如何为这场商业界的“超级碗”做好准备。\n\n### 三轨框架 (The Three-Track Framework)\n\nShopify 的 BFCM 准备工作从三月份开始，采用了基于 Google Cloud 的多区域策略。\n\n工程团队将工作组织成三个并行运行并相互影响的轨道：\n\n*   **容量规划 (Capacity Planning)** 涉及使用历史数据和商家增长预测来建模流量模式。团队尽早将这些估算提交给其云提供商，以便提供商能够确保他们有足够的物理基础设施可用。这个规划定义了 Shopify 需要多少计算能力以及这些能力需要部署在哪个地理位置。\n*   **基础设施路线图 (Infrastructure Roadmap)** 是团队审查其技术栈、评估需要哪些架构变更以及识别达到目标容量所需的系统升级的地方。这个轨道有助于安排所有待办工作。重要的是，Shopify 从不将 BFCM 作为发布截止日期。所有架构变更和迁移都在关键窗口前几个月完成。\n*   **风险评估 (Risk Assessments)** 使用“可能出什么问题 (What Could Go Wrong)”练习来记录故障场景。团队设定升级优先级并生成他们称之为“游戏日 (Game Days)”的输入。这些信息帮助他们提前测试和强化系统。\n\n这三条轨道不断相互反馈。例如，风险发现可能揭示团队未考虑到的容量缺口。基础设施变更可能引入需要评估的新风险。换句话说，这是一个持续的反馈循环。\n\n### 游戏日 (Game Days)\n\n为了正确评估风险，Shopify 工程团队会运行“游戏日”。这些是混沌工程 (chaos engineering) 演练，故意在 BFCM 规模下模拟生产故障。\n\n团队在早春开始举办游戏日。这涉及故意向系统注入故障，以测试它们在故障条件下的响应方式。可以将其视为软件的消防演习。\n\n在这些游戏日中，工程团队特别关注他们称之为“关键路径 (critical journeys)”的部分。这些是其平台上最具业务关键性的路径：结账、支付处理、订单创建和履约。如果这些在 BFCM 期间中断，商家会立即损失销售额。\n\n关键路径游戏日运行跨系统灾难模拟。以下是团队测试的一些常见方面：\n\n*   团队测试搜索和页面端点，同时随机化导航以模拟真实用户行为。他们注入网络故障和延迟，以查看当服务无法快速通信时会发生什么。\n*   他们清除缓存，以创建真实的负载模式，而不是在所有内容都被缓存时获得的人工快速响应。\n*   前端团队在这些演练期间运行 bug 扫荡 (bug bashes)。他们识别回归 (regressions)、测试关键用户流，并验证用户体验在峰值负载下是否能保持稳定。\n\n这些演练通过暴露操作手册和监控工具中的不足，建立了事件响应的“肌肉记忆”。\n\n最重要的是，Shopify 在 BFCM 之前就弥补了这些不足，而不是在商家最需要平台时才发现它们。游戏日的所有发现都输入到 Shopify 所谓的“弹性矩阵 (Resiliency Matrix)”中。这是一个集中式文档，用于跟踪整个平台上的漏洞、事件响应程序和修复。\n\n弹性矩阵包含五个关键组件：\n\n1.  **服务状态 (service status)**，显示所有关键服务的当前运行状态。\n2.  **故障场景 (failure scenarios)**，记录系统如何可能崩溃以及影响是什么。\n3.  **恢复程序 (recovery procedures)**，列出预期的恢复时间目标 (RTO) 和详细的问题修复运行手册 (runbooks)。\n4.  **操作手册 (operational playbooks)**，包含逐步的事件响应指南。\n5.  **值班覆盖 (on-call coverage)**，显示团队排班和 PagerDuty 升级路径。\n\n该矩阵成为 BFCM 之前系统强化的路线图。团队全年持续更新它，记录弹性改进。\n\n### 使用 Genghis 和 Toxiproxy 进行负载测试\n\n游戏日测试组件的隔离性，但 Shopify 还需要知道整个平台是否能处理 BFCM 流量。这就是负载测试 (load testing) 的用武之地。\n\n工程团队构建了一个名为 Genghis 的工具，该工具运行模拟真实用户行为的脚本化工作流。它模拟浏览、将商品添加到购物车以及完成结账流程。该工具逐渐增加流量，直到出现问题，这有助于团队找到其实际容量限制。\n\n测试在生产基础设施上同时从三个 Google Cloud 区域运行：us-central、us-east 和 europe-west4。这准确模拟了全球流量模式。Genghis 还在基线负载之上注入闪购爆发，以测试峰值容量场景。\n\nShopify 将 Genghis 与 Toxiproxy 结合使用，这是一个他们为模拟网络条件而构建的开源框架。Toxiproxy 注入网络故障和分区，从而阻止服务相互通信。举例来说，网络分区是指系统中的两个部分失去通信能力，即使它们都仍在运行。\n\n在测试期间，团队实时监控仪表盘，并随时准备在系统开始降级时中止。多个团队协调合作，以发现和修复出现的瓶颈。\n\n当负载测试揭示限制时，团队有三个选择：\n\n*   **横向扩展 (Horizontal scaling)** 意味着增加更多的应用实例。\n*   **纵向扩展 (Vertical scaling)** 意味着为每个实例提供更多的资源，例如 CPU 和内存。\n*   **优化 (Optimizations)** 意味着进行架构层面的更改以提高性能，范围从更好的数据库查询到跨消费层直至前端的性能调优。\n\n这些决策设定了最终的 BFCM 容量，并推动了 Shopify 整个技术栈的优化工作。关键的洞察是，团队不能等到 BFCM 才发现容量限制。扩展基础设施和优化代码需要数月的准备。\n\n### 分析平台挑战 (The Analytics Platform Challenge)\n\nBFCM 测试了 Shopify 的每一个系统，但 2025 年提出了一个独特的挑战。他们的一部分基础设施从未经历过假日流量，这带来了一个问题：当没有历史数据可供建模时，如何为峰值负载做准备？\n\n2024 年，Shopify 的工程团队重建了其整个分析平台。他们创建了新的 ETL 管道 (ETL stands for Extract, Transform, Load，这是一个从各种来源提取数据、处理数据并将其存储到有用位置的过程)。他们还切换了持久层 (persistence layer)，并用全新的 API 替换了其遗留系统。\n\n这造成了不对称。ETL 管道运行了 BFCM 2024，因此团队有一整季的生产数据，显示这些管道在假日负载下的表现。但他们的 API 层在高峰季节结束后才推出。他们正在为 BFCM 准备从未经历过假日流量的 API。\n\n这非常重要，因为在 BFCM 期间，商家会痴迷于检查他们的分析数据。他们想要实时销售额、转化率、流量模式和流行产品的数据。每一个这样的查询都会命中 API 层。如果这些 API 无法处理负载，商家在最关键的销售期间就会失去可见性。\n\nShopify 专门为分析基础设施运行了游戏日。这些是受控实验，旨在揭示故障模式和瓶颈。团队模拟了增加的流量负载，引入了数据库延迟，并测试了缓存故障，以系统地绘制系统在压力下的行为。\n\n结果显示了四个需要修复的关键问题：\n\n1.  首先，ETL 管道需要增加 Kafka 分区 (Kafka partition increases)，以在流量高峰期间保持数据的新鲜度。Apache Kafka 是一个分布式流处理平台，处理实时数据流。更多的分区意味着更多的并行处理，从而使 API 能够提供最新数据。\n2.  其次，API 层内存使用需要优化。团队通过性能分析 (profiling) 发现这一点，这意味着精确测量代码如何使用内存。每个 API 请求都使用了过多的内存。在高负载下，这会导致内存不足错误、响应时间变慢或完全崩溃。\n3.  第三，连接超时 (connection timeouts) 需要调整，以防止连接池耗尽。连接池 (connection pool) 是一组可重用的数据库连接。创建新连接是昂贵的，因此应用程序会重用它们。问题是超时时间太长，这意味着连接会卡住等待。在高负载下，可用连接会耗尽，新的请求开始失败。Shopify 调整了超时时间，以更快地释放连接。\n4.  第四，团队通过不同的负载均衡器方法拆分 API 请求。最初，API 请求都会排队到单个区域，这增加了延迟和负载。通过扩展次要区域的集群并更新负载均衡策略，他们更好地分配了工作，并防止 API 服务器被淹没。\n\n除了性能修复之外，团队还验证了警报并记录了响应程序。他们的团队经过培训，为在实际事件中处理故障做好了准备。\n\n### 规模测试 (The Scale Tests)\n\n游戏日和负载测试准备单个组件，但规模测试 (scale testing) 不同。它验证整个平台在 BFCM 流量下协同工作，揭示只有当所有系统同时满负荷运行时才会出现的问题。\n\n从四月到十月，Shopify 以其预测的流量水平运行了五次大规模测试，特别是其峰值 p90 流量假设。在统计学中，p90 表示第 90 百分位，即 90% 的请求将低于的流量水平。\n\n以下是这些规模测试的详细信息：\n\n*   前两次测试根据 2024 年的实际数据验证了基线性能。\n*   第三次到第五次测试逐步提高到 2025 年的预测，目标是去年负载的 150%。\n*   到第四次测试，Shopify 达到了每分钟 1.46 亿次请求和每分钟超过 8 万次结账。在当年的最后一次测试中，他们测试了 p99 场景，达到了每分钟 2 亿次请求。\n\n这些测试规模异常庞大，因此 Shopify 在夜间运行它们，并与 YouTube 协调，因为这些测试会影响共享的云基础设施。团队测试了弹性 (resilience)，而不仅仅是原始负载容量。他们执行了区域故障转移 (regional failovers)，将流量从核心美国和欧盟区域疏散，以验证他们的灾难恢复程序是否实际有效。\n\nShopify 运行了四种类型的测试：\n\n*   **架构扩展测试 (Architecture scale-up tests)** 验证了其基础设施是否处理计划容量。\n*   **正常运行期间的负载测试 (Load tests during normal operations)** 建立了峰值负载下的基线性能。\n*   **带故障转移的负载测试 (Load tests with failover)** 验证了灾难恢复和跨区域故障转移能力。\n*   **游戏日模拟 (Game Day simulations)** 通过混沌工程测试了跨系统弹性。\n\n团队模拟了真实用户行为，例如店面浏览和结账、来自应用程序和集成的管理员 API 流量、分析和报告负载以及后端 webhook 处理。他们还测试了关键场景，如持续峰值负载、区域故障转移和多个系统同时失效的级联故障。\n\n每个测试周期都识别出了在稳态负载下永远不会出现的问题，并且团队在问题出现时就修复了它们。一些关键问题如下：\n\n*   规模测试 1 和 2 揭示，在高负载下，核心操作会抛出错误，结账队列会积压。\n*   规模测试 3 验证了关键迁移，并确认在基础设施更改后区域路由行为符合预期。\n*   规模测试 4 达到了限制，触发了计划外的故障转移，识别了测试流量路由中的优先问题，并发现了在重新平衡期间使区域恢复上线时的延迟。\n*   规模测试 5 进行了全面预演，并且是唯一一次在北美工作时间运行的测试，以模拟真实的 BFCM 条件。所有其他测试都在夜间运行。\n\n项目中期，Shopify 做出了一个重要的转变。他们将**已认证的结账流程 (authenticated checkout flows)** 添加到其测试场景中。模拟真实的登录买家暴露了匿名浏览从未触及的速率限制代码路径。尽管已认证流程在流量中占比很小，但它们揭示了在实际事件中会导致问题的瓶颈。\n\n### BFCM 周末运营 (BFCM Weekend Operations)\n\nBFCM 的准备工作让 Shopify 做好准备，但卓越的运营能力使他们在流量实际飙升时保持稳定。\n\n运营计划协调工程团队、事件响应和实时系统调优。以下是该计划的关键组成部分：\n\n*   BFCM 周末的计划包括**实时监控**，所有区域的仪表盘可见性以及自动化警报。\n*   对于事件响应，**事件经理值班团队 (Incident Manager OnCall teams)** 提供 24/7 覆盖，并有清晰的升级路径。\n*   **商家沟通 (Merchant communications)** 确保商家获得状态更新和任何问题的通知。\n*   **实时优化 (Live optimization)** 允许根据实时流量模式进行系统调优。\n\nBFCM 结束后，**事后分析 (post-mortem process)** 将监控数据与实际商家结果关联起来，以了解哪些有效，哪些需要改进。\n\n理念很简单：准备让你做好准备，但卓越的运营能力让你保持稳定。\n\n### 结论\n\nShopify 2025 年的 BFCM 准备计划展示了大规模系统化准备的样子。数千名工程师工作了九个月，运行了五次主要规模测试，将他们的基础设施推向预期负载的 150%。他们执行了区域故障转移，进行了混沌工程演练，记录了系统漏洞，并在商家需要它们之前用更新的运行手册强化了系统。\n\n与典型的发布前准备不同之处在于其系统化的方法。大多数公司进行一两次负载测试，修复关键 bug，然后寄希望于最好。Shopify 花了九个月持续测试，发现突破点，修复问题，并验证修复是否实际有效。\n\n此外，Shopify 构建的工具并非临时的 BFCM 脚手架。弹性矩阵 (Resiliency Matrix)、关键路径游戏日 (Critical Journey Game Days) 和实时自适应预测 (real-time adaptive forecasting) 成为永久性的基础设施改进。它们使 Shopify 每天都更具弹性，而不仅仅是在高峰季节。\n\n为了可视化 BFCM，Shopify 还推出了一款有趣的弹球游戏来展示 Shopify Live Globe。游戏本身在浏览器中以 120fps 运行，具有完整的 3D 环境、物理引擎和 VR 支持。在幕后，游戏是一个使用 “react-three-fiber” 构建的 three.js 应用程序。每一个商家销售都会在几秒钟后显示在这个地球仪上。每个人都可以在 Shopify Live Globe 的主页上查看该游戏和可视化。\n\n---\n\n### 要点总结\n\n*   **三轨框架：** Shopify 采用容量规划、基础设施路线图和风险评估三个并行轨道进行系统准备，确保相互反馈和持续改进。\n*   **混沌工程与游戏日：** 通过模拟生产故障（如网络故障、缓存失效），尤其关注“关键业务路径”（结账、支付），以暴露系统弱点并建立事件响应“肌肉记忆”。\n*   **弹性矩阵：** 集中文档化服务状态、故障场景、恢复程序、操作手册和值班覆盖，作为系统强化的核心路线图。\n*   **负载测试工具：** 使用 Genghis 模拟真实用户行为和渐进式流量，配合 Toxiproxy 模拟网络故障和分区，全面评估系统容量。\n*   **应对容量限制的策略：** 负载测试发现瓶颈后，采取横向扩展、纵向扩展或架构优化三种措施。\n*   **无历史数据挑战与分析平台优化：** 针对新重建的分析平台，通过专门的游戏日，优化 Kafka 分区、API 内存使用、连接超时和负载均衡策略。\n*   **多轮规模测试：** 在长达数月的时间里，运行五次大型规模测试（包括 p90 和 p99 场景），验证整体平台在远超预期的负载下协同工作。\n*   **灾难恢复验证：** 在规模测试中执行区域故障转移，验证灾难恢复程序和跨区域故障转移能力。\n*   **已认证流程测试的重要性：** 即使占比小，模拟登录用户的结账流程也能揭示匿名测试无法触及的速率限制瓶颈。\n*   **运营卓越与持续改进：** 强调 BFCM 周末的实时监控、24/7 待命、商家沟通和实时调优，并通过事后分析不断改进。\n\n### 你可以从这篇文章学到什么\n\n对于一个拥有几年经验的后端/系统设计工程师来说，这篇文章提供了宝贵的实践经验和系统化思考框架，远超简单的“如何优化代码”的范畴：\n\n1.  **系统级准备的宏观视角：** 文章展示了一个超大规模公司如何进行长达九个月的系统级准备。这不仅仅是技术细节，更是项目管理、风险管理和团队协作的典范。你可以学习如何将看似零散的准备工作组织成结构化的“三轨框架”，确保关键要素不被遗漏。\n2.  **混沌工程的深度应用：** “游戏日”概念是混沌工程在实践中的一个绝佳案例。它教导我们不能只在正常运行时测试系统，而要主动引入故障，模拟真实世界的混乱。理解“关键路径”的测试焦点，能帮助你在设计和测试自己的系统时，优先保障最核心的业务流程。\n3.  **负载测试的科学方法：** 学习 Shopify 如何结合 Genghis 和 Toxiproxy 进行多区域、多场景（基线、峰值、闪购、故障转移）的负载测试，并采取迭代优化的策略。这提醒我们在进行负载测试时，不仅要测性能，更要测弹性，并为测试结果制定明确的应对方案（横向/纵向扩展、优化）。\n4.  **应对“无历史数据”的挑战：** 对于新系统或新功能，如何进行峰值准备是一个常见难题。Shopify 对分析平台的处理方式——通过模拟和游戏日来揭示瓶颈，然后进行针对性的优化（Kafka 分区、内存、连接池、负载均衡），提供了非常有价值的实战经验。\n5.  **设计弹性系统的具体技术细节：** 文章中提到了许多具体的优化点，如 Kafka 分区增加、API 内存分析、连接池超时调优、负载均衡策略优化。这些都是日常工作中可能遇到的问题，Shopify 的解决方案能作为你的参考和启发。\n6.  **迭代与持续改进的哲学：** Shopify 并非“一次性”准备，而是通过多轮规模测试，每次发现问题并修复，然后再次测试。这种“发现-修复-验证”的闭环过程，以及将临时工具转化为永久基础设施（如弹性矩阵），体现了持续集成和持续改进的思想。\n7.  **运营与工程的紧密结合：** BFCM 周末的运营计划强调了实时监控、明确的事件响应、商家沟通和实时调优。这提醒我们，再完美的系统也需要一套健壮的运营流程来支撑，并且事后分析对于长期的系统健康至关重要。\n8.  **风险规避的策略：** “绝不将 BFCM 作为发布截止日期”的原则至关重要。大型事件前冻结代码和架构，提前完成变更，是降低风险的黄金法则。\n\n将这些经验应用到你的工作中，可以帮助你构建更健壮、更具弹性的系统，并以更系统化、更前瞻性的思维应对潜在的挑战和大规模流量冲击。",
    "url": "https://blog.bytebytego.com/p/how-shopify-prepares-for-black-friday"
  },
  {
    "id": "2025-12-25-how-shopify-prepares-for-black-friday",
    "title": "How Shopify Prepares for Black Friday",
    "date": "2025-12-25",
    "preview": "Shopify 如何备战黑色星期五  **注意：** 本文是与 Shopify 工程团队合作撰写的。特别感谢 Shopify 工程团队与我们分享他们为“黑色星期五网络星期一”所做的准备工作，并审阅最终文章。本文中分享的所有技术细节均归功于 Shopify 工程团队。  2024 ...",
    "content": "Shopify 如何备战黑色星期五\n\n**注意：** 本文是与 Shopify 工程团队合作撰写的。特别感谢 Shopify 工程团队与我们分享他们为“黑色星期五网络星期一”所做的准备工作，并审阅最终文章。本文中分享的所有技术细节均归功于 Shopify 工程团队。\n\n2024 年的“黑色星期五网络星期一”（BFCM）对 Shopify 来说是一次巨大的考验。该平台处理了 57.3 PB (petabytes) 的数据，处理了 10.5 万亿次数据库查询，并在其边缘网络（edge network）上达到了每分钟 2.84 亿次请求的峰值。仅在应用服务器上，他们在黑色星期五就处理了每分钟 8000 万次请求，同时每分钟推送 12 TB (terabytes) 的数据。\n\n有趣的是：这种流量水平现在已成为 Shopify 的基线。而 2025 年的 BFCM 规模更大，处理了 90 PB 的数据，处理了 1.75 万亿次数据库写入，峰值性能达到每分钟 4.89 亿次请求。这就是为什么 Shopify 从零开始重建了其整个 BFCM 备战计划。\n\n这项准备工作涉及数千名工程师，历时九个月，进行了五次大规模压力测试。\n\n在本文中，我们将探讨 Shopify 如何在这一“商业超级碗”中取得成功。\n\n### 三轨框架\n\nShopify 的 BFCM 准备工作始于三月份，采取了基于 Google Cloud 的多区域策略。\n\n工程团队将工作分为三个并行且相互影响的轨道：\n\n1.  **容量规划（Capacity Planning）**：涉及使用历史数据和商家增长预测来建模流量模式。团队提前将这些估算提交给其云提供商，以便提供商能够确保有足够的物理基础设施可用。这项规划定义了 Shopify 需要多少计算能力以及这些能力需要部署在哪些地理位置。\n2.  **基础设施路线图（Infrastructure Roadmap）**：团队在此审查其技术栈，评估需要进行哪些架构更改，并确定达到目标容量所需的系统升级。此轨道有助于规划所有后续工作。重要的是，Shopify 从不将 BFCM 作为发布截止日期。所有架构更改和迁移都在关键窗口期前几个月完成。\n3.  **风险评估（Risk Assessments）**：使用“可能出错的地方”（What Could Go Wrong）练习来记录故障场景。团队设定升级优先级，并为他们称之为“Game Days”的活动生成输入。这种情报有助于他们提前测试和强化系统。\n\n这三个轨道不断相互反馈。例如，风险发现可能会揭示团队未曾考虑到的容量缺口。基础设施变更可能会引入需要评估的新风险。换句话说，这是一个持续的反馈循环。\n\n### Game Days（演练日）\n\n为了正确评估风险，Shopify 工程团队会运行“Game Days”。这些是混沌工程（chaos engineering）练习，旨在故意模拟 BFCM 规模下的生产故障。\n\n团队从早春开始举办 Game Days。这涉及故意向系统注入故障，以测试它们在故障条件下的响应方式。可以将其视为软件的消防演习。\n\n在这些 Game Days 中，工程团队特别关注他们称之为“关键旅程”（critical journeys）的部分。这些是平台中最关键的业务路径：结账（checkout）、支付处理（payment processing）、订单创建（order creation）和履约（fulfillment）。如果这些在 BFCM 期间出现问题，商家会立即蒙受销售损失。\n\n关键旅程 Game Days 运行跨系统灾难模拟。以下是团队测试的一些常见方面：\n\n*   团队测试搜索和页面端点，同时随机化导航以模仿真实用户行为。他们注入网络故障和延迟，以查看服务无法快速通信时会发生什么。\n*   他们清除缓存（bust caches），以创建真实的负载模式，而不是在所有内容都被缓存时获得的人工快速响应。\n*   前端团队在这些练习期间进行“bug bashes”（集中找 Bug）。他们识别回归（regressions），测试关键用户流程，并验证用户体验在高峰负载条件下是否能保持稳定。\n\n这些练习通过暴露操作手册（operational playbooks）和监控工具中的空白，培养了事件响应的“肌肉记忆”。\n\n最重要的是，Shopify 在 BFCM 之前就填补了这些空白，而不是在商家最需要平台时才发现它们。Game Days 的所有发现都反馈到 Shopify 所称的“弹性矩阵”（Resiliency Matrix）中。这是一个集中的文档，用于跟踪整个平台中的漏洞、事件响应程序和修复措施。\n\n弹性矩阵包含五个关键组件：\n\n1.  **服务状态（service status）**：显示所有关键服务的当前运行状态。\n2.  **故障场景（failure scenarios）**：记录可能出现的故障类型及其影响。\n3.  **恢复程序（recovery procedures）**：列出预期的恢复时间目标（RTO）和修复问题的详细运行手册（runbooks）。\n4.  **操作手册（operational playbooks）**：提供逐步的事件响应指南。\n5.  **值班覆盖（on-call coverage）**：显示团队排班和 PagerDuty 升级路径。\n\n该矩阵成为 BFCM 之前系统强化的路线图。团队全年持续更新它，记录他们在此过程中进行的弹性改进。\n\n### 使用 Genghis 和 Toxiproxy 进行负载测试\n\nGame Days 隔离地测试组件，但 Shopify 还需要知道整个平台是否能处理 BFCM 的流量。这就是负载测试（load testing）发挥作用的地方。\n\n工程团队构建了一个名为 Genghis 的工具，该工具运行模拟真实用户行为的脚本化工作流。它模拟浏览、将商品添加到购物车以及完成结账流程。该工具逐渐增加流量，直到系统出现故障，这有助于团队找到其实际容量限制。\n\n测试同时从三个 Google Cloud 区域的生产基础设施上运行：`us-central`、`us-east` 和 `europe-west4`。这准确地模拟了全球流量模式。Genghis 还会注入闪购（flash sale）突发流量，叠加在基线负载之上，以测试峰值容量场景。\n\nShopify 将 Genghis 与 Toxiproxy 结合使用，Toxiproxy 是他们为模拟网络条件而构建的开源框架。Toxiproxy 注入网络故障和分区，阻止服务相互通信。作为参考，网络分区是指系统中的两个部分失去通信能力，即使它们都仍在运行。\n\n在测试期间，团队实时监控仪表板，并准备在系统开始退化时中止测试。多个团队协调工作，以发现并修复出现的瓶颈。\n\n当负载测试揭示限制时，团队有三个选择：\n\n*   **水平扩展（Horizontal scaling）**：意味着添加更多应用实例。\n*   **垂直扩展（Vertical scaling）**：意味着为每个实例提供更多资源，例如 CPU 和内存。\n*   **优化（Optimizations）**：意味着进行架构级别的更改以提高性能，范围从更好的数据库查询到跨消费层直到前端的性能调优。\n\n这些决策设定了最终的 BFCM 容量，并推动了 Shopify 整个技术栈的优化工作。关键的见解是，团队不能等到 BFCM 才发现容量限制。扩展基础设施和优化代码需要数月时间准备。\n\n### 分析平台挑战\n\nBFCM 测试了 Shopify 的每一个系统，但 2025 年提出了一个独特的挑战。他们部分基础设施从未经历过假日流量，这带来了一个问题：在没有历史数据可供建模的情况下，如何为高峰负载做准备？\n\n2024 年，Shopify 的工程团队重建了其整个分析平台。他们创建了新的 ETL 管道（ETL 代表 Extract, Transform, Load，即从各种源提取数据、处理数据并将其存储到有用位置的过程）。他们还更换了持久层（persistence layer），并用全新的 API 替换了其旧系统。\n\n这造成了一种不对称。ETL 管道在 2024 年 BFCM 期间运行，因此团队拥有一个完整的生产数据季节，显示这些管道在假日负载下的表现。但他们的 API 层在高峰季结束后才发布。他们正在为从未见过假日流量的 API 做 BFCM 准备。\n\n这一点非常重要，因为在 BFCM 期间，商家会 obsessively 检查他们的分析数据。他们想要实时的销售数据、转化率、流量模式和热门产品数据。所有这些查询都会命中 API 层。如果这些 API 无法处理负载，商家将在其最关键的销售期间失去可见性。\n\nShopify 专门为分析基础设施运行了 Game Days。这些是受控实验，旨在揭示故障模式和瓶颈。团队模拟了增加的流量负载，引入了数据库延迟，并测试了缓存故障，以系统地映射系统在压力下的行为。\n\n结果显示了四个需要修复的关键问题：\n\n1.  首先，ETL 管道需要增加 Kafka 分区（Kafka partition increases），以在流量高峰期间保持数据新鲜度。Apache Kafka 是一个分布式流处理平台，处理实时数据流。更多的分区意味着更多的并行处理，从而保持数据对 API 的新鲜度。\n2.  其次，API 层的内存使用需要优化。团队通过性能分析（profiling）发现了这一点，这意味着精确测量代码如何使用内存。每个 API 请求都使用了过多的内存。在高负载下，这会导致内存不足错误、响应时间变慢或完全崩溃。\n3.  第三，连接超时（connection timeouts）需要调整，以防止连接池耗尽。连接池（connection pool）是一组可重用的数据库连接。创建新连接成本很高，因此应用程序会重用它们。问题在于超时时间过长，这意味着连接会卡住等待。在高负载下，可用连接会耗尽，新请求开始失败。Shopify 调整了超时时间，以更快地释放连接。\n4.  第四，团队通过不同的负载均衡器方法拆分 API 请求。最初，API 请求都排队到同一个区域，这增加了延迟和负载。通过扩展次要区域的集群并更新负载均衡策略，他们更好地分配了工作，防止 API 服务器过载。\n\n除了性能修复之外，团队还验证了警报并记录了响应程序。他们的团队经过培训，为在实际事件中处理故障做好了准备。\n\n### 规模测试\n\nGame Days 和负载测试为单个组件做准备，但规模测试（scale testing）有所不同。它验证整个平台在 BFCM 流量下协同工作，揭示只有在所有系统同时满负荷运行时才会出现的问题。\n\n从四月到十月，Shopify 以其预测的流量水平，特别是其峰值 p90 流量假设（p90 在统计学中表示第 90 百分位数，即 90% 的请求流量将低于此水平），进行了五次大规模压力测试。\n\n以下是这些规模测试的详细信息：\n\n*   前两次测试根据 2024 年的实际数据验证了基线性能。\n*   第三到第五次测试逐步增加到 2025 年的预测值，目标是去年负载的 150%。\n*   到第四次测试时，Shopify 达到了每分钟 1.46 亿次请求和每分钟超过 8 万次结账。在当年的最后一次测试中，他们测试了 p99 场景，达到了每分钟 2 亿次请求。\n\n这些测试规模异常庞大，因此 Shopify 在夜间运行它们，并与 YouTube 协调，因为这些测试会影响共享的云基础设施。团队测试了弹性，而不仅仅是原始负载容量。他们执行了区域故障转移（regional failovers），从核心美国和欧盟区域撤离流量，以验证其灾难恢复程序是否实际有效。\n\nShopify 运行了四种类型的测试：\n\n*   **架构扩展测试（Architecture scale-up tests）**：验证其基础设施能否处理计划容量。\n*   **正常运行期间的负载测试（Load tests during normal operations）**：在峰值负载下建立基线性能。\n*   **带故障转移的负载测试（Load tests with failover）**：验证灾难恢复和跨区域故障转移能力。\n*   **Game Day 模拟（Game Day simulations）**：通过混沌工程测试跨系统弹性。\n\n团队模拟了真实用户行为，例如店面浏览和结账、来自应用程序和集成的管理员 API 流量、分析和报告负载以及后端 Webhook 处理。他们还测试了关键场景，如持续峰值负载、区域故障转移以及多个系统同时失败的级联故障（cascading failures）。\n\n每个测试周期都发现了一些在稳定负载下永远不会出现的问题，团队在问题出现时立即修复了它们。以下是一些关键问题：\n\n*   规模测试 1 和 2 发现，在高负载下，核心操作会抛出错误，并且结账队列会积压。\n*   规模测试 3 验证了关键迁移，并确认在基础设施更改后区域路由（regional routing）行为符合预期。\n*   规模测试 4 达到了限制，触发了计划外的故障转移，识别了测试流量路由中的优先问题，并发现了在重新平衡期间使区域重新上线时的延迟。\n*   规模测试 5 进行了全面演练，是唯一在北美工作时间运行的测试，以模拟真实的 BFCM 条件。所有其他测试都在夜间运行。\n\n项目中期，Shopify 做出了一个重要的转变。他们在测试场景中添加了已验证身份的结账流程（authenticated checkout flows）。模拟真实的登录买家暴露了匿名浏览从未触及的限速代码路径。尽管已验证身份的流程在总流量中占比较小，但它们揭示了在实际事件中会导致问题的瓶颈。\n\n### BFCM 周末运营\n\nBFCM 准备让 Shopify 做好了准备，但卓越的运营能力使他们在流量实际飙升时保持稳定。\n\n运营计划协调工程团队、事件响应和实时系统调优。以下是该计划的关键组成部分：\n\n*   BFCM 周末计划包括实时监控，所有区域的仪表板可见性以及自动化警报。\n*   对于事件响应，事件经理值班团队（Incident Manager OnCall teams）提供 24/7 全天候覆盖，并有明确的升级路径。\n*   商家沟通确保商店获得状态更新和任何问题的通知。\n*   实时优化（Live optimization）允许根据实时流量模式进行系统调优。\n*   BFCM 结束后，事后分析（post-mortem）流程将监控数据与实际商家结果关联起来，以了解哪些有效，哪些需要改进。\n\n理念很简单：准备让你做好准备，但卓越的运营能力让你保持稳定。\n\n### 结论\n\nShopify 的 2025 年 BFCM 备战计划展示了规模化系统准备的样貌。数千名工程师工作了九个月，进行了五次大规模压力测试，将基础设施推到了预期负载的 150%。他们执行了区域故障转移，进行了混沌工程演练，记录了系统漏洞，并在商家需要它们之前用更新的运行手册强化了系统。\n\n与典型的发布前准备不同之处在于其系统化的方法。大多数公司只进行一两次负载测试，修复关键 Bug，然后祈祷一切顺利。Shopify 花了九个月时间持续测试，发现突破点，修复问题，并验证修复措施是否实际有效。\n\n此外，Shopify 构建的工具并非临时的 BFCM 脚手架。弹性矩阵（Resiliency Matrix）、关键旅程 Game Days 和实时自适应预测（real-time adaptive forecasting）都成为了永久性的基础设施改进。它们使 Shopify 每天都更具弹性，而不仅仅是在高峰期。\n\n---\n\n### 要点总结\n\n*   **持续的容量规划与预测**：Shopify 从历史数据和商家增长预测出发，提前与云服务商协调资源，确保物理基础设施的供应。\n*   **三轨并行工作框架**：容量规划、基础设施路线图和风险评估三个轨道并行进行，相互反馈，形成持续改进的闭环。\n*   **Game Days 与混沌工程**：通过“Game Days”模拟真实生产故障，尤其关注“关键旅程”（如结账、支付），提前暴露系统脆弱点并培养团队的事件响应能力。\n*   **Resiliency Matrix（弹性矩阵）**：作为核心文档，集中记录服务状态、故障场景、恢复程序、操作手册和值班覆盖，指导系统强化工作。\n*   **专业负载测试工具**：使用自研工具 Genghis 模拟真实用户行为和流量突发，结合 Toxiproxy 注入网络故障，全面测试系统在高压和异常条件下的行为。\n*   **多区域生产基础设施测试**：负载测试在生产环境中跨多个 Google Cloud 区域并行运行，准确模拟全球流量模式。\n*   **优化策略**：当发现容量限制时，采取水平扩展、垂直扩展和代码/架构优化相结合的策略。\n*   **分析平台特殊挑战应对**：针对新建的、缺乏历史高峰流量数据的分析平台，通过专门的 Game Days 识别并解决了 Kafka 分区、API 内存、连接池超时和负载均衡策略等关键问题。\n*   **分阶段大规模压力测试**：在 BFCM 前的几个月内进行多轮分阶段的规模测试，从基线性能验证逐步升级到预测峰值（p90, p99），并执行区域故障转移，验证灾难恢复能力。\n*   **BFCM 周末运营计划**：强调实时监控、24/7 值班响应、商家沟通以及基于实时流量的动态优化，并通过事后分析持续学习和改进。\n\n### 你可以从这篇文章学到什么\n\n对于一个有几年经验的后端/系统设计工程师来说，这篇文章提供了宝贵的实践经验和系统性方法，远超出了“做负载测试”的表面理解。\n\n1.  **系统性思维和长周期准备**：文章强调了长达九个月的系统性准备工作，这表明大规模系统的弹性并非一蹴而就。它教导工程师应该将高可用性和可伸缩性视为一个持续的项目，而不是一次性的任务。你可以学习到如何在项目初期就将容量规划、架构演进和风险评估整合到开发流程中。\n2.  **混沌工程与真实性模拟**：Shopify 的“Game Days”和结合 Toxiproxy 的负载测试是混沌工程在生产环境准备中的典范。这不仅仅是测试系统“能跑多快”，更是测试系统“如何优雅地失败”。你可以借鉴这种方法，在自己的系统中引入故障注入，主动发现那些在正常操作下难以察觉的系统脆弱点，并为最坏情况做准备。\n3.  **“关键旅程”的识别与重点测试**：识别并重点测试业务最关键的路径（如结账、支付）是高效利用测试资源的关键。这提醒我们在设计和测试时，要始终以业务价值为导向，确保核心功能在极端负载下能够幸存。\n4.  **弹性矩阵（Resiliency Matrix）的实践价值**：将服务状态、故障场景、恢复程序、操作手册和值班计划集中文档化，形成“弹性矩阵”，是构建和维护高弹性系统的核心实践。这可以帮助工程师梳理系统的弱点、明确恢复步骤，并确保团队在紧急情况下能够迅速响应。\n5.  **未知场景的应对策略**：分析平台在 BFCM 2025 面临“无历史数据”的挑战，Shopify 仍通过专门的 Game Days 和有针对性的优化（Kafka 分区、API 内存、连接池、负载均衡）解决了问题。这展示了即使面对全新的系统或无先例的负载，也能通过系统性分析和实验来构建弹性的能力。\n6.  **迭代和多阶段测试**：Shopify 进行了五次大规模压力测试，逐步提升目标负载，并根据每次测试的结果进行迭代修复。这种循序渐进、不断发现和解决问题的测试策略，比一次性的大型测试更可靠。它鼓励工程师在项目生命周期中持续进行性能和弹性测试。\n7.  **运营卓越的重要性**：除了准备工作，BFCM 周末的实时监控、24/7 值班、自动化警报和动态优化，都体现了运营（Ops）在系统稳定性中的关键作用。这强调了“DevOps”理念，即开发和运营的紧密结合是确保系统在峰值表现的关键。\n\n总之，这篇文章提供了一份在极端流量和复杂环境下构建、测试和运营超大规模电商平台的“蓝图”。它不仅仅是关于技术栈的选择，更是关于组织、流程和文化的系统性工程。对于希望提升系统设计和工程实践能力的工程师而言，深入理解并尝试应用 Shopify 的这些方法，将大有裨益。",
    "url": "https://blog.bytebytego.com/p/how-shopify-prepares-for-black-friday"
  },
  {
    "id": "2025-12-24-how-shopify-prepares-for-black-friday",
    "title": "How Shopify Prepares for Black Friday",
    "date": "2025-12-24",
    "preview": "Shopify 如何备战黑色星期五  注：本文是与 Shopify 工程团队合作撰写的。特别感谢 Shopify 工程团队与我们分享了他们为黑色星期五网络星期一（BFCM）所做的准备工作细节，并审阅了文章终稿。本文中分享的所有技术细节均归功于 Shopify 工程团队。  202...",
    "content": "Shopify 如何备战黑色星期五\n\n注：本文是与 Shopify 工程团队合作撰写的。特别感谢 Shopify 工程团队与我们分享了他们为黑色星期五网络星期一（BFCM）所做的准备工作细节，并审阅了文章终稿。本文中分享的所有技术细节均归功于 Shopify 工程团队。\n\n2024 年的黑色星期五网络星期一（BFCM）对 Shopify 来说是一场盛事。该平台处理了 57.3 PB 的数据，处理了 10.5 万亿次数据库查询，其边缘网络（edge network）的峰值请求达到每分钟 2.84 亿次。仅在应用服务器上，他们每分钟就处理了 8000 万次请求，并在黑色星期五期间每分钟推送 12 TB 的数据。\n\n有趣的是，这种流量水平现在已成为 Shopify 的基线。而 2025 年的 BFCM 规模更大，处理了 90 PB 的数据，1.75 万亿次数据库写入，峰值性能达到每分钟 4.89 亿次请求。正因如此，Shopify 彻底重建了其 BFCM 准备计划。\n\n准备工作涉及数千名工程师，历时九个月，进行了五次大规模的扩展性测试。\n\n在本文中，我们将探讨 Shopify 如何为这场商业界的“超级碗”做好准备。\n\n### 三轨并行框架\n\nShopify 的 BFCM 准备工作从三月份开始，在 Google Cloud 上采用了多区域（multi-region）策略。\n\n工程团队将工作分为三个并行轨道（tracks），它们同时运行并相互影响：\n\n**容量规划（Capacity Planning）**涉及利用历史数据和商家增长预测来建模流量模式。团队会提早将这些估算提交给其云服务提供商，以确保提供商有足够的物理基础设施可用。这项规划定义了 Shopify 需要多少计算能力以及这些能力在地理上应如何分布。\n\n**基础设施路线图（Infrastructure Roadmap）**是团队审查其技术栈（technology stack），评估需要进行哪些架构更改，并确定为达到目标容量所需的系统升级。此轨道有助于安排所有后续工作的顺序。重要的是，Shopify 从不将 BFCM 作为发布截止日期。所有的架构变更和迁移都会在关键窗口（critical window）前数月完成。\n\n**风险评估（Risk Assessments）**使用“可能出现什么问题”（What Could Go Wrong）的练习来记录故障场景。团队设定升级优先级，并为他们所谓的“Game Days”（演练日）提供输入。这些信息有助于他们提前测试和强化系统。\n\n这三个轨道之间持续相互影响。例如，风险评估结果可能会揭示团队未考虑到的容量缺口。基础设施变更可能会引入需要评估的新风险。换句话说，这是一个持续的反馈循环。\n\n### 演练日（Game Days）\n\n为了正确评估风险，Shopify 工程团队会进行“演练日”。这些是混沌工程（chaos engineering）演练，旨在有意识地模拟 BFCM 规模下的生产故障。\n\n团队在早春就开始举办演练日。这包括故意向系统注入故障，以测试它们在故障条件下的响应方式。可以将其视为软件的消防演习。\n\n在这些演练日期间，工程团队会特别关注他们所谓的“关键业务路径”（critical journeys）。这些是其平台中最关键的业务路径：结账、支付处理、订单创建和履约。如果在 BFCM 期间这些路径中断，商家会立即蒙受销售损失。\n\n关键业务路径的演练日会运行跨系统（cross-system）的灾难模拟。以下是团队通常测试的一些方面：\n\n*   团队测试搜索和页面端点（endpoints），同时随机化导航以模仿真实用户行为。他们注入网络故障和延迟，以观察服务无法快速通信时会发生什么。\n*   他们“清除缓存”（bust caches），以创建真实的负载模式，而不是当所有内容都被缓存时获得的人工快速响应。\n*   前端团队在这些演练中进行“找 Bug 大会”（bug bashes）。他们识别回归问题（regressions），测试关键用户流，并验证用户体验在峰值负载条件下是否能保持稳定。\n\n这些演练通过暴露运维手册（operational playbooks）和监控工具中的不足，帮助团队建立事故响应的“肌肉记忆”。\n\n最重要的是，Shopify 在 BFCM 之前就填补了这些空白，而不是在商家最需要平台时才发现问题。演练日的所有发现都会汇总到 Shopify 所称的“弹性矩阵”（Resiliency Matrix）中。这是一个集中式文档，用于跟踪整个平台的漏洞、事故响应程序和修复措施。\n\n弹性矩阵包含五个关键组件：\n\n1.  首先是**服务状态（service status）**，显示所有关键服务的当前运行状态。\n2.  其次是**故障场景（failure scenarios）**，记录系统可能如何崩溃以及会产生什么影响。\n3.  第三是**恢复程序（recovery procedures）**，列出预期的恢复时间目标（recovery time objectives）和详细的问题修复操作手册（runbooks）。\n4.  第四是**运维手册（operational playbooks）**，包含分步式事故响应指南。\n5.  第五是**值班覆盖（on-call coverage）**，显示团队排班和 PagerDuty 升级路径。\n\n该矩阵成为 BFCM 前系统强化的路线图。团队全年持续更新它，记录弹性改进。\n\n### 使用 Genghis 和 Toxiproxy 进行负载测试\n\n演练日测试的是独立组件，但 Shopify 还需要知道整个平台是否能处理 BFCM 的流量。这就是负载测试（load testing）的作用。\n\n工程团队构建了一个名为 Genghis 的工具，它运行模拟真实用户行为的脚本化工作流。它模拟浏览、将商品添加到购物车和完成结账流程。该工具逐渐增加流量，直到系统崩溃，这有助于团队找到其实际容量限制。\n\n测试在生产基础设施（production infrastructure）上同时从三个 Google Cloud 区域运行：us-central、us-east 和 europe-west4。这准确模拟了全球流量模式。Genghis 还在基线负载之上注入“闪购”（flash sale）爆发流量，以测试峰值容量场景。\n\nShopify 将 Genghis 与 Toxiproxy 结合使用，Toxiproxy 是他们构建的一个用于模拟网络条件的开源框架。Toxiproxy 注入网络故障和分区，阻止服务之间相互通信。例如，网络分区（network partition）是指系统的两个部分失去通信能力，即使它们都在运行。\n\n在测试期间，团队会实时监控仪表盘（dashboards），并准备在系统开始降级时中止测试。多个团队协调工作，及时发现并修复瓶颈。\n\n当负载测试揭示了限制时，团队有三个选择：\n\n*   **横向扩展（Horizontal scaling）**意味着增加更多的应用实例。\n*   **纵向扩展（Vertical scaling）**意味着为每个实例提供更多资源，例如 CPU 和内存。\n*   **优化（Optimizations）**意味着进行架构层面的更改以提高性能，范围从更好的数据库查询到跨消费层（consuming layers）乃至前端的性能调优。\n\n这些决策设定了最终的 BFCM 容量，并推动了 Shopify 整个技术栈（stack）的优化工作。关键的见解是，团队不能等到 BFCM 才发现容量限制。扩展基础设施和优化代码需要数月的准备。\n\n### 分析平台挑战\n\nBFCM 会考验 Shopify 的每一个系统，但 2025 年带来了一个独特的挑战。其部分基础设施从未经历过假日流量，这带来了一个问题：当没有历史数据可供建模时，如何为峰值负载做准备？\n\n2024 年，Shopify 的工程团队重建了整个分析平台。他们创建了新的 ETL 管道（pipelines）。ETL 代表 Extract（提取）、Transform（转换）、Load（加载），这是一个从各种来源拉取数据、处理数据并将其存储到有用位置的过程。他们还更换了持久化层（persistence layer），并用全新的 API 替换了其旧系统。\n\n这造成了一种不对称性。ETL 管道在 2024 年 BFCM 期间运行过，因此团队拥有一整季的生产数据，显示这些管道在假日负载下的性能。但他们的 API 层是在高峰期结束后才上线的。他们正在为 BFCM 准备那些从未经历过假日流量的 API。\n\n这非常重要，因为在 BFCM 期间，商家会痴迷地查看他们的分析数据。他们需要实时的销售数字、转化率、流量模式和热门产品数据。所有这些查询都会命中 API 层。如果这些 API 无法处理负载，商家在最关键的销售期将失去可见性。\n\nShopify 专门为分析基础设施运行了演练日。这些是受控实验，旨在揭示故障模式和瓶颈。团队模拟增加的流量负载，引入数据库延迟，并测试缓存故障，以系统地绘制系统在压力下的行为。\n\n结果显示了四个需要修复的关键问题：\n\n1.  首先，ETL 管道需要增加 Kafka 分区（partitions），以在流量高峰期间保持数据新鲜度。Apache Kafka 是一个处理实时数据流的分布式流处理平台。更多的分区意味着更多的并行处理，从而使 API 可以提供更新鲜的数据。\n2.  其次，API 层的内存使用需要优化。团队通过性能分析（profiling）发现了这一点，性能分析是指精确测量代码如何使用内存。每个 API 请求使用了过多的内存。在高负载下，这会导致内存不足错误（out-of-memory errors）、响应时间变慢或完全崩溃。\n3.  第三，连接超时（connection timeouts）需要调整以防止连接池耗尽（pool exhaustion）。连接池（connection pool）是一组可重用的数据库连接。创建新连接的开销很大，因此应用程序会重用它们。问题在于超时时间过长，这意味着连接会一直处于等待状态。在高负载下，可用连接会耗尽，新的请求将开始失败。Shopify 调整了超时时间以更快地释放连接。\n4.  第四，团队通过不同的负载均衡器（load balancer）方法来拆分 API 请求。最初，API 请求会全部排队到一个区域，这增加了延迟和负载。通过扩展辅助区域的集群并更新负载均衡策略，他们更好地分配了工作，防止 API 服务器过载。\n\n除了性能修复之外，团队还验证了警报机制（alerting）并记录了响应程序。他们的团队都经过培训，为在实际事件中处理故障做好了准备。\n\n### 规模测试\n\n演练日和负载测试是为单个组件做准备，而规模测试（scale testing）则不同。它验证整个平台在 BFCM 流量下协同工作的情况，揭示只有当所有系统同时满负荷运行时才会出现的问题。\n\n从四月到十月，Shopify 按照其预测的流量水平，特别是峰值 p90 流量假设，进行了五次大规模测试。在统计学中，p90 表示第 90 百分位，即 90% 的请求量都低于此流量水平。\n\n以下是这些规模测试的详细信息：\n\n*   前两次测试根据 2024 年的实际数据验证了基线性能。\n*   第三到第五次测试逐步提高到 2025 年的预测，目标是去年负载的 150%。\n*   到第四次测试时，Shopify 达到了每分钟 1.46 亿次请求和每分钟超过 8 万次结账。在当年的最后一次测试中，他们测试了 p99 场景，达到了每分钟 2 亿次请求。\n\n这些测试规模异常庞大，因此 Shopify 在夜间运行它们，并与 YouTube 协调，因为这些测试会影响共享的云基础设施。团队测试的是弹性（resilience），而不仅仅是原始负载容量。他们执行了区域故障转移（regional failovers），从美国和欧盟的核心区域疏散流量，以验证其灾难恢复程序（disaster recovery procedures）确实有效。\n\nShopify 运行了四种类型的测试：\n\n*   **架构扩展测试（Architecture scale-up tests）**验证了其基础设施能够处理计划的容量。\n*   **正常运行期间的负载测试（Load tests during normal operations）**建立了峰值负载下的基线性能。\n*   **带故障转移的负载测试（Load tests with failover）**验证了灾难恢复和跨区域故障转移能力。\n*   **演练日模拟（Game Day simulations）**通过混沌工程测试了跨系统的弹性。\n\n团队模拟了真实用户行为，例如店面浏览和结账、来自应用程序和集成的管理 API 流量、分析和报告负载以及后端 Webhook 处理。他们还测试了关键场景，如持续峰值负载、区域故障转移以及多个系统同时失败的级联故障（cascading failures）。\n\n每个测试周期都识别出在稳态负载下永远不会出现的问题，并且团队随着问题的出现而修复它们。一些关键问题如下：\n\n*   规模测试 1 和 2 揭示了在重负载下，核心操作会抛出错误，并且结账队列（checkout queues）会积压。\n*   规模测试 3 验证了关键迁移，并确认了基础设施变更后区域路由（regional routing）行为符合预期。\n*   规模测试 4 达到了限制，触发了计划外的故障转移，识别了测试流量路由中的优先问题，并发现了在重新平衡期间将区域重新上线时的延迟。\n*   规模测试 5 进行了全面预演，是唯一一次在北美工作时间运行的测试，以模拟真实的 BFCM 条件。所有其他测试都在夜间运行。\n\n在项目中期，Shopify 做出了一个重要的转变。他们将**认证结账流程（authenticated checkout flows）**添加到了测试场景中。模拟真实登录买家暴露了匿名浏览从未触及的限速代码路径。尽管认证流程只占流量的一小部分，但它们揭示了在实际事件中会导致问题的瓶颈。\n\n### BFCM 周末运营\n\nBFCM 的准备工作让 Shopify 做好了准备，但卓越的运营（operational excellence）确保他们在流量真正高峰时保持稳定。\n\n运营计划协调工程团队、事故响应和实时系统调优。以下是该计划的关键组成部分：\n\n*   BFCM 周末的计划包括实时监控（real-time monitoring），提供所有区域的仪表盘可见性（dashboard visibility）和自动化警报（automated alerts）。\n*   对于事故响应，事故经理（Incident Manager）值班团队提供 24/7 全天候覆盖，并有明确的升级路径。\n*   商家沟通确保商店获得状态更新和任何问题的通知。\n*   实时优化（Live optimization）允许根据实时流量模式进行系统调优。\n*   BFCM 结束后，事后分析（post-mortem）过程将监控数据与实际商家结果关联起来，以了解哪些方法有效以及哪些地方需要改进。\n\n理念很简单：准备让你做好准备，但卓越的运营让你保持稳定。\n\n### 结论\n\nShopify 2025 年的 BFCM 准备计划展示了大规模系统准备工作是怎样的。数千名工程师工作了九个月，进行了五次大规模的扩展性测试，将其基础设施推向了预期负载的 150%。他们执行了区域故障转移，运行了混沌工程演练，记录了系统漏洞，并在商家需要之前，用更新的操作手册强化了系统。\n\n这与典型的发布前准备不同之处在于其系统化的方法。大多数公司进行一两次负载测试，修复关键 bug，然后寄希望于最佳结果。Shopify 则花费了九个月的时间持续测试，发现系统崩溃点，修复问题，并验证修复措施确实有效。\n\n此外，Shopify 构建的工具并非临时的 BFCM 支撑结构。弹性矩阵（Resiliency Matrix）、关键业务路径演练日（Critical Journey Game Days）和实时自适应预测（real-time adaptive forecasting）都成为了永久性的基础设施改进。它们使 Shopify 每天都更具弹性，而不仅仅是在高峰期。\n\n为了提供 BFCM 的可视化效果，Shopify 还推出了一款有趣的弹珠游戏，以展示 Shopify Live Globe。该游戏本身在浏览器中以 120fps 运行，拥有完整的 3D 环境、物理引擎和 VR 支持。在幕后，这款游戏是一个使用“react-three-fiber”构建的 three.js 应用程序。每一笔商家销售都会在几秒钟后显示在这个地球仪上。\n\n参考资料：\n*   How we prepare Shopify for BFCM (Shopify 如何为 BFCM 做准备)\n*   Extract, Transform, Load (提取、转换、加载 - ETL)\n*   Toxiproxy\n*   Shopify Live Globe\n*   Details about the Shopify Live Globe Pinball Game (关于 Shopify Live Globe 弹珠游戏的详细信息)\n\n---\n\n### 要点总结\n\n*   Shopify 采用系统化的“三轨并行框架”准备 BFCM：容量规划、基础设施路线图和风险评估，三者持续相互反馈。\n*   通过“演练日”（Game Days）进行混沌工程，模拟生产故障，特别关注结账、支付等“关键业务路径”。\n*   建立了“弹性矩阵”（Resiliency Matrix）作为集中的文档，记录服务状态、故障场景、恢复程序、运维手册和值班安排，指导系统强化。\n*   使用自研工具 Genghis 进行全平台负载测试，模拟真实用户行为和闪购流量，并通过 Toxiproxy 模拟网络故障。\n*   负载测试中发现容量限制时，采取横向扩展、纵向扩展或架构优化等策略。\n*   对新构建的分析平台，通过专门的演练日识别并解决了 Kafka 分区不足、API 内存使用过高、连接超时及负载均衡不合理等问题。\n*   从四月到十月进行了五次大规模测试，覆盖 p90 和 p99 峰值流量，并执行了区域故障转移，验证灾难恢复能力。\n*   测试场景中增加了认证结账流程，揭示了匿名浏览无法触及的限速瓶颈。\n*   BFCM 期间的运营侧重于实时监控、自动化警报、24/7 事故响应、商家沟通和实时系统调优，并通过事后分析持续改进。\n*   所建立的弹性矩阵、演练日和实时自适应预测等机制是永久性的基础设施改进，而非临时措施，持续提升系统弹性。\n\n---\n\n### 你可以从这篇文章学到什么\n\n对于一个拥有几年经验的后端/系统设计工程师来说，这篇文章提供了一个大型电商平台如何系统性地应对流量洪峰的宝贵案例。你可以从中学习到以下几点，并应用于实际工作中：\n\n1.  **分阶段、系统化的准备方法**：Shopify 的“三轨并行框架”——容量规划、基础设施路线图和风险评估——展示了如何在早期并行开展多项工作，并形成反馈闭环。这对于任何大型项目的准备都非常有借鉴意义，它强调了规划、实施和风险管理需同步进行，而非线性推进。\n\n2.  **混沌工程与“关键业务路径”**：文章详细介绍了“演练日”如何通过故意注入故障来测试系统弹性，并强调了聚焦“关键业务路径”（如结账、支付）的重要性。在你的系统设计中，识别并持续测试最核心的业务流程，能够确保在极端情况下业务不受致命影响。你可以将混沌工程的理念引入自己的测试策略，而不仅仅是简单的单元测试和集成测试。\n\n3.  **可操作的“弹性矩阵”**：弹性矩阵作为集中式文档，涵盖了服务状态、故障场景、恢复程序、运维手册和值班覆盖。这提供了一个构建自身灾难恢复和应急响应体系的清晰蓝图。一个详尽且持续更新的矩阵，能够显著提高团队在突发事件中的响应效率和准确性。\n\n4.  **精细化的负载与规模测试**：Genghis 和 Toxiproxy 这类工具的运用，以及多区域、多场景（正常负载、闪购爆发、带故障转移）的测试方法，展示了如何真实地模拟生产环境。尤其是对新系统（如分析平台 API）没有历史数据的情况，通过专门的演练日来发现和解决问题，提供了应对“数据盲点”的有效策略。在你的项目中，即使没有自研工具，也可以利用现有的负载测试工具和混沌工程框架，设计更贴近真实世界的测试方案。\n\n5.  **深入的问题分析与解决**：文章中分析平台遇到的四个问题及其解决方案（Kafka 分区调整、API 内存优化、连接超时调优、负载均衡策略调整），都是后端工程师在日常工作中可能遇到的典型性能瓶颈。了解这些具体的优化手段，能帮助你在面对类似问题时，有更清晰的排查思路和解决方案。\n\n6.  **早期发现和持续改进**：Shopify 强调不能等到峰值才发现问题，而是要提前数月持续测试和修复。这种“持续测试-发现-修复-验证”的循环，以及将临时应对措施转化为永久性基础设施改进（如弹性矩阵成为日常工具）的理念，是提升系统长期稳定性和可维护性的关键。\n\n总之，这篇文章不仅仅是关于如何应对黑色星期五，更是关于如何构建一个高度弹性、可伸缩且运维卓越的大规模分布式系统。它鼓励工程师从更宏观的视角去思考系统准备、风险管理和持续改进。",
    "url": "https://blog.bytebytego.com/p/how-shopify-prepares-for-black-friday"
  }
]