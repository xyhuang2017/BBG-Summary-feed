[
  {
    "id": "2025-12-16-top-ai-agentic-workflow-patterns",
    "title": "Top AI Agentic Workflow Patterns",
    "date": "2025-12-16",
    "preview": "顶级的AI智能体工作流模式  当我们最初与大型语言模型（LLM）互动时，体验是直接的：我们输入一个提示词（prompt），模型生成一个响应，互动随即结束。  这种单轮（single-turn）方式对于简单问题或基础内容生成效果良好，但当我们处理更复杂的任务时，它的局限性很快就暴露...",
    "content": "顶级的AI智能体工作流模式\n\n当我们最初与大型语言模型（LLM）互动时，体验是直接的：我们输入一个提示词（prompt），模型生成一个响应，互动随即结束。\n\n这种单轮（single-turn）方式对于简单问题或基础内容生成效果良好，但当我们处理更复杂的任务时，它的局限性很快就暴露出来。试想一下，要求AI分析市场趋势、创建一份全面的报告并提供可操作的建议。一个单独的响应，无论多么精心制作，往往力有不逮，因为它缺乏收集额外信息、反思其推理过程或根据反馈完善输出的机会。\n\n这正是智能体工作流（agentic workflows）发挥作用的地方。\n\n智能体工作流不再将AI互动视为一次性交易，而是引入了迭代过程、工具集成和结构化的问题解决方法。这些工作流将语言模型从复杂的文本生成器转变为有能力的智能体，它们能够分解复杂问题、调整策略并产生更高质量的结果。这种差异类似于将一个快速草图与一幅精心打磨的画作进行比较。两者都有其用途，但当质量和可靠性至关重要时，迭代方法更胜一筹。\n\n在本文中，我们将探讨最流行的智能体工作流模式及其运作方式。\n\n### 理解智能体工作流\n\n智能体工作流不仅仅响应一个单一指令。相反，它在一定程度上自主运作，决定如何处理任务、采取哪些步骤以及如何根据其发现进行调整。这代表了我们思考如何使用AI系统的根本转变。\n\n考虑一下请求一个基础聊天机器人和一个智能体系统帮助撰写研究报告的区别。基础聊天机器人收到请求后，根据其训练数据生成一份报告，并一次性提供其生成的所有内容。然而，一个智能体系统可能会首先在网络上搜索有关该主题的最新信息，然后将发现组织成主题，起草报告的各个部分，审查每个部分的准确性和连贯性，修改薄弱区域，最后将所有内容编译成一份精美的文档。这些步骤中的每一个都可能涉及多个子步骤、关于使用哪些工具的决策以及根据智能体发现进行调整。\n\n真正使工作流具有智能体特性的，是内置于过程中的迭代和反馈循环。智能体工作流不是一次性生成输出，而是涉及循环：智能体执行一个动作，观察结果，然后利用该观察结果指导下一步动作。这与人类实际解决复杂问题的方式异曲同工。我们很少在事前就弄清所有事情并执行一个完美的计划。相反，我们尝试一些东西，观察发生的情况，从结果中学习，然后调整方法。智能体工作流将这种适应性、迭代性带入了AI系统。\n\n### 五种核心智能体工作流模式\n\n现在让我们看看五种核心智能体工作流模式：\n\n#### 1. 反思模式（Reflection Pattern）：自我改进的智能体\n\n反思的核心是让智能体审查和批判自己的工作，然后根据批判进行修改。这个简单的想法提高了输出质量，因为它引入了一个迭代的精炼过程，可以发现错误、识别弱点并增强优势。\n\n反思循环在实践中是这样运作的：\n\n智能体首先根据收到的任务或提示词生成初始输出。\n\n然后，智能体不立即将此输出呈现为最终结果，而是切换到批判模式。它审查刚刚生成的内容，寻找问题、不一致、缺乏清晰度的区域或改进的机会。这种批判成为修改的基础。\n\n智能体生成一个改进版本，解决其识别出的问题。根据实现方式，这个循环可能会重复多次，每次迭代都会进一步完善输出。\n\n请参见下图：\n（此处原文有图示，表示智能体生成初始输出 -> 批判 -> 改进 -> 再次批判/改进的循环）\n\n当我们专门针对执行的批判类型时，反思的力量变得更加明显。例如：\n\n一个智能体可能专门反思准确性，检查其所做的事实和主张是否正确且有充分支持。\n或者，反思可能侧重于清晰度，询问不熟悉该主题的人是否能理解解释。\n对于创意写作，反思可能会评估语气，确保声音符合预期的风格和受众。\n对于代码生成，反思可能侧重于识别错误（bugs）、安全漏洞或优化性能的机会。\n\n反思模式最适用于质量比速度更重要，并且存在受益于审查的主观方面的任务。然而，对于答案直接的简单、事实性查询，或者速度至关重要且“足够好”确实就足够的任务，这种模式的必要性较低。\n\n#### 2. 工具使用模式（Tool Use Pattern）\n\n工具使用模式代表了AI智能体能够完成的事情的根本性扩展。\n\n一个语言模型本身，无论多么复杂，都局限于推理其在训练期间学到的信息，并根据该知识生成文本。它无法访问最新信息、执行大规模精确计算、从特定数据库检索数据或与外部系统交互。工具改变了一切。\n\n在工具使用模式中，智能体配备了一套在需要时可以调用的能力。这些能力可能包括用于查找最新信息的网络搜索引擎、用于访问天气数据或股票价格等服务的API、用于运行程序和执行计算的代码解释器、用于检索特定记录的数据库查询工具、用于读写文档的文件系统访问以及无数其他专业功能。与传统软件的关键区别在于，智能体本身根据手头的任务决定何时以及如何使用这些工具。\n\n请参见下图：\n（此处原文有图示，表示智能体接收任务 -> 分析需求 -> 选择工具 -> 使用工具 -> 观察结果 -> 再次分析/选择工具的循环）\n\n当智能体收到一个任务时，它会分析完成该任务需要哪些能力。例如：\n\n如果任务需要智能体没有的信息，它会识别出需要搜索或数据检索工具。\n如果任务涉及数学运算，它会访问计算器或代码解释器。\n如果任务需要与特定服务交互，它会使用相应的API工具。\n\n工具使用之所以强大，在于工具选择的动态性以及将多个工具调用链接在一起的能力。\n\n智能体不遵循预设脚本。如果第一次搜索没有返回足够的信息，智能体可能会重新组织查询并再次搜索。如果API调用失败或返回错误，智能体可能会尝试另一种方法或完全不同的工具。这种适应性使得启用工具的智能体比僵化的自动化工作流强大得多。\n\n#### 3. 推理与行动模式（Reason and Act Pattern，简称ReAct）\n\n推理与行动模式，通常称为ReAct，代表了一种结合明确推理和迭代行动的复杂问题解决方法。ReAct智能体不是在行动前思考整个计划，也不是不经反思盲目行动，而是在推理下一步要做什么和实际执行之间交替进行。这种思想和行动的交织创造了一种自然的、适应性强的问题解决过程。\n\nReAct循环遵循清晰的模式：\n\n首先，智能体推理当前情况以及它需要完成什么。这个推理步骤是明确的，通常被字面记录为智能体的内部思维过程。智能体可能会思考它拥有什么信息，还需要什么，哪些方法可能有效，以及最佳的下一步是什么。\n然后，基于这个推理，智能体采取一个行动。这可能是使用工具收集信息、执行计算或做出决定。\n行动之后，智能体观察结果并进入新的推理阶段，思考它学到了什么以及下一步要做什么。这个循环持续进行，直到智能体确定它已完成目标或达到无法继续进行的地步。\n\n请参见下图：\n（此处原文有图示，表示智能体思考 -> 行动 -> 观察 -> 再次思考/行动的循环）\n\n明确的推理步骤具有多重重要目的：\n\n首先，它们帮助智能体保持专注并聚焦于目标。通过阐明它试图完成什么以及为什么每个行动都有意义，智能体不太可能走上无关的路径或陷入无益的循环。\n其次，推理步骤实现了适应性。当某个行动没有产生预期结果时，推理阶段允许智能体诊断原因并调整其方法，而不是盲目地继续。\n第三，推理轨迹提供了透明度。用户和开发者不仅可以看到智能体做了什么，还可以看到它为什么做出这些选择，这对于信任、调试和理解智能体的决策过程非常宝贵。\n\n将ReAct与纯粹的计划或纯粹的执行进行比较，突显了其优势。\n\n纯粹的计划意味着在采取任何行动之前弄清所有步骤。当信息完整且环境可预测时，这非常有效，但当我们需要在过程中发现信息或情况发生变化时，它就会遇到困难。\n纯粹的执行意味着不加太多思索地采取行动，这很快但往往效率低下且容易出错。\nReAct找到了一个中间地带，通过推理提供了足够的结构，同时通过迭代行动保持了灵活性。\n\n#### 4. 规划模式（Planning Pattern）\n\n规划模式与ReAct采用了不同的方法，它强调在执行开始之前进行前期的战略性思考。\n\n使用规划模式时，智能体首先分析总体目标并理解成功的样子。然后，它将这个目标分解为更小、更易于管理的子任务。这种分解一直持续，直到智能体识别出具体的、可操作的步骤。\n\n至关重要的是，智能体识别任务之间的依赖关系，确定哪些步骤必须在其他步骤开始之前完成，以及哪些步骤可以并行进行。智能体还会考虑每个步骤需要哪些资源、工具或信息。只有在创建了这个结构化计划之后，智能体才开始执行。\n\n请参见下图：\n（此处原文有图示，表示智能体接收目标 -> 计划（分解任务、识别依赖、分配资源） -> 执行 -> 观察并反馈给计划阶段的循环）\n\n规划模式的关键优势之一是自适应规划。\n\n规划模式最适用于具有自然阶段或步骤的任务，其中某些活动在逻辑上先于其他活动。它对于具有截止日期、预算或资源限制等约束条件，并且协调至关重要的任务很有价值。它在错误或回溯成本高昂的情况下表现出色，这使得投入时间进行周密规划是值得的。涉及多个工作流的复杂项目从规划中受益匪多。\n\n然而，规划模式也有局限性：\n\n对于简单、线性任务，其中每个步骤自然地暗示下一个步骤，创建正式计划的开销几乎没有益处。\n对于高度不确定的任务，我们很可能在执行过程中发现根本性改变方法的重要信息，此时广泛的前期规划可能只是浪费精力。\n\n#### 5. 多智能体模式（Multi-Agent Pattern）\n\n多智能体模式可能代表了构建AI系统最复杂的方法。\n\n这种模式不依赖单一智能体处理所有事情，而是使用多个专业智能体协同完成任务。每个智能体都具有特定的专业知识、能力或视角，它们像人类团队一样协同工作。\n\n多智能体系统背后的核心洞察是，专业化通常比泛化带来更好的性能。\n\n一个试图在所有方面都表现出色的单一智能体面临挑战。它必须在其设计和训练中平衡相互竞争的需求。它需要广泛的知识，但也需要深入的专业知识。它必须富有创造力，但也必须具有批判性。通过在多个智能体之间划分职责，每个智能体都可以针对其特定角色进行优化。\n\n在多智能体系统中，我们通常会看到几种类型的角色：\n\n有专注于特定领域或任务的专业智能体，例如擅长查找和综合信息的**研究智能体**、优化代码编写和调试的**编码智能体**，或擅长统计分析和可视化的**数据分析智能体**。\n通常还有**评论者或审查智能体**，其工作是评估其他智能体的输出，识别缺陷、提出改进建议或验证质量。\n通常有一个**协调者或编排者智能体**，管理整个工作流，决定哪个专家应该处理每个子任务，并确保所有部分连贯地组合在一起。\n\n多智能体模式引入了复杂的权衡：\n\n协调开销随着智能体数量的增加而增加。\n智能体之间的通信需要清晰的协议。\n调试变得更具挑战性，因为问题可能来自智能体之间的交互，而不是单个智能体的错误。\n\n收益必须证明这些成本是合理的。对于简单任务，一个有能力的单一智能体几乎总是更好的选择。对于需要多样化专业知识、细致协调或多重视角的复杂任务，多智能体方法尽管增加了复杂性，但通常会产生卓越的结果。\n\n### 结论\n\n各种智能体工作流模式代表了我们构建和部署AI系统的根本性演进。\n\n从简单的提示词驱动到复杂的迭代过程，这转变了AI智能体能够可靠完成的任务。以下是我们涵盖的模式的快速总结：\n\n*   **反思模式**通过自我改进确保质量。\n*   **工具使用**将能力扩展到纯语言生成之外。\n*   **ReAct**将周密的推理与自适应行动相结合。\n*   **规划**为复杂任务带来战略性思维。\n*   **多智能体协作**利用专业化和多样化的视角。\n\n这些模式共同为构建能够处理真实世界复杂性的AI系统提供了强大的工具包。\n\n这些模式之所以特别强大，是因为它们并非相互排斥。最复杂的智能体系统通常会结合多种模式来实现其目标。\n\n---\n\n### 要点总结\n\n*   **超越单轮交互**：智能体工作流将AI互动从简单的单轮提示词响应，转变为迭代、自适应、具备工具集成的问题解决过程。\n*   **核心特性**：智能体工作流具有自主性、决策能力、适应性，并通过内置的迭代和反馈循环来模仿人类解决复杂问题的方式。\n*   **反思模式（Reflection）**：智能体审查和批判自身输出，并进行迭代改进，以提升结果质量和准确性。\n*   **工具使用模式（Tool Use）**：通过集成外部工具（如搜索引擎、API、代码解释器），智能体能超越其训练数据的限制，获取最新信息并执行特定操作。\n*   **推理与行动模式（ReAct）**：智能体在明确的推理和实际行动之间交替进行，根据观察到的结果动态调整策略，提供透明的决策路径。\n*   **规划模式（Planning）**：在执行前进行全面的战略规划，将目标分解为子任务，识别依赖关系，并分配资源，适用于需要预先协调和避免高成本错误的复杂项目。\n*   **多智能体模式（Multi-Agent）**：通过多个专业化智能体（如研究员、编码员、评论者、协调者）的协作，利用各自专长，共同解决复杂任务，实现比单一智能体更优异的性能。\n*   **能力提升**：这些模式显著提高了AI系统处理复杂任务的可靠性、质量和广度。\n*   **模式组合**：文章中提到的各种模式并非相互排斥，最先进的AI系统通常会组合使用多种模式来达到更精细、更强大的目标。\n*   **选择依据**：选择合适的工作流模式取决于任务的复杂性、对速度和质量的要求以及对错误容忍度等因素。\n\n### 你可以从这篇文章学到什么\n\n对于具有数年经验的后端/系统设计工程师而言，这篇文章提供了关于AI智能体工作流的深刻见解，这些概念不仅限于AI领域，对设计和构建任何复杂的分布式系统都具有重要的启发意义和实际应用价值：\n\n1.  **AI集成的新范式**：你将意识到，将AI能力集成到现有系统中远不止调用一个大模型API那么简单。智能体工作流提供了一套强大的结构化方法，让AI能够更智能、更可靠地执行复杂任务，这对于设计企业级AI应用至关重要。\n\n2.  **系统设计层面的思考**：\n    *   **编排层（Orchestration Layer）**：ReAct、规划和多智能体模式都强调了对复杂任务进行拆解、调度和协调的重要性。这直接对应了后端系统中构建工作流引擎、任务调度器或微服务编排器的需求。你需要设计一个高效、可扩展的编排层来管理智能体的状态、工具调用和决策流程。\n    *   **工具集成与安全性**：工具使用模式要求智能体能够安全、高效地调用外部工具（如数据库、内部API、第三方服务）。这引发了对API网关、统一认证授权、速率限制、服务发现和容错机制的设计思考。如何让智能体以受控的方式访问和操作外部资源，同时保证数据安全和系统稳定性，是后端工程师的核心职责。\n    *   **状态管理与持久化**：智能体在迭代过程中需要维护上下文信息。这意味着你需要设计合适的数据存储方案（关系型数据库、NoSQL、缓存），以持久化智能体的历史记录、决策路径和中间结果，这对于调试、审计和恢复至关重要。\n    *   **可观测性与调试**：ReAct模式中明确的“思考”步骤，以及反思模式中的自我批判，为系统提供了宝贵的“审计日志”和“决策路径”。作为后端工程师，你可以利用这些思想，在设计系统时内建更强的日志记录、追踪和监控机制，以便在复杂分布式系统中定位问题、理解行为。\n    *   **弹性与错误处理**：智能体工作流的迭代性质意味着它需要处理工具调用失败、外部服务异常或自身推理错误的情况。这要求你在系统设计中融入更强的错误恢复、重试机制和回退策略，提升整个系统的韧性。\n\n3.  **实际项目应用**：\n    *   **智能自动化平台**：你可以设计一个智能自动化平台，利用规划模式分解复杂的业务流程（例如，自动化报告生成、数据清理、部署流程），然后使用工具使用模式集成各种企业内部系统和外部服务。\n    *   **高级智能客服或运维助手**：通过多智能体模式，你可以构建一个客服系统，其中包含一个意图识别智能体、一个知识库检索智能体、一个回复生成智能体和一个审核智能体，协同工作以提供更准确、更个性化的服务。在运维场景中，智能体可以使用ReAct模式诊断系统故障（调用监控API）、查找解决方案（搜索知识库）、甚至执行修复操作（调用自动化部署或脚本执行工具）。\n    *   **数据驱动的决策支持系统**：利用反思模式和工具使用模式，开发能够自动分析大量数据、生成报告并自我审查报告准确性和完整性的系统，为商业决策提供更可靠的洞察。\n\n总之，这篇文章不仅仅是关于AI，更是关于如何设计更智能、更自适应的系统。它鼓励你将大模型视为一个可编程的、具备推理能力的组件，而不是一个简单的黑盒API。作为系统设计者，理解这些智能体模式，将帮助你构建下一代更加健壮、灵活且具备高度自动化能力的软件系统。",
    "url": "https://blog.bytebytego.com/p/top-ai-agentic-workflow-patterns"
  },
  {
    "id": "2025-12-16-how-linkedin-built-an-ai-powered-hiring-assistant",
    "title": "How LinkedIn Built an AI-Powered Hiring Assistant",
    "date": "2025-12-16",
    "preview": "LinkedIn 如何打造一个 AI 驱动的招聘助手 ByteByteGo 2025年12月16日  116 2 3 分享  **为你的应用解决企业级认证、身份和安全问题（赞助内容）** 企业客户期望获得 SSO（单点登录）、Directory Sync（目录同步）、RBAC（基...",
    "content": "LinkedIn 如何打造一个 AI 驱动的招聘助手\nByteByteGo\n2025年12月16日\n\n116\n2\n3\n分享\n\n**为你的应用解决企业级认证、身份和安全问题（赞助内容）**\n企业客户期望获得 SSO（单点登录）、Directory Sync（目录同步）、RBAC（基于角色的访问控制）和 Audit Logs（审计日志）等功能，但构建和维护这些基础设施会拖慢团队进度，并使其偏离核心产品工作。\nWorkOS 通过简单的 API 和托管的 Admin Portal（管理门户）提供这些功能，可与所有身份提供商集成。你无需自行承担复杂性，即可获得生产就绪的企业级能力。\n深受 OpenAI、Cursor、Vercel 等 1000 多家公司的信赖。首一百万 MAU（月活跃用户）免费。\n立即添加企业功能 →\n\n免责声明：本文中的细节来源于 LinkedIn 工程团队在线分享的信息。所有技术细节的功劳均归于 LinkedIn 工程团队。原文链接和来源可在文章末尾的参考文献部分找到。我们试图分析这些细节并提供我们的见解。如果您发现任何不准确或遗漏之处，请留言，我们将尽力纠正。\n\n招聘是一项需要战略思维和一丝不苟的细节关注的职业。招聘人员必须就哪些候选人最适合某个职位做出高价值的决策，但他们也花费无数小时在重复性的模式识别任务上。筛选数百份简历，根据职位要求评估资质，以及起草个性化的外联信息，这些都是必不可少的活动。然而，它们也消耗了大量时间，这些时间本可以用于建立关系和做出战略性招聘决策。\n\nLinkedIn 的 Hiring Assistant 代表了一种解决这一挑战的新方法。\n这个 AI 代理旨在处理招聘工作流程中重复、耗时的方面，而不是取代招聘人员，从而让专业人士能够专注于他们最擅长的事情：与人建立联系并做出关键的招聘选择。\n\n招聘中最劳动密集的部分分为三大类。\n首先，Sourcing candidates（搜寻候选人）需要在 LinkedIn 超过 12 亿个资料的网络中搜索，以识别符合条件的个人。\n其次，Evaluating candidates（评估候选人）涉及仔细阅读简历和资料，以评估每个人是否符合职位的具体要求。\n第三，Engaging candidates（联系候选人）意味着起草并发送个性化信息给潜在雇员，回答他们的问题，并在整个招聘过程中保持持续对话。\n\n为了应对这些挑战，LinkedIn 构建了具有三个核心能力的 Hiring Assistant。\n该系统通过高效搜索数十亿份资料并可靠处理企业级工作负载，实现大规模价值交付。\n它通过自然对话理解招聘人员意图，在需要时提出澄清问题，并根据实时反馈调整其行为，从而实现 Interactive communication（交互式沟通）。\n最后，它还具有 Continuous learning（持续学习）能力，通过观察招聘人员的行为、学习个人偏好并记住过去的互动和决策，随着时间的推移不断改进。\n\n在本文中，我们将深入探讨 LinkedIn Hiring Assistant 的架构和技术构建块。\n\n**Verizon 节日季倾情奉献：优惠多多，精心设计（赞助内容）**\n这个节日季，等式很简单：每个人都能在 Verizon 获得更好的优惠。最好的设备。最好的套餐。再加上屡获殊荣的网络，你就能得到最好的优惠。就是这样。\n**无与伦比的优惠**：转用 Verizon，四条线路享受 Unlimited Welcome 套餐，每条线路每月 25 美元（通过 Auto Pay 支付，另加税费），并可获得四台最新的高端设备，如 iPhone 17 Pro、Samsung Galaxy S25+ 或 Google Pixel 10 Pro XL，全部来自 Verizon。\n在这个节日季享受灵活性并节省开支，因为你花的每一分钱都至关重要。\n探索节日优惠。查看此处了解完整条款。\n\n### 高层架构\n\nHiring Assistant 的核心建立在 LinkedIn 所谓的 “plan-and-execute”（规划与执行）架构之上，如下图所示：\n\n为了理解这为什么重要，了解他们避免了什么会有所帮助。一种更简单的方法，称为 ReAct，会让 AI 尝试在一个单一的连续循环中处理所有事情。虽然直接，但当任务变得复杂时，这种方法会遇到问题。大型语言模型（驱动此类工具的 AI 系统）在被要求同时处理太多事情时会变得不可靠。\n\nReAct 模式如下图所示。\n\n相反，LinkedIn 将工作拆分为两个不同的阶段：\n\n**The Planner** 充当战略思想家。当招聘人员提出请求时，Planner 从高层审视它，将工作分解为更小、更易于管理的步骤，并创建一个结构化的计划，说明需要完成什么。可以将其视为项目经理在实际工作开始前概述方法。\n\n**The Executor** 随后接管。它一步一步地执行计划，使用可用的工具完成每个任务。对于每个步骤，Executor 运行自己的推理和行动循环，找出需要做什么，然后使其发生。\n\n这种分而治之的策略带来了几个优势：\n首先，它使系统更加可靠。将复杂的招聘工作流分解为离散的步骤意味着 AI 混淆或犯错的可能性更小。\n其次，它允许更好的成本管理。LinkedIn 可以为复杂的推理任务使用更强大的 AI 模型，同时为简单的步骤部署更简单、更便宜的模型。\n第三，当任务定义明确且范围可控时，它们成功完成的可能性会大得多。\n\n除了 plan-and-execute 设计之外，Hiring Assistant 还使用 message-driven architecture（消息驱动架构）。\n每位招聘人员都拥有自己的独立助手实例，并配有自己的身份和邮箱。所有工作都通过 asynchronous messages（异步消息）进行，非常像电子邮件。当招聘人员要求助手查找候选人时，他们不必坐着等待结果。助手收到消息，在后台处理，并在准备就绪时发送更新。\n\n这种异步方法使助手能够大规模运行。当招聘人员专注于其他任务时，他们的助手可以在后台搜索数百万份资料，评估候选人，并准备推荐，所有这些都无需持续的关注或监督。\n\n### 代理用户体验 (Agentic User Experience)\n\nHiring Assistant 以两种互补模式运行，每种模式都针对招聘过程的不同阶段设计：\n\n**交互模式 (Interactive Mode)**：\n当招聘人员首次启动新项目时，他们会与助手在交互模式下工作。这感觉就像与同事交谈一样。招聘人员可以澄清他们正在寻找什么样的人，细化职位要求，并获得对其请求的即时反馈。助手在工作时会展示其推理过程，使过程透明化。这建立了信任，因为招聘人员可以确切地看到系统正在做什么，并在出现问题时迅速纠正。\n\n**异步模式 (Asynchronous Mode)**：\n一旦招聘人员和助手就成功标准达成一致，系统就会切换到异步模式。这就是自动化真正发挥作用的地方。助手在后台自主工作，在数百万份资料中进行大规模搜索，持续更新候选人管道，并在新申请人出现时进行评估。\n\nLinkedIn 将其描述为一种 “source while you sleep”（在你睡觉时进行招聘）的能力。\n助手可以在一夜之间审查数千名候选人，这项任务如果由人工招聘人员手动完成，将需要数周时间。\n然而，即使在这种自主模式下，人类仍然控制着重要的决策。助手筛选候选人并提供推荐，但招聘人员最终决定联系谁以及最终录用谁。这种自动化与人类判断之间的平衡是系统设计的核心。\n\n### 技术构建块\n\nHiring Assistant 建立在 LinkedIn 更广泛的 agent platform（代理平台）之上，这是一个可为公司内任何 AI 代理产品提供动力的可复用组件基础。这种方法意味着 LinkedIn 工程团队在每次构建新的智能系统时不必重复造轮子。\n\n在用户界面层面，client-side SDK（客户端软件开发工具包）将助手直接嵌入到招聘人员的工作流中。该 SDK 创建动态界面，根据 AI 在任何给定时刻的需求进行调整。它支持多种输入方法，包括聊天、语音和打字辅助，同时记录所有交互以供未来分析和改进。\n\n连接此界面到后端服务的是 GraphQL API，它以结构化包（称为 view models）的形式交付数据。这些包包含了在屏幕上显示信息所需的一切。LinkedIn 将其称为 agent-driven UI（代理驱动的用户界面），其中 AI 本身可以决定招聘人员看到什么，随着任务的进展动态调整界面。\n\n该系统不采用传统的 request-response pattern（请求-响应模式），即你提出问题并等待答案，而是使用 push-based, event-driven architecture（推播式、事件驱动架构）。其工作原理如下：\n用户界面订阅来自代理的更新，当有变化时，代理会发布该更新。这意味着界面会自动刷新，用户无需手动重新加载任何内容。\n长时间运行的 AI 任务通过 streaming responses（流式响应）交付。招聘人员无需等待完整答案，而是可以实时看到 AI 的推理过程，结果一经可用即显示。\n如果招聘人员在多台设备上登录，cross-session synchronization（跨会话同步）可保持所有内容同步。在手机上采取的行动会立即反映在桌面浏览器上。\n\n### 监督代理 (The Supervisor Agent)\n\nHiring Assistant 的核心是 LinkedIn 所称的 supervisor agent（监督代理）。如果整个系统是一个团队，那么监督代理就是确保每个人有效协作的团队领导。\n\n如下图所示：\n\n监督代理承担着几项关键职责：\n它负责整个招聘过程的 workflow management（工作流管理），确保任务按正确的顺序进行。\n当招聘人员发送消息或请求时，监督代理接收并将其路由到适当的 sub-agent（子代理）进行处理。\n它还会对 task prioritization（任务优先级）做出判断，决定哪些需要人工输入，哪些可以安全地自动化。\n除了委托工作之外，监督代理还在不同的子代理之间进行 coordination（协调），以确保它们顺利协作。它积极观察环境，关注新的候选人活动或申请提交等变化，并触发相应的行动。\n监督代理还管理系统的 human-in-the-loop（人工干预）方面。它知道哪些决策足够重要需要人工批准，并将这些时刻呈现给招聘人员。\n所有通信，无论是来自用户还是子代理之间，都通过监督代理。它充当中央枢纽，使整个操作有条不紊，并与招聘人员的目标保持一致。\n\n### 专业化子代理 (The Specialized Sub-Agents)\n\nHiring Assistant 将招聘工作分配给多个 specialized sub-agents（专业化子代理），每个代理专注于工作流程的特定部分。这种模块化设计允许每个组件在其特定任务上表现出色，同时作为一个有凝聚力的系统协同工作。让我们详细了解各种子代理：\n\n** Intake Agent（摄取代理）**\n摄取代理是每个招聘项目的起点。\n它从招聘人员那里收集职位要求，确认诸如职位名称、地点和资历水平等基本细节。当信息缺失时，代理会利用 LinkedIn 的 Economic Graph（经济图谱）智能地填补空白。然后，代理会根据成功的过往招聘和行业知识生成具体的资质要求，为评估候选人创建一个清晰的框架。\n\n**Sourcing Agent（搜寻代理）**\n找到合适的候选人可能是招聘中最知识密集的部分，搜寻代理通过多种策略应对这一挑战。\n它使用传统的 Boolean logic（布尔逻辑，即 AND、OR、NOT 运算符）创建搜索查询，根据招聘要求生成 AI 驱动的查询，并借鉴历史招聘人员搜索模式作为起点。重要的是，客户数据绝不会跨越公司边界，保持严格的数据隔离。\n\n使该代理脱颖而出的是其与 LinkedIn Economic Graph 的集成。\n这使其能够访问有关特定人才库的顶级地点、职位名称和技能的洞察。它可以识别哪些候选人正在积极寻找工作或最近被录用，了解公司和行业之间的人才流动模式，发现快速增长的公司和技能组合，标记正在裁员的公司，并突出顶尖学校或有空缺职位的公司的机会。这些洞察帮助代理找到那些可能被忽视的“隐藏宝石”，远远超出了简单的关键词匹配。\n搜寻代理还实现了一个 closed feedback loop（闭环反馈）。它将搜寻与评估结果结合起来，使用 AI 推理根据哪些候选人被证明是良好匹配来优化查询。这使得系统能够在精度（找到完全合适的候选人）与流动性（找到足够多的候选人）之间取得平衡，随着时间的推移不断提高结果的质量和数量。\n\n**Evaluation Agent（评估代理）**\n阅读简历和评估资质是招聘人员最耗时的任务之一。\n评估代理通过阅读候选人资料和简历，将其与职位资质进行比较，并提供有证据支持的结构化推荐来解决这一问题。它会展示候选人可能符合或不符合要求的原因，而不仅仅是提供是或否的答案。\n\nLinkedIn 设计此代理以解决几个复杂的挑战。\n在任何评估开始之前，招聘人员必须审查并批准所使用的资质要求。\nSafety checks（安全检查）确保这些资质符合负责任的 AI 政策。代理会在资料和简历中搜索具体的证据，证明候选人如何满足每项资质，并将这些证据呈现给招聘人员进行审查。\n为了确保准确性，LinkedIn 建立了质量基准，用于在不同场景下测试评估代理。\n他们开发了专门针对资质评估优化的 custom AI models（自定义 AI 模型），因为通用模型无法实现必要的准确性和速度组合。通过使用 speculative decoding（推测解码）和 custom serving infrastructure（自定义服务基础设施）等技术，这些精细调整的模型可以在几秒钟而不是几分钟内评估候选人，速度足以支持实时、对话式的要求细化。\n\n**Candidate Outreach Agent（候选人外联代理）**\n一旦识别出有前景的候选人，外联代理就会处理沟通。\n它会撰写个性化消息，发送初始外联和跟进，并使用在摄取阶段定义的特定职位 FAQ 回复候选人问题。该代理甚至可以直接通过消息安排电话面试，简化协调工作。\n\n**Candidate Screening Agent（候选人筛选代理）**\n为了支持面试过程，筛选代理会根据招聘要求和候选人资料准备定制的面试问题。\n它可以转录和总结筛选对话，同时记录笔记和见解。重要的是，招聘人员保持完全控制，可以随时接管对话或根据需要引导过程。\n\n**Learning Agent（学习代理）**\n学习代理使系统能够随着时间的推移而改进。\n它分析招聘人员的行为，例如他们给哪些候选人发消息或添加到管道中，从显式反馈和隐式行为信号中学习。代理会根据这些模式更新职位资质，但任何建议的更改都必须由招聘人员审查并批准才能应用。这确保了助手在适应的同时，人类始终掌控大局。\n\n**Cognitive Memory Agent（认知记忆代理）**\n最后，认知记忆代理赋予助手跨互动持久的记忆能力。\n它会记住过去的对话、偏好和决策，有助于随着时间的推移进行个性化推荐。所有记忆数据都限制在个人招聘人员的环境中，并有严格的隐私保护。\n这些数据绝不会用于训练 AI 模型，确保客户信息安全保密。\n\n### 质量支柱 (The Quality Pillars)\n\n构建一个能够大规模运行的 AI 代理需要一种全面的质量方法，以确保系统安全、负责任且有效地运行。\nLinkedIn 工程团队将其质量框架建立在两个互补的支柱之上：\n\n**1 - 护栏 (The Rails)**\n产品政策充当使系统保持正轨的护栏。这些政策为安全、合规和法律标准设定了明确的界限，同时定义了预期的代理行为。它们建立了必须达到的最低质量阈值。\n为了执行这些标准，LinkedIn 采用了 AI-powered judges（AI 驱动的评判器）来评估质量的不同方面。一些评判器检查 coherence（连贯性），询问输出是否符合逻辑。另一些则验证 factual accuracy（事实准确性），确保系统不会生成虚假或误导性信息。\n\n**2 - 指南针 (The Compass)**\nHuman alignment（人类校准）充当指南针，确保助手朝着真正有价值的结果前进。\n这个支柱建立在 human-validated data（人类验证数据）之上，包括人们标注示例的 annotated datasets（标注数据集）和真实的招聘人员活动。当招聘人员向候选人发送消息或将其添加到管道时，系统将其视为强烈的积极信号。\n随着时间的推移，助手学会推荐与这些招聘人员验证模式相匹配的候选人。人类校准还有助于验证产品政策是否在实践中真正起作用。\n\n### 结论\n\nLinkedIn 的 Hiring Assistant 展示了构建企业级 AI 代理的宏大方法。\n通过采用 plan-and-execute 架构，系统将复杂的招聘工作流分解为可管理的步骤，提高了可靠性并减少了错误。消息驱动设计允许每个招聘人员拥有自己的助手实例，在后台异步工作，实现真正的规模化。\n专业化子代理之间的分工确保每个组件都能专注于其最擅长的任务，从搜寻和评估到外联和筛选。与 LinkedIn Economic Graph 的集成提供了超越简单关键词匹配的市场情报，有助于发现可能被忽视的候选人。\n也许最重要的是，该系统在自动化与人类判断之间取得了平衡。质量框架确保助手安全，并与实际招聘结果保持一致，而学习代理则根据个人招聘人员的偏好确保持续改进。\n\n参考文献：\n[Building the agentic future of recruiting: how we engineered LinkedIn’s Hiring Assistant](https://www.linkedin.com/posts/linkedin-engineering_building-the-agentic-future-of-recruiting-activity-7132924197479714816-G42P)\n[Under the hood: The tech behind the first agent from LinkedIn](https://www.linkedin.com/posts/linkedin-engineering_under-the-hood-the-tech-behind-the-first-activity-7132924200792078336-M9-F)\n[The LinkedIn Generative AI Application Tech Stack](https://www.linkedin.com/posts/linkedin-engineering_the-linkedin-generative-ai-application-tech-activity-7132924194031640576-8H0s)\n\n赞助我们\n让您的产品呈现在超过 1,000,000 名技术专业人士面前。\n我们的新闻通讯将您的产品和服务直接呈现在一个重要的受众面前——数十万工程领导者和高级工程师——他们对重要的技术决策和重大采购拥有影响力。\n广告位快速售罄 - 立即预订\n广告位通常提前约 4 周售罄。为确保您的广告能够触达这个有影响力的受众，请立即通过电子邮件 sponsorship@bytebytego.com 预订您的位置。\n\n116\n2\n3\n分享\n\n---\n\n### 要点总结\n\n*   **痛点与解决方案**：招聘人员面临大量重复性任务，LinkedIn 的 Hiring Assistant 旨在通过 AI 代理自动化这些耗时环节，使招聘人员专注于高价值的人际互动和战略决策。\n*   **核心能力**：系统具备大规模运行、交互式沟通（理解意图、提问、适应反馈）和持续学习（观察、学习偏好、记忆交互）的能力。\n*   **“规划与执行”架构**：采用 Planner（规划者）和 Executor（执行者）两阶段模式，将复杂任务分解为可管理步骤，提高可靠性、降低成本，并确保任务成功，避免了 ReAct 等更简单的单循环模式的局限性。\n*   **消息驱动与异步处理**：每个招聘人员拥有独立助手实例，所有交互通过异步消息进行。这种设计实现了大规模并发处理，允许助手在后台处理耗时任务，而用户无需等待。\n*   **交互与异步工作模式**：系统在项目初期提供透明的交互模式（对话式澄清），达成共识后切换到高效的异步模式（例如“在你睡觉时进行招聘”），实现大规模自动化，但关键决策仍由人工控制。\n*   **代理平台与模块化**：Hiring Assistant 构建在 LinkedIn 通用的 agent platform（代理平台）之上，并通过 client-side SDK、GraphQL API 和 agent-driven UI 等技术栈，实现动态界面和事件驱动的实时数据流。\n*   **监督代理 (Supervisor Agent)**：作为中央协调者，负责工作流管理、任务路由、优先级判断、子代理间协调，并管理 human-in-the-loop（人工干预）决策点。\n*   **专业化子代理**：系统由 Intake（摄取）、Sourcing（搜寻）、Evaluation（评估）、Outreach（外联）、Screening（筛选）、Learning（学习）和 Cognitive Memory（认知记忆）等多个专业化子代理组成，各司其职，协同完成复杂任务。\n*   **智能数据集成**：Sourcing Agent 深度整合 LinkedIn 的 Economic Graph（经济图谱），提供超越关键词匹配的洞察力，如人才流动、公司裁员、高增长领域等，发现“隐藏的宝石”。\n*   **质量保障双支柱**：通过“护栏”（产品政策、AI 评判器，确保安全与合规）和“指南针”（人类校准、人类验证数据，确保价值与效用）双重机制，保障 AI 代理的负责任和有效运行。\n\n### 你可以从这篇文章学到什么\n\n作为一名后端/系统设计工程师，LinkedIn Hiring Assistant 的设计思路和技术实践为我们提供了宝贵的学习机会，并可以在实际项目中得到应用：\n\n1.  **复杂系统分层与解耦（Agentic Architecture）**：\n    *   **学习点**：文章详细介绍了“规划与执行”架构，以及 Supervisor Agent 和 Specialized Sub-Agents 的设计。这种将复杂任务分解为战略规划（Planner/Supervisor）和具体执行（Executor/Sub-Agents）的模式，极大提升了系统的可靠性、可维护性和可扩展性。\n    *   **应用**：当你面对一个涉及多步骤、复杂逻辑和多种外部工具（或微服务）调用的系统时，不要试图在一个单一服务或组件中处理所有事情。可以考虑引入一个“调度层”或“编排器”（类似 Supervisor Agent），它负责接收用户请求，将其分解为一系列子任务，并分配给专门的“执行层”或“功能服务”（类似 Specialized Sub-Agents）。这有助于实现模块化、提高容错能力，并且可以针对不同复杂度的任务使用不同资源消耗的 AI 模型。\n\n2.  **大规模异步处理与实时用户体验**：\n    *   **学习点**：Hiring Assistant 采用 message-driven architecture 和异步消息处理，结合 streaming responses 和 push-based, event-driven architecture 提供实时更新。这使得系统能够在后台处理长时间运行的任务，同时保持前端的响应性和互动性。\n    *   **应用**：在设计需要长时间运行的后台任务（如数据分析、AI 推理、批量处理）的系统时，异步通信（消息队列如 Kafka, RabbitMQ）是核心。为了提供良好的用户体验，结合 WebSocket 或 Server-Sent Events (SSE) 等技术实现实时状态更新和流式结果展示，而不是让用户等待一个完整的同步响应。\n\n3.  **Human-in-the-Loop 的设计理念**：\n    *   **学习点**：文章多次强调了人类在 AI 系统中的控制权和决策权。无论是招聘人员审核资质、最终决定候选人，还是学习代理需要人工批准才能更新资质，都体现了“人工干预”的重要性。质量支柱中的“指南针”也强调了人类校准的重要性。\n    *   **应用**：在构建任何 AI 驱动的企业级应用时，不要盲目追求 100% 自动化。设计明确的接口和流程，允许人类进行审查、批准、修正和提供反馈。这不仅能提高系统的可靠性和信任度，还能为 AI 模型提供持续的训练数据和优化方向。将人类决策点作为系统的一部分进行建模，而不是视为异常处理。\n\n4.  **数据与 AI 的深度融合**：\n    *   **学习点**：Sourcing Agent 通过与 LinkedIn Economic Graph 的深度集成，提供了超越传统关键词匹配的智能搜寻能力。这表明 AI 代理的效能不仅仅取决于模型本身，更取决于其能够访问和利用的数据的广度和深度。\n    *   **应用**：在设计 AI 系统时，除了考虑 AI 模型和算法，更要深入思考如何有效整合公司内部的结构化数据、知识图谱、历史操作数据以及外部数据源。将这些丰富的数据作为 AI 代理的“上下文”和“知识库”，可以显著提升其理解、推理和决策能力。\n\n5.  **系统质量与负责任 AI (Responsible AI) 的框架**：\n    *   **学习点**：LinkedIn 提出了“护栏”和“指南针”的质量双支柱，分别从政策合规、安全性和人类价值对系统进行约束和引导。\n    *   **应用**：在系统设计初期就应考虑如何构建一个负责任的 AI 系统。为 AI 模型的输出设计明确的验证机制（例如 AI judges 进行一致性、准确性检查），制定严格的产品政策和行为边界（护栏）。同时，通过持续的用户反馈、行为分析和人类验证数据（指南针），确保 AI 系统真正创造价值并与业务目标保持一致。",
    "url": "https://blog.bytebytego.com/p/how-linkedin-built-an-ai-powered"
  }
]