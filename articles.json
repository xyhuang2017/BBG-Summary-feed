[
  {
    "id": "2025-12-17-how-meta-built-a-new-ai-powered-ads-model-for-5-better-conversions",
    "title": "How Meta Built a New AI-Powered Ads Model for 5% Better Conversions",
    "date": "2025-12-17",
    "preview": "Meta 如何构建新的 AI 驱动广告模型以实现 5% 的转化率提升 ByteByteGo  当 Meta 在 2025 年第二季度宣布其新的生成式广告模型 (GEM) 使 Instagram 的广告转化率提高了 5%，Facebook Feed 提高了 3% 时，这些数字可能看...",
    "content": "Meta 如何构建新的 AI 驱动广告模型以实现 5% 的转化率提升\nByteByteGo\n\n当 Meta 在 2025 年第二季度宣布其新的生成式广告模型 (GEM) 使 Instagram 的广告转化率提高了 5%，Facebook Feed 提高了 3% 时，这些数字可能看起来不大。\n\n然而，在 Meta 的规模下，这些百分比意味着数十亿美元的额外收入，并代表了 AI 驱动广告运作方式的根本性转变。\n\nGEM 是有史以来为推荐系统构建的最大基础模型。它的训练规模通常只用于像 GPT-4 或 Claude 这样的大型语言模型。然而，悖论在于：GEM 如此强大且计算密集，以至于 Meta 实际上无法直接使用它来向用户提供广告。\n\n相反，该公司开发了一种教师-学生架构，让更小、更快的模型能够从 GEM 的智能中获益，而无需继承其计算成本。\n\n在本文中，我们将探讨 Meta 工程团队如何构建 GEM 以及他们克服的挑战。\n\n## GEM 解决的核心问题\n\n每天，数十亿用户滚动浏览 Facebook、Instagram 和其他 Meta 平台，产生数万亿潜在的广告展示机会。每一次展示都代表一个决策点：从数百万种可能性中，应该在特定时刻向特定用户展示哪个广告？做错了，就意味着浪费广告商预算在不相关的广告上，并用用户不关心的内容惹恼他们。做对了，就能为所有相关方创造价值。\n\n传统的广告推荐系统在几个方面都面临挑战。一些系统将每个平台独立对待，这意味着关于用户在 Instagram 上行为的洞察无法用于 Facebook 上的预测。这种孤立的方法错失了有价值的跨平台模式。其他系统试图将所有平台同等对待，却忽略了人们与 Instagram Stories 互动的方式与他们浏览 Facebook Feed 的方式截然不同。这两种方法都不是最优的。\n\n数据复杂性也通过以下方式加剧了这些挑战：\n\n*   与总展示量相比，点击和转化等有意义的信号极其稀疏。\n*   用户特征是动态且不断变化的。\n*   系统必须处理多模态输入，包括文本、图像、视频和复杂的行为序列。\n*   传统模型存在严重的内存限制，通常只考虑用户最近 10 到 20 个行为。\n\nGEM 的目标是创建一个统一智能，在 Meta 的整个生态系统中全面理解用户，从长期的行为历史和复杂的跨平台模式中学习，同时保持针对每个具体界面和目标进行优化所需的细微差别。\n\n## GEM 如何理解用户？\n\nGEM 的架构通过三个互补系统处理用户和广告信息，每个系统处理预测问题的不同方面。\n\n第一个系统处理 Meta 所谓的非序列特征，这本质上是静态属性及其组合。这些包括用户人口统计信息（如年龄和位置）、用户兴趣、广告特征（如格式和创意内容）以及广告商目标。\n\n这里的挑战不仅在于了解这些单独的特征，还在于理解它们如何相互作用。例如，一个 25 岁的科技工作者与一个 25 岁的教师有非常不同的购买模式，即使他们有一些共同的兴趣。系统需要学习哪些特征组合真正重要。\n\nGEM 使用 Wukong 架构的增强版，该架构带有可堆叠因子分解机 (stackable factorization machines)，可以垂直扩展以实现更深层次的交互，也可以水平扩展以实现更广泛的特征覆盖。该架构通过多个堆叠层工作，其中每个后续层从前一层发现的更简单模式中学习日益复杂的模式。例如，早期层可能发现年轻专业人士对科技产品广告反应良好这一基本模式。堆栈中更深一层则在此基础上学习到，城市地区对健身感兴趣的年轻专业人士对智能可穿戴设备广告反应尤其好。更深一层可能会进一步细化这一点，发现这种组合在广告强调数据跟踪功能而非时尚元素时效果最佳。\n\n第二个系统处理序列特征，它捕捉用户行为的时间线。用户的行为并非孤立存在，它们以顺序和意义讲述一个故事。一个用户先点击了家庭健身内容，然后搜索附近的健身房，接着浏览了几个健身房网站，然后研究了会员费，这显然是在进行一次特定的旅程。传统架构难以有效地处理长序列，因为计算成本随序列长度快速增长。\n\nGEM 通过金字塔并行结构克服了这一点。可以将其想象成在底层分块处理你的行为历史，然后将这些分块组合成中间层更广泛的模式，最后在顶层将所有信息合成，形成完整的旅程理解。多个分块可以同时处理而非顺序处理，这显著提高了效率。\n\n这里的突破是规模。GEM 现在可以分析你过去数千个行为，而不仅仅是最近的几个。这种扩展视图揭示了更短窗口根本无法捕捉到的模式，例如从随意兴趣到认真购买意图的渐进发展，这可能需要数月时间。\n\n请参见下图：\n(原文配图，此处省略)\n\n第三个系统，名为 InterFormer，通过连接你的静态画像和行为时间线来处理跨特征学习。这正是 GEM 智能真正显现的地方。以前的方法会将你的整个行为历史压缩成一个紧凑的摘要向量（就像将一部完整的小说缩减为单一评分）。这种压缩不可避免地会丢失你旅程中的关键细节。\n\nInterFormer 采用一种不同的方法，使用交错结构。它在纯粹专注于理解你的行为序列的层和将这些行为与你的画像属性连接起来的层之间交替。\n\n*   第一个序列层可能识别出你对健身的兴趣随时间增长。\n*   第一个跨特征层然后考虑你的年龄、收入和位置上下文如何塑造这种健身兴趣的含义。\n*   第二个序列层用这些新洞察重新审视你的行为，可能会注意到你在工作地点附近开设健身房后，你的健身研究变得更加深入。\n*   第二个跨特征层然后对购买意图和时机做出更深层次的连接。\n\n这种交替过程通过多个层持续进行，每个周期都在不丢失完整行为记录的情况下，循环地完善理解。\n\n## 使用 GEM 的实际问题\n\n尽管 GEM 具有明显的优势，Meta 在使用 GEM 时面临一个根本性的工程挑战。\n\nGEM 规模庞大，使用数千个 GPU 经过长时间训练。直接为每次广告预测运行 GEM 将是慢得无法接受且成本高昂的。当用户滚动浏览 Instagram 时，系统需要在几十毫秒内做出广告决策。GEM 在同时服务数十亿用户时根本无法以这种速度运行。\n\nMeta 的解决方案是采用教师-学生架构，其中 GEM 充当主导师，训练数百个更小、更快的垂直模型 (VMs)，这些 VMs 实际在生产环境中提供广告服务。这些 VMs 针对特定上下文进行专门化，例如 Instagram Stories 的点击预测或 Facebook Feed 的转化预测。每个 VM 都足够轻量，可以在几毫秒内做出预测，但它们比独立训练时更智能，因为它们从 GEM 中学习。\n\n知识迁移通过两种策略进行。当 VM 在与 GEM 训练的相同领域运作，具有相似数据和目标时，直接迁移 (Direct transfer) 起作用。GEM 可以直接教授这些模型。当 VMs 在与 GEM 训练领域截然不同的专业领域工作时，分层迁移 (Hierarchical transfer) 则适用。在这些情况下，GEM 首先为 Instagram 或 Facebook Marketplace 等领域训练中型领域特定基础模型。然后，这些领域模型再训练更小的 VMs。知识通过层级向下流动，在每个阶段得到适应和专门化。\n\nMeta 采用了三种复杂技术来最大化迁移效率：\n\n*   **带有 Student Adapter 的知识蒸馏 (Knowledge distillation with Student Adapter)**：学生模型学习复制 GEM 的推理过程，而不仅仅是最终预测。Student Adapter 使用最新的真实数据优化 GEM 的预测，调整时间延迟和领域特定差异。\n*   **表示学习 (Representation learning)**：在教师和学生之间创建共享的概念框架。GEM 学习以易于在不同模型大小之间迁移的方式编码信息，在广告服务期间不增加计算开销。\n*   **参数共享 (Parameter sharing)**：这使得 VMs 能够选择性地直接从 GEM 中整合特定组件。小型 VMs 保持快速，同时借用 GEM 的复杂组件来执行复杂的用户理解任务。\n\n这三种技术共同实现了单独使用标准知识蒸馏两倍的效果。持续改进循环的工作方式如下：\n\n*   用户实时与快速的 VMs 互动。\n*   他们的互动数据流回 Meta 的数据管道。\n*   GEM 定期基于这些新数据进行再训练，更新的知识通过训练后技术迁移到 VMs。\n*   改进后的 VMs 部署到生产环境。\n\n这个循环持续重复，GEM 变得越来越智能，VMs 定期获取智能更新。\n\n## 空前规模的训练\n\n构建 GEM 要求 Meta 从头开始重建其训练基础设施。\n\n挑战在于以 LLM（大语言模型）的规模训练一个模型，但任务是推荐而非语言生成，这与 LLM 根本不同。该公司实现了有效训练吞吐量增加 23 倍，同时使用了 16 倍的 GPU，并将硬件效率提高了 1.43 倍。\n\n这需要多个领域的创新。多维并行 (Multi-dimensional parallelism) 协调数千个 GPU 如何协同工作，使用像 Hybrid Sharded Distributed Parallel 这样的技术分割模型的密集组件，并通过数据并行和模型并行的结合处理像嵌入表 (embedding tables) 这样的稀疏组件。目标是确保每个 GPU 都保持忙碌，并最大限度地减少等待来自其他 GPU 通信的空闲时间。\n\n系统级优化进一步提高了 GPU 利用率：\n\n*   **专为可变长度用户序列设计的自定义 GPU 内核 (Custom GPU kernels)**，融合操作以减少内存带宽瓶颈。\n*   **PyTorch 2.0 图级编译 (graph-level compilation)** 自动化激活检查点 (activation checkpointing) 和操作符融合 (operator fusion) 等优化。\n*   **内存压缩 (Memory compression)**，包括 FP8 量化 (quantization) 以减少占用空间而不影响准确性。\n*   **NCCLX 通信集合 (communication collectives)** 处理 GPU 间通信，不占用主要计算资源。\n\n效率提升不仅仅是原始训练速度。\n\nMeta 通过优化训练器初始化、数据读取器设置和检查点 (checkpointing)，将作业启动时间缩短了 5 倍。他们通过智能缓存策略将 PyTorch 2.0 编译时间缩短了 7 倍。这些看似微不足道的细节，但在训练消耗数百万美元计算资源的模型时，每提高一个百分点的效率都至关重要。\n\n结果是一个能够快速迭代 GEM 的训练系统，以过去基础设施无法达到的速度整合新数据和架构改进。这使 Meta 能够将 GEM 保持在推荐 AI 的前沿，同时足够控制成本，使这项巨大投资物有所值。\n\n## 结论\n\nMeta 的 GEM 路线图远远超出了其当前能力。\n\n下一个主要演进涉及真正的多模态学习 (multimodal learning)，即 GEM 同时处理文本、图像、音频和视频，而不是将它们视为单独的输入流。这将对用户偏好和广告创意效果在所有内容类型上实现更丰富的理解。该公司还在探索推理时扩展 (inference-time scaling)，这将允许系统动态地为困难的预测分配更多计算资源，同时更高效地处理直接的案例。\n\n或许最雄心勃勃的是，Meta 设想一个统一互动模型 (unified engagement model)，使用相同的底层智能对有机内容和广告进行排名。这将从根本上改变广告如何融入社交信息流，可能创造更无缝的体验，让广告感觉像是自然的内容推荐而不是中断。在广告商方面，GEM 的智能将实现更复杂的代理自动化 (agentic automation)，其中 AI 系统可以以最少的人工干预管理和优化广告活动，同时实现更好的结果。\n\n## 参考文献:\n*   Meta’s Generative Ads Model (GEM): The Central Brain Accelerating Ads Recommendation AI Innovation\n*   InterFormer Research Paper\n*   Wukong: Towards a Scaling Law for Large-Scale Recommendation\n\n---\n\n## 要点总结\n\n*   **核心挑战与 GEM 的目标**：传统广告推荐系统难以处理跨平台、数据稀疏、动态特征和多模态输入。GEM 旨在通过统一智能，在 Meta 整个生态系统中全面理解用户，优化特定场景。\n*   **GEM 的用户理解架构**：GEM 通过三个互补系统理解用户：非序列特征系统（基于 Wukong 架构和可堆叠因子分解机）、序列特征系统（采用金字塔并行结构处理长序列）和 InterFormer（通过交错结构连接静态画像和行为时间线进行跨特征学习）。\n*   **教师-学生架构**：由于 GEM 本身计算成本过高，无法直接服务实时请求，Meta 采用教师-学生架构。GEM 作为“教师”训练数百个更小、更快的“垂直模型 (VMs)”，这些 VMs 在生产环境中提供广告服务。\n*   **知识迁移策略**：知识从 GEM 迁移到 VMs 的策略包括直接迁移和分层迁移，并结合了三种核心技术：带有 Student Adapter 的知识蒸馏、表示学习和参数共享，以最大化迁移效率。\n*   **持续改进循环**：系统通过用户互动数据反馈给 GEM 进行再训练，然后将更新的知识迁移到 VMs 并部署，形成一个不断学习和优化的闭环。\n*   **空前规模的训练基础设施**：Meta 为 GEM 的训练从头构建了基础设施，实现了 LLM 规模的推荐模型训练，大幅提升了训练吞吐量和硬件效率。\n*   **关键的训练优化技术**：高效训练依赖于多维并行（处理密集和稀疏组件）、自定义 GPU 内核、PyTorch 2.0 图级编译（包括激活检查点和操作符融合）以及内存压缩（如 FP8 量化）。\n*   **工程效率提升**：通过优化训练器初始化、数据读取器设置、检查点和智能缓存策略，Meta 将作业启动和编译时间大幅缩短，提升了整体工程迭代效率。\n*   **GEM 的未来方向**：包括真正的多模态学习（处理多种媒体类型）、推理时扩展（动态分配计算资源）以及统一互动模型（将有机内容和广告一同排名），以创造更无缝的用户体验和实现更高级的代理自动化。\n\n## 你可以从这篇文章学到什么\n\n作为一名有几年经验的后端/系统设计工程师，这篇文章为你提供了在构建和优化超大规模 AI 驱动系统方面的宝贵洞察和实践经验：\n\n1.  **处理复杂性的分层架构设计**：GEM 在理解用户方面采用了“非序列特征”、“序列特征”和“跨特征学习”三个互补系统，这种将复杂问题分解为多个专业化、协同工作的子系统的思想，在设计任何大型后端系统时都非常有用。你可以学习如何将一个宏大的功能拆解为可管理、可优化的模块。\n2.  **师生模型 (知识蒸馏) 的实用策略**：当你面对一个功能强大但计算资源消耗巨大的核心模型时（例如一个复杂的机器学习模型，或一个耗时的大型复杂计算模块），“教师-学生架构”是一种非常有效的解决方案。它可以帮助你在性能、成本和准确性之间找到平衡点，在生产环境中提供快速、低成本的服务，同时保留核心模型的“智能”。这对于优化延迟敏感的服务尤其重要。\n3.  **大规模机器学习基础设施的挑战与解决方案**：文章详细描述了 Meta 如何应对 LLM 规模的推荐模型训练挑战。即使你不是 ML 工程师，理解多维并行、GPU 内核优化、内存管理（如 FP8 量化）、以及 PyTorch 2.0 编译优化等技术，能帮助你更好地与 ML 团队协作，并为任何计算密集型服务提供基础设施支持和优化思路。\n4.  **持续改进和迭代的系统思维**：从用户互动到数据回流、模型再训练、知识迁移和部署的闭环，是现代数据驱动系统不断进化的关键。这强调了监控、数据管道、A/B 测试和快速迭代在系统设计中的核心地位，确保系统能够随着业务和用户行为的变化而演进。\n5.  **特征工程和模式识别的深度思考**：GEM 如何通过 Wukong 架构处理特征交互、通过金字塔并行结构处理长序列行为，以及 InterFormer 如何整合静态与动态特征，都提供了在设计数据模型和处理业务逻辑时，对数据维度、时间序列和多源信息整合的深刻启发。这能帮助你设计更智能的数据处理流程和更准确的业务规则。\n6.  **性能与效率优化的细节考量**：文章中提到的作业启动时间、编译时间优化，以及 GPU 利用率的提升，都提醒我们，在超大规模系统中，即使是看似微小的细节，其累积效应也可能带来巨大的成本节约和效率提升。这培养了对系统每个环节进行性能剖析和优化的习惯。\n7.  **前瞻性的技术发展趋势**：了解多模态学习、推理时资源动态分配、以及统一内容与广告排名等未来方向，有助于你对技术栈进行前瞻性规划，并保持对行业最新发展趋势的敏感度，从而在职业发展中保持竞争力。",
    "url": "https://blog.bytebytego.com/p/how-meta-built-a-new-ai-powered-ads"
  }
]