[
  {
    "id": "2025-12-16-top-ai-agentic-workflow-patterns",
    "title": "Top AI Agentic Workflow Patterns",
    "date": "2025-12-16",
    "preview": "顶级的AI智能体工作流模式  当我们最初与大型语言模型（LLM）互动时，体验是直接的：我们输入一个提示词（prompt），模型生成一个响应，互动随即结束。  这种单轮（single-turn）方式对于简单问题或基础内容生成效果良好，但当我们处理更复杂的任务时，它的局限性很快就暴露...",
    "content": "顶级的AI智能体工作流模式\n\n当我们最初与大型语言模型（LLM）互动时，体验是直接的：我们输入一个提示词（prompt），模型生成一个响应，互动随即结束。\n\n这种单轮（single-turn）方式对于简单问题或基础内容生成效果良好，但当我们处理更复杂的任务时，它的局限性很快就暴露出来。试想一下，要求AI分析市场趋势、创建一份全面的报告并提供可操作的建议。一个单独的响应，无论多么精心制作，往往力有不逮，因为它缺乏收集额外信息、反思其推理过程或根据反馈完善输出的机会。\n\n这正是智能体工作流（agentic workflows）发挥作用的地方。\n\n智能体工作流不再将AI互动视为一次性交易，而是引入了迭代过程、工具集成和结构化的问题解决方法。这些工作流将语言模型从复杂的文本生成器转变为有能力的智能体，它们能够分解复杂问题、调整策略并产生更高质量的结果。这种差异类似于将一个快速草图与一幅精心打磨的画作进行比较。两者都有其用途，但当质量和可靠性至关重要时，迭代方法更胜一筹。\n\n在本文中，我们将探讨最流行的智能体工作流模式及其运作方式。\n\n### 理解智能体工作流\n\n智能体工作流不仅仅响应一个单一指令。相反，它在一定程度上自主运作，决定如何处理任务、采取哪些步骤以及如何根据其发现进行调整。这代表了我们思考如何使用AI系统的根本转变。\n\n考虑一下请求一个基础聊天机器人和一个智能体系统帮助撰写研究报告的区别。基础聊天机器人收到请求后，根据其训练数据生成一份报告，并一次性提供其生成的所有内容。然而，一个智能体系统可能会首先在网络上搜索有关该主题的最新信息，然后将发现组织成主题，起草报告的各个部分，审查每个部分的准确性和连贯性，修改薄弱区域，最后将所有内容编译成一份精美的文档。这些步骤中的每一个都可能涉及多个子步骤、关于使用哪些工具的决策以及根据智能体发现进行调整。\n\n真正使工作流具有智能体特性的，是内置于过程中的迭代和反馈循环。智能体工作流不是一次性生成输出，而是涉及循环：智能体执行一个动作，观察结果，然后利用该观察结果指导下一步动作。这与人类实际解决复杂问题的方式异曲同工。我们很少在事前就弄清所有事情并执行一个完美的计划。相反，我们尝试一些东西，观察发生的情况，从结果中学习，然后调整方法。智能体工作流将这种适应性、迭代性带入了AI系统。\n\n### 五种核心智能体工作流模式\n\n现在让我们看看五种核心智能体工作流模式：\n\n#### 1. 反思模式（Reflection Pattern）：自我改进的智能体\n\n反思的核心是让智能体审查和批判自己的工作，然后根据批判进行修改。这个简单的想法提高了输出质量，因为它引入了一个迭代的精炼过程，可以发现错误、识别弱点并增强优势。\n\n反思循环在实践中是这样运作的：\n\n智能体首先根据收到的任务或提示词生成初始输出。\n\n然后，智能体不立即将此输出呈现为最终结果，而是切换到批判模式。它审查刚刚生成的内容，寻找问题、不一致、缺乏清晰度的区域或改进的机会。这种批判成为修改的基础。\n\n智能体生成一个改进版本，解决其识别出的问题。根据实现方式，这个循环可能会重复多次，每次迭代都会进一步完善输出。\n\n请参见下图：\n（此处原文有图示，表示智能体生成初始输出 -> 批判 -> 改进 -> 再次批判/改进的循环）\n\n当我们专门针对执行的批判类型时，反思的力量变得更加明显。例如：\n\n一个智能体可能专门反思准确性，检查其所做的事实和主张是否正确且有充分支持。\n或者，反思可能侧重于清晰度，询问不熟悉该主题的人是否能理解解释。\n对于创意写作，反思可能会评估语气，确保声音符合预期的风格和受众。\n对于代码生成，反思可能侧重于识别错误（bugs）、安全漏洞或优化性能的机会。\n\n反思模式最适用于质量比速度更重要，并且存在受益于审查的主观方面的任务。然而，对于答案直接的简单、事实性查询，或者速度至关重要且“足够好”确实就足够的任务，这种模式的必要性较低。\n\n#### 2. 工具使用模式（Tool Use Pattern）\n\n工具使用模式代表了AI智能体能够完成的事情的根本性扩展。\n\n一个语言模型本身，无论多么复杂，都局限于推理其在训练期间学到的信息，并根据该知识生成文本。它无法访问最新信息、执行大规模精确计算、从特定数据库检索数据或与外部系统交互。工具改变了一切。\n\n在工具使用模式中，智能体配备了一套在需要时可以调用的能力。这些能力可能包括用于查找最新信息的网络搜索引擎、用于访问天气数据或股票价格等服务的API、用于运行程序和执行计算的代码解释器、用于检索特定记录的数据库查询工具、用于读写文档的文件系统访问以及无数其他专业功能。与传统软件的关键区别在于，智能体本身根据手头的任务决定何时以及如何使用这些工具。\n\n请参见下图：\n（此处原文有图示，表示智能体接收任务 -> 分析需求 -> 选择工具 -> 使用工具 -> 观察结果 -> 再次分析/选择工具的循环）\n\n当智能体收到一个任务时，它会分析完成该任务需要哪些能力。例如：\n\n如果任务需要智能体没有的信息，它会识别出需要搜索或数据检索工具。\n如果任务涉及数学运算，它会访问计算器或代码解释器。\n如果任务需要与特定服务交互，它会使用相应的API工具。\n\n工具使用之所以强大，在于工具选择的动态性以及将多个工具调用链接在一起的能力。\n\n智能体不遵循预设脚本。如果第一次搜索没有返回足够的信息，智能体可能会重新组织查询并再次搜索。如果API调用失败或返回错误，智能体可能会尝试另一种方法或完全不同的工具。这种适应性使得启用工具的智能体比僵化的自动化工作流强大得多。\n\n#### 3. 推理与行动模式（Reason and Act Pattern，简称ReAct）\n\n推理与行动模式，通常称为ReAct，代表了一种结合明确推理和迭代行动的复杂问题解决方法。ReAct智能体不是在行动前思考整个计划，也不是不经反思盲目行动，而是在推理下一步要做什么和实际执行之间交替进行。这种思想和行动的交织创造了一种自然的、适应性强的问题解决过程。\n\nReAct循环遵循清晰的模式：\n\n首先，智能体推理当前情况以及它需要完成什么。这个推理步骤是明确的，通常被字面记录为智能体的内部思维过程。智能体可能会思考它拥有什么信息，还需要什么，哪些方法可能有效，以及最佳的下一步是什么。\n然后，基于这个推理，智能体采取一个行动。这可能是使用工具收集信息、执行计算或做出决定。\n行动之后，智能体观察结果并进入新的推理阶段，思考它学到了什么以及下一步要做什么。这个循环持续进行，直到智能体确定它已完成目标或达到无法继续进行的地步。\n\n请参见下图：\n（此处原文有图示，表示智能体思考 -> 行动 -> 观察 -> 再次思考/行动的循环）\n\n明确的推理步骤具有多重重要目的：\n\n首先，它们帮助智能体保持专注并聚焦于目标。通过阐明它试图完成什么以及为什么每个行动都有意义，智能体不太可能走上无关的路径或陷入无益的循环。\n其次，推理步骤实现了适应性。当某个行动没有产生预期结果时，推理阶段允许智能体诊断原因并调整其方法，而不是盲目地继续。\n第三，推理轨迹提供了透明度。用户和开发者不仅可以看到智能体做了什么，还可以看到它为什么做出这些选择，这对于信任、调试和理解智能体的决策过程非常宝贵。\n\n将ReAct与纯粹的计划或纯粹的执行进行比较，突显了其优势。\n\n纯粹的计划意味着在采取任何行动之前弄清所有步骤。当信息完整且环境可预测时，这非常有效，但当我们需要在过程中发现信息或情况发生变化时，它就会遇到困难。\n纯粹的执行意味着不加太多思索地采取行动，这很快但往往效率低下且容易出错。\nReAct找到了一个中间地带，通过推理提供了足够的结构，同时通过迭代行动保持了灵活性。\n\n#### 4. 规划模式（Planning Pattern）\n\n规划模式与ReAct采用了不同的方法，它强调在执行开始之前进行前期的战略性思考。\n\n使用规划模式时，智能体首先分析总体目标并理解成功的样子。然后，它将这个目标分解为更小、更易于管理的子任务。这种分解一直持续，直到智能体识别出具体的、可操作的步骤。\n\n至关重要的是，智能体识别任务之间的依赖关系，确定哪些步骤必须在其他步骤开始之前完成，以及哪些步骤可以并行进行。智能体还会考虑每个步骤需要哪些资源、工具或信息。只有在创建了这个结构化计划之后，智能体才开始执行。\n\n请参见下图：\n（此处原文有图示，表示智能体接收目标 -> 计划（分解任务、识别依赖、分配资源） -> 执行 -> 观察并反馈给计划阶段的循环）\n\n规划模式的关键优势之一是自适应规划。\n\n规划模式最适用于具有自然阶段或步骤的任务，其中某些活动在逻辑上先于其他活动。它对于具有截止日期、预算或资源限制等约束条件，并且协调至关重要的任务很有价值。它在错误或回溯成本高昂的情况下表现出色，这使得投入时间进行周密规划是值得的。涉及多个工作流的复杂项目从规划中受益匪多。\n\n然而，规划模式也有局限性：\n\n对于简单、线性任务，其中每个步骤自然地暗示下一个步骤，创建正式计划的开销几乎没有益处。\n对于高度不确定的任务，我们很可能在执行过程中发现根本性改变方法的重要信息，此时广泛的前期规划可能只是浪费精力。\n\n#### 5. 多智能体模式（Multi-Agent Pattern）\n\n多智能体模式可能代表了构建AI系统最复杂的方法。\n\n这种模式不依赖单一智能体处理所有事情，而是使用多个专业智能体协同完成任务。每个智能体都具有特定的专业知识、能力或视角，它们像人类团队一样协同工作。\n\n多智能体系统背后的核心洞察是，专业化通常比泛化带来更好的性能。\n\n一个试图在所有方面都表现出色的单一智能体面临挑战。它必须在其设计和训练中平衡相互竞争的需求。它需要广泛的知识，但也需要深入的专业知识。它必须富有创造力，但也必须具有批判性。通过在多个智能体之间划分职责，每个智能体都可以针对其特定角色进行优化。\n\n在多智能体系统中，我们通常会看到几种类型的角色：\n\n有专注于特定领域或任务的专业智能体，例如擅长查找和综合信息的**研究智能体**、优化代码编写和调试的**编码智能体**，或擅长统计分析和可视化的**数据分析智能体**。\n通常还有**评论者或审查智能体**，其工作是评估其他智能体的输出，识别缺陷、提出改进建议或验证质量。\n通常有一个**协调者或编排者智能体**，管理整个工作流，决定哪个专家应该处理每个子任务，并确保所有部分连贯地组合在一起。\n\n多智能体模式引入了复杂的权衡：\n\n协调开销随着智能体数量的增加而增加。\n智能体之间的通信需要清晰的协议。\n调试变得更具挑战性，因为问题可能来自智能体之间的交互，而不是单个智能体的错误。\n\n收益必须证明这些成本是合理的。对于简单任务，一个有能力的单一智能体几乎总是更好的选择。对于需要多样化专业知识、细致协调或多重视角的复杂任务，多智能体方法尽管增加了复杂性，但通常会产生卓越的结果。\n\n### 结论\n\n各种智能体工作流模式代表了我们构建和部署AI系统的根本性演进。\n\n从简单的提示词驱动到复杂的迭代过程，这转变了AI智能体能够可靠完成的任务。以下是我们涵盖的模式的快速总结：\n\n*   **反思模式**通过自我改进确保质量。\n*   **工具使用**将能力扩展到纯语言生成之外。\n*   **ReAct**将周密的推理与自适应行动相结合。\n*   **规划**为复杂任务带来战略性思维。\n*   **多智能体协作**利用专业化和多样化的视角。\n\n这些模式共同为构建能够处理真实世界复杂性的AI系统提供了强大的工具包。\n\n这些模式之所以特别强大，是因为它们并非相互排斥。最复杂的智能体系统通常会结合多种模式来实现其目标。\n\n---\n\n### 要点总结\n\n*   **超越单轮交互**：智能体工作流将AI互动从简单的单轮提示词响应，转变为迭代、自适应、具备工具集成的问题解决过程。\n*   **核心特性**：智能体工作流具有自主性、决策能力、适应性，并通过内置的迭代和反馈循环来模仿人类解决复杂问题的方式。\n*   **反思模式（Reflection）**：智能体审查和批判自身输出，并进行迭代改进，以提升结果质量和准确性。\n*   **工具使用模式（Tool Use）**：通过集成外部工具（如搜索引擎、API、代码解释器），智能体能超越其训练数据的限制，获取最新信息并执行特定操作。\n*   **推理与行动模式（ReAct）**：智能体在明确的推理和实际行动之间交替进行，根据观察到的结果动态调整策略，提供透明的决策路径。\n*   **规划模式（Planning）**：在执行前进行全面的战略规划，将目标分解为子任务，识别依赖关系，并分配资源，适用于需要预先协调和避免高成本错误的复杂项目。\n*   **多智能体模式（Multi-Agent）**：通过多个专业化智能体（如研究员、编码员、评论者、协调者）的协作，利用各自专长，共同解决复杂任务，实现比单一智能体更优异的性能。\n*   **能力提升**：这些模式显著提高了AI系统处理复杂任务的可靠性、质量和广度。\n*   **模式组合**：文章中提到的各种模式并非相互排斥，最先进的AI系统通常会组合使用多种模式来达到更精细、更强大的目标。\n*   **选择依据**：选择合适的工作流模式取决于任务的复杂性、对速度和质量的要求以及对错误容忍度等因素。\n\n### 你可以从这篇文章学到什么\n\n对于具有数年经验的后端/系统设计工程师而言，这篇文章提供了关于AI智能体工作流的深刻见解，这些概念不仅限于AI领域，对设计和构建任何复杂的分布式系统都具有重要的启发意义和实际应用价值：\n\n1.  **AI集成的新范式**：你将意识到，将AI能力集成到现有系统中远不止调用一个大模型API那么简单。智能体工作流提供了一套强大的结构化方法，让AI能够更智能、更可靠地执行复杂任务，这对于设计企业级AI应用至关重要。\n\n2.  **系统设计层面的思考**：\n    *   **编排层（Orchestration Layer）**：ReAct、规划和多智能体模式都强调了对复杂任务进行拆解、调度和协调的重要性。这直接对应了后端系统中构建工作流引擎、任务调度器或微服务编排器的需求。你需要设计一个高效、可扩展的编排层来管理智能体的状态、工具调用和决策流程。\n    *   **工具集成与安全性**：工具使用模式要求智能体能够安全、高效地调用外部工具（如数据库、内部API、第三方服务）。这引发了对API网关、统一认证授权、速率限制、服务发现和容错机制的设计思考。如何让智能体以受控的方式访问和操作外部资源，同时保证数据安全和系统稳定性，是后端工程师的核心职责。\n    *   **状态管理与持久化**：智能体在迭代过程中需要维护上下文信息。这意味着你需要设计合适的数据存储方案（关系型数据库、NoSQL、缓存），以持久化智能体的历史记录、决策路径和中间结果，这对于调试、审计和恢复至关重要。\n    *   **可观测性与调试**：ReAct模式中明确的“思考”步骤，以及反思模式中的自我批判，为系统提供了宝贵的“审计日志”和“决策路径”。作为后端工程师，你可以利用这些思想，在设计系统时内建更强的日志记录、追踪和监控机制，以便在复杂分布式系统中定位问题、理解行为。\n    *   **弹性与错误处理**：智能体工作流的迭代性质意味着它需要处理工具调用失败、外部服务异常或自身推理错误的情况。这要求你在系统设计中融入更强的错误恢复、重试机制和回退策略，提升整个系统的韧性。\n\n3.  **实际项目应用**：\n    *   **智能自动化平台**：你可以设计一个智能自动化平台，利用规划模式分解复杂的业务流程（例如，自动化报告生成、数据清理、部署流程），然后使用工具使用模式集成各种企业内部系统和外部服务。\n    *   **高级智能客服或运维助手**：通过多智能体模式，你可以构建一个客服系统，其中包含一个意图识别智能体、一个知识库检索智能体、一个回复生成智能体和一个审核智能体，协同工作以提供更准确、更个性化的服务。在运维场景中，智能体可以使用ReAct模式诊断系统故障（调用监控API）、查找解决方案（搜索知识库）、甚至执行修复操作（调用自动化部署或脚本执行工具）。\n    *   **数据驱动的决策支持系统**：利用反思模式和工具使用模式，开发能够自动分析大量数据、生成报告并自我审查报告准确性和完整性的系统，为商业决策提供更可靠的洞察。\n\n总之，这篇文章不仅仅是关于AI，更是关于如何设计更智能、更自适应的系统。它鼓励你将大模型视为一个可编程的、具备推理能力的组件，而不是一个简单的黑盒API。作为系统设计者，理解这些智能体模式，将帮助你构建下一代更加健壮、灵活且具备高度自动化能力的软件系统。",
    "url": "https://blog.bytebytego.com/p/top-ai-agentic-workflow-patterns"
  },
  {
    "id": "2025-12-16-how-linkedin-built-an-ai-powered-hiring-assistant",
    "title": "How LinkedIn Built an AI-Powered Hiring Assistant",
    "date": "2025-12-16",
    "preview": "# LinkedIn 如何构建 AI 驱动的招聘助理  ByteByteGo 2025年12月16日  ---  免责声明：本文中的细节来源于 LinkedIn 工程团队在线分享的信息。所有技术细节的功劳归于 LinkedIn 工程团队。原始文章和来源链接已在文章末尾的参考文献部...",
    "content": "# LinkedIn 如何构建 AI 驱动的招聘助理\n\nByteByteGo\n2025年12月16日\n\n---\n\n免责声明：本文中的细节来源于 LinkedIn 工程团队在线分享的信息。所有技术细节的功劳归于 LinkedIn 工程团队。原始文章和来源链接已在文章末尾的参考文献部分列出。我们尝试分析这些细节并提供我们的见解。如果您发现任何不准确或遗漏之处，请留言，我们将尽力修正。\n\n招聘是一项需要战略思维和一丝不苟的职业。招聘人员必须就哪些候选人最适合某个职位做出高价值的决策，但他们也花费无数时间在重复的模式识别任务上。筛选数百份简历，根据职位要求评估资格，以及起草个性化的外联信息，这些都是必不可少的活动。然而，它们也消耗了大量时间，这些时间本可以用于建立关系和做出战略性招聘决策。\n\nLinkedIn 的 Hiring Assistant 代表了一种解决这一挑战的新方法。\n\n这个 AI agent 的设计宗旨不是取代招聘人员，而是处理招聘流程中重复、耗时的方面，让专业人士能够专注于他们最擅长的事情：与人建立联系并做出关键的招聘选择。\n\n招聘中最劳动密集的部分分为三类：\n\n首先，**寻源候选人 (sourcing candidates)** 需要在 LinkedIn 超过12亿个档案的网络中搜索，以识别合格的个人。\n\n其次，**评估候选人 (evaluating candidates)** 涉及仔细阅读简历和档案，以评估每个人是否符合职位的具体要求。\n\n第三，**与候选人互动 (engaging candidates)** 意味着起草并发送个性化沟通信息给潜在雇员，回答他们的问题，并在整个招聘过程中保持持续对话。\n\n为了应对这些挑战，LinkedIn 构建了 Hiring Assistant，它具有三个核心能力：\n\n该系统通过高效搜索数十亿个档案并可靠处理企业级工作负载，实现**大规模交付价值**。\n\n它通过自然对话理解招聘人员意图，在需要时提出澄清问题，并根据实时反馈调整其行为，从而实现**交互式沟通**。\n\n最后，它还通过观察招聘人员的行为、学习个人偏好以及记忆过去的互动和决策，实现**持续学习**，随着时间的推移不断改进。\n\n在本文中，我们将探讨 LinkedIn Hiring Assistant 的架构和技术构建模块。\n\n## 高层架构\n\nHiring Assistant 的核心建立在 LinkedIn 称之为“plan-and-execute”（计划与执行）架构之上，如下图所示：\n\n![High-Level Architecture](https://github.com/ByteByteGo/system-design-interviews/blob/main/linkedin-ai-hiring-assistant/1.png)\n\n要理解这为何重要，有助于了解他们避免了什么。一种更简单的方法，称为 ReAct 模式，会让 AI 尝试在一个单一的连续循环中处理所有事情。虽然直接，但当任务变得复杂时，这种方法会遇到问题。大型语言模型（LMMs），即驱动此类工具的 AI 系统，在被要求同时处理太多事情时可能会变得不可靠。\n\nReAct 模式见下图。\n![ReAct Pattern](https://github.com/ByteByteGo/system-design-interviews/blob/main/linkedin-ai-hiring-assistant/2.png)\n\n相反，LinkedIn 将工作分成了两个不同的阶段：\n\n**Planner** 充当战略思考者。当招聘人员提出请求时，Planner 从高层次审视请求，将其分解为更小、更易于管理的步骤，并创建一个结构化的计划，说明需要完成什么。可以将其视为项目经理在实际工作开始前概述方法。\n\n**Executor** 随后接管。它根据计划一步步地执行任务，使用可用工具完成每个任务。对于每个步骤，Executor 运行自己的推理和行动循环，弄清需要做什么，然后去实现它。\n\n这种“分而治之”的策略带来了几个优势：\n\n首先，它使系统更加可靠。将复杂的招聘流程分解为离散的步骤意味着 AI 不太可能混淆或犯错。\n\n其次，它允许更好的成本管理。LinkedIn 可以将更强大的 AI 模型用于复杂的推理任务，同时为直接的步骤部署更简单、更便宜的模型。\n\n第三，当任务明确且范围可控时，它们更有可能成功完成。\n\n除了 plan-and-execute 设计之外，Hiring Assistant 还使用**消息驱动架构 (message-driven architecture)**。\n\n每个招聘人员都有自己的 Hiring Assistant 实例，并配有自己的身份和邮箱。一切都通过异步消息进行，很像电子邮件。当招聘人员要求助理寻找候选人时，他们不必坐着等待结果。助理接收消息，在后台处理，并在准备好时发送更新。\n\n这种异步方法使得助理能够大规模工作。当招聘人员专注于其他任务时，他们的助理可以搜索数百万份档案，评估候选人，并准备推荐，所有这些都无需持续的关注或监督。\n\n## Agentic 用户体验\n\nHiring Assistant 以两种互补模式运行，每种模式都设计用于招聘过程的不同阶段：\n\n**Interactive Mode（交互模式）**：\n当招聘人员首次开始一个新项目时，他们以交互模式与助理合作。这感觉就像与同事交谈。招聘人员可以澄清他们正在寻找什么样的人，细化职位要求，并获得对其请求的即时反馈。助理在工作时展示其推理过程，使流程透明化。这建立了信任，因为招聘人员可以确切地看到系统正在做什么，并在出现问题时迅速纠正方向。\n\n**Asynchronous Mode（异步模式）**：\n一旦招聘人员和助理对“成功”的定义达成一致，系统就会切换到异步模式。这就是自动化真正发挥作用的地方。助理在后台自主工作，对数百万份档案进行大规模搜索，持续更新候选人管道，并评估新出现的申请人。\n\nLinkedIn 将其描述为“source while you sleep”（在你睡觉时寻源）的能力。\n\n助理可以在一夜之间审查数千名候选人，而这项任务如果由人工招聘人员手动完成，则需要数周时间。\n\n然而，即使在这种自主模式下，人类仍然掌握着重要决策的控制权。助理浮现候选人并提供推荐，但招聘人员最终决定联系谁以及最终聘用谁。这种自动化与人类判断之间的平衡是系统设计的核心。\n\n## 技术构建模块\n\nHiring Assistant 建立在 LinkedIn 更广泛的 agent 平台之上，这是一个可为公司内部任何 AI agent 产品提供动力的可重用组件基础。这种方法意味着 LinkedIn 工程团队每次构建新的智能系统时，都不必重复造轮子。\n\n在用户界面层面，一个**客户端 SDK (client-side SDK)** 将助理直接嵌入到招聘人员的工作流程中。这个 SDK 创建动态界面，根据 AI 在任何给定时刻的需求进行调整。它支持多种输入方法，包括聊天、语音和打字辅助，同时记录所有交互以供未来分析和改进。\n\n连接这个界面到后端服务的是一个 **GraphQL API**，它以结构化的数据包（称为 **view models**）提供数据。这些数据包包含显示屏幕上所需的一切信息。LinkedIn 将其称为 **agent-driven UI（代理驱动 UI）**，其中 AI 本身可以决定招聘人员看到什么，随着任务的进展动态调整界面。\n\n该系统没有采用传统的请求-响应模式（即你提出问题并等待答案），而是使用了**推送式、事件驱动架构 (push-based, event-driven architecture)**。其工作方式如下：\n\n用户界面订阅来自 agent 的更新，当有变化时，agent 发布该更新。这意味着界面会自动刷新，用户无需手动重新加载任何内容。\n\n长时间运行的 AI 任务通过**流式响应 (streaming responses)** 交付。招聘人员无需等待完整的答案，而是实时看到 AI 的推理过程，结果一经可用即显示。\n\n如果招聘人员在多个设备上登录，**跨会话同步 (cross-session synchronization)** 会保持所有内容同步。在手机上执行的操作会立即反映在桌面浏览器上。\n\n## 监督代理 (Supervisor Agent)\n\nHiring Assistant 的核心是一个 LinkedIn 称之为 **Supervisor Agent** 的组件。如果整个系统是一个团队，那么 Supervisor Agent 就是团队领导，确保每个人都有效协作。\n\n见下图：\n![Supervisor Agent](https://github.com/ByteByteGo/system-design-interviews/blob/main/linkedin-ai-hiring-assistant/3.png)\n\nSupervisor Agent 负责处理几项关键职责：\n\n它负责整个招聘流程的**工作流管理 (workflow management)**，确保任务按正确顺序推进。\n\n当招聘人员发送消息或请求时，Supervisor Agent 接收并将其**路由 (routes)** 到适当的子 agent 进行处理。\n\n它还会就任务**优先级 (task prioritization)** 做出判断，决定哪些任务需要人工输入，哪些可以安全地自动化。\n\n除了委派工作，Supervisor Agent 还协调不同的子 agent 之间，确保它们顺利协作。它积极**观察环境 (observes the environment)**，监测新候选人活动或申请提交等变化，并触发适当的响应行动。\n\nSupervisor Agent 还管理系统的**人机协作 (human-in-the-loop)** 方面。它知道哪些决策足够重要需要人工批准，并将这些时刻呈现给招聘人员。\n\n所有通信，无论是来自用户还是子 agent 之间，都流经 Supervisor Agent。它充当中央枢纽，使整个操作保持有序并与招聘人员的目标保持一致。\n\n## 专业化子代理 (Specialized Sub-Agents)\n\nHiring Assistant 将招聘工作分配给几个**专业化子 agent**，每个 agent 都专注于工作流程的特定部分。这种模块化设计允许每个组件擅长其特定任务，同时作为一个有凝聚力的系统协同工作。让我们详细了解各种子 agent：\n\n### 引导代理 (Intake Agent)\n\nIntake Agent 是每个招聘项目的起点。\n\n它从招聘人员那里收集职位要求，确认职位名称、地点和资历水平等基本细节。当信息缺失时，该 agent 利用 LinkedIn 的 **Economic Graph**（全球经济的数字地图，即经济图谱）智能地填补空白。然后，该 agent 根据过去的成功招聘和行业知识生成具体的资格要求，为评估候选人创建清晰的框架。\n\n### 寻源代理 (Sourcing Agent)\n\n寻找合适的候选人可能是招聘中最知识密集的部分，Sourcing Agent 采用多种策略应对这一挑战。\n\n它使用传统的**布尔逻辑 (Boolean logic)**（AND、OR、NOT 运算符）创建搜索查询，根据招聘要求生成 AI 驱动的查询，并以历史招聘人员搜索模式作为起点。重要的是，客户数据绝不会跨越公司边界，保持严格的数据隔离。\n\n这个 agent 的独特之处在于它与 LinkedIn 的 Economic Graph 集成。\n\n这使其能够访问特定人才库的顶级地点、职位名称和技能的洞察。它可以识别哪些候选人正在积极寻找工作或最近被录用，了解公司和行业之间的人才流动模式，发现快速增长的公司和技能组合，标记正在裁员的公司，并突出顶尖学校或有空缺职位的公司中的机会。这些洞察帮助 agent 找到那些可能被忽视的“隐藏瑰宝”，远远超出了简单的关键词匹配。\n\nSourcing Agent 还实现了**闭环反馈 (closed feedback loop)**。它将寻源结果与评估结果结合起来，利用 AI 推理根据哪些候选人被证明是良好匹配来优化查询。这使得系统能够在**精确度 (precision)**（找到完全符合的候选人）与**流动性 (liquidity)**（找到足够多的候选人）之间取得平衡，随着时间的推移不断提高结果的质量和数量。\n\n### 评估代理 (Evaluation Agent)\n\n阅读简历和评估资格是招聘人员最耗时的任务之一。\n\nEvaluation Agent 通过阅读候选人档案和简历，将其与职位资格进行比较，并提供有证据支持的结构化推荐来解决这个问题。它展示了候选人可能符合或不符合要求的原因，而不仅仅是提供“是”或“否”的答案。\n\nLinkedIn 设计此 agent 以应对几个复杂的挑战。\n\n在任何评估开始之前，招聘人员必须审查并批准所使用的资格要求。\n\n安全检查确保这些资格要求遵循负责任的 AI 政策。该 agent 搜索档案和简历，寻找特定证据，证明候选人如何符合每项资格，并将这些证据呈现给招聘人员进行审查。\n\n为了确保准确性，LinkedIn 建立了质量基准，用于在不同场景下测试 Evaluation Agent。\n\n他们开发了专门针对资格评估进行优化的定制 AI 模型，因为通用模型无法实现所需的准确性和速度组合。使用 **speculative decoding**（推测解码，一种加速推理的技术）和**定制服务基础设施 (custom serving infrastructure)** 等技术，这些经过微调的模型可以在几秒钟而不是几分钟内评估候选人，速度足够快，可以支持实时、对话式的需求细化。\n\n### 候选人外联代理 (Candidate Outreach Agent)\n\n一旦识别出有希望的候选人，Outreach Agent 会处理沟通。\n\n它撰写个性化消息，发送初始外联和跟进，并使用在引导阶段定义的特定职位常见问题解答来回复候选人的问题。该 agent 甚至可以直接通过消息安排电话筛选，简化协调工作。\n\n### 候选人筛选代理 (Candidate Screening Agent)\n\n为了支持面试流程，Screening Agent 根据招聘要求和候选人档案准备定制的面试问题。\n\n它可以转录和总结筛选对话，同时捕捉笔记和洞察。重要的是，招聘人员保持完全控制，可以随时接管对话或根据需要引导流程。\n\n### 学习代理 (Learning Agent)\n\nLearning Agent 使系统能够随着时间的推移而改进。\n\n它分析招聘人员的行为，例如他们向哪些候选人发送消息或将其添加到候选人管道中，从显式反馈和隐式行为信号中学习。该 agent 根据这些模式更新职位资格，但任何建议的更改都必须经过招聘人员审查和批准才能应用。这确保了助理在保持人类控制的同时进行适应。\n\n### 认知记忆代理 (Cognitive Memory Agent)\n\n最后，Cognitive Memory Agent 为助理提供了跨交互的持久记忆。\n\n它记住过去的对话、偏好和决策，有助于随着时间的推移个性化推荐。所有内存数据都仅限于个人招聘人员的环境，并具有强大的隐私保护。\n\n这些数据绝不用于训练 AI 模型，确保客户信息安全保密。\n\n## 质量支柱 (The Quality Pillars)\n\n构建一个大规模运行的 AI agent 需要一个全面的质量方法，以确保系统安全、负责任且有效地运行。\n\nLinkedIn 工程团队的质量框架建立在两个互补的支柱之上：\n\n**1 - 护栏 (The Rails)**\n\n产品政策充当保持系统正常运行的**护栏 (rails)**。这些政策为安全、合规和法律标准设定了明确的界限，同时定义了预期的 agent 行为。它们建立了必须满足的最低质量阈值。\n\n为了强制执行这些标准，LinkedIn 采用了 **AI 驱动的评估器 (AI-powered judges)**，它们评估质量的不同方面。一些评估器检查**连贯性 (coherence)**，询问输出是否合乎逻辑。另一些则验证**事实准确性 (factual accuracy)**，确保系统不会生成虚假或误导性信息。\n\n**2 - 指南针 (The Compass)**\n\n**人机对齐 (Human alignment)** 充当**指南针 (compass)**，确保助理朝着真正有价值的结果前进。\n\n这个支柱以人类验证的数据为基础，包括人们进行标注的数据集和真实的招聘人员活动。当招聘人员向候选人发送消息或将其添加到候选人管道时，系统将其视为强烈的积极信号。\n\n随着时间的推移，助理学会推荐与这些招聘人员验证模式相匹配的候选人。人机对齐还用于验证产品政策在实践中是否真正有效。\n\n## 结论\n\nLinkedIn 的 Hiring Assistant 展示了一种构建企业级 AI agent 的宏大方法。\n\n通过采用 plan-and-execute 架构，系统将复杂的招聘工作流分解为可管理的步骤，提高了可靠性并减少了错误。消息驱动设计允许每个招聘人员拥有自己的助理实例，在后台异步工作，实现了真正的规模化。\n\n专业化子 agent 之间的分工确保每个组件都能专注于其最擅长的领域，从寻源和评估到外联和筛选。与 LinkedIn 的 Economic Graph 集成提供了超越简单关键词匹配的市场情报，有助于发现可能被忽视的候选人。\n\n或许最重要的是，该系统平衡了自动化与人类判断。质量框架使助理安全并与真实的招聘结果保持一致，而 Learning Agent 确保基于个人招聘人员偏好的持续改进。\n\n## 参考文献\n\nBuilding the agentic future of recruiting: how we engineered LinkedIn’s Hiring Assistant\nUnder the hood: The tech behind the first agent from LinkedIn\nThe LinkedIn Generative AI Application Tech Stack\n\n---\n\n## 要点总结\n\n*   LinkedIn Hiring Assistant 是一个 AI agent，旨在通过处理重复性任务来增强招聘人员的能力，而非取代他们。\n*   系统采用“plan-and-execute”（计划与执行）架构，通过 Planner 规划和 Executor 执行，提高复杂任务的可靠性和可管理性。\n*   Hiring Assistant 运行于消息驱动、异步处理的架构上，为每个招聘人员提供独立的助理实例，支持大规模并发操作。\n*   它提供“交互模式”和“异步模式”（如“在你睡觉时寻源”）两种用户体验模式，适应招聘流程的不同阶段。\n*   核心由 Supervisor Agent 协调，负责工作流管理、任务路由和人机协作决策。\n*   系统由多个专业化子 agent 组成（如 Intake、Sourcing、Evaluation、Outreach、Screening、Learning、Cognitive Memory Agent），各司其职，模块化设计。\n*   Sourcing Agent 深度集成 LinkedIn 的 Economic Graph（经济图谱），提供超越关键词匹配的智能寻源能力。\n*   通过 Learning Agent 实现持续学习，根据招聘人员行为和反馈改进，并由 Cognitive Memory Agent 提供持久的记忆和个性化推荐。\n*   质量保障通过“护栏”（产品政策、AI 驱动评估器）和“指南针”（人机对齐、经验证数据）两个支柱确保系统安全、负责任且有效。\n*   系统设计强调 AI 自动化与人类判断之间的平衡，在关键决策点上保留了人类控制。\n\n## 你可以从这篇文章学到什么\n\n对于具有几年经验的后端/系统设计工程师而言，这篇文章提供了关于构建复杂企业级 AI 系统的宝贵实践经验和设计模式：\n\n1.  **AI 系统解耦与编排**：文章详细介绍了“plan-and-execute”架构，这是处理大型语言模型 (LLM) 复杂任务的有效策略。你可以学习如何将一个宏大的 AI 任务分解为更小、更可控的“计划”和“执行”阶段，从而提高系统的可靠性、可调试性和成本效益。在实际项目中，可以将复杂业务流程拆解为多个明确的步骤，并为每个步骤选择最合适的 AI 模型或业务逻辑。\n2.  **模块化与 Agentic 设计思想**：LinkedIn 将招聘流程划分为多个专业化子 agent（如 Intake、Sourcing、Evaluation 等），并由一个 Supervisor Agent 进行协调。这种“Agentic”设计模式是微服务架构在 AI 领域的延伸。它强调职责分离、模块化开发和独立扩展，有助于构建灵活且可维护的 AI 应用。你可以借鉴此模式来设计你的服务，让每个服务专注于一个明确的领域，并通过一个中央协调器进行管理。\n3.  **大规模异步处理与实时体验**：Hiring Assistant 采用消息驱动、异步架构，支持每个用户独立的助理实例并行工作。结合推送式、事件驱动的 UI 和流式响应，系统实现了高效的后台处理和流畅的实时用户体验。这对于设计需要处理长时间运行任务、高并发以及需要实时反馈的后端系统至关重要。\n4.  **人机协作与信任构建**：文章强调“human-in-the-loop”（人机协作）设计，确保人类在关键决策中保持控制，并通过透明的推理过程建立信任。对于任何面向用户的 AI 系统，工程师都需要考虑如何有效地融入人工审查、反馈和干预点，这不仅提升了系统质量，也满足了用户对可控性的需求。\n5.  **数据集成与领域智能**：Sourcing Agent 与 LinkedIn 的 Economic Graph 深度集成，展示了如何将通用 AI 能力与丰富的领域特定数据和知识图谱结合，以提供超越通用解决方案的独特价值。这启发我们，在设计系统时，应思考如何充分利用现有的数据资产和领域知识来增强 AI 模型的智能和准确性。\n6.  **AI 系统质量保障框架**：文章提出的“护栏”（规则、政策、AI 评估器）和“指南针”（人机对齐、验证数据）质量支柱，提供了一个构建负责任 AI 系统的全面框架。你可以将这些原则应用于自己的项目，建立清晰的质量标准、安全策略和验证机制，确保 AI 系统的产出符合预期并避免潜在风险。",
    "url": "https://blog.bytebytego.com/p/how-linkedin-built-an-ai-powered"
  }
]