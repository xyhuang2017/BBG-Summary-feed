[
  {
    "id": "2025-12-20-a-guide-to-retry-pattern-in-distributed-systems",
    "title": "A Guide to Retry Pattern in Distributed Systems",
    "date": "2025-12-20",
    "preview": "A Guide to Retry Pattern in Distributed Systems 分布式系统中的重试模式指南  ByteByteGo Dec 18, 2025 ∙ Paid 70 1 5 Share  在单体应用中，函数调用是一个本地的、内存中的进程。除了灾难性的硬...",
    "content": "A Guide to Retry Pattern in Distributed Systems\n分布式系统中的重试模式指南\n\nByteByteGo\nDec 18, 2025\n∙ Paid\n70\n1\n5\nShare\n\n在单体应用中，函数调用是一个本地的、内存中的进程。除了灾难性的硬件故障或进程崩溃之外，函数的执行基本得到保证。如果进程存活，调用就会成功。\n\n然而，在分布式系统中，这种保证不再成立。组件通过物理网络进行通信，而物理网络本质上是不可靠的。这一现实体现在“分布式计算的谬误”（Fallacies of Distributed Computing）中，特别是第一条谬误：“网络是可靠的”。但事实上，它并非如此。从 Service A 发送到 Service B 的请求可能会失败，并不是因为 Service B 本身出现故障，而仅仅是因为通信介质暂时出现了问题。\n\n这催生了对防御性编程模式的需求，其中我们使用的一个主要机制就是**重试模式**（Retry pattern）。通过自动重试失败的操作，系统可以牺牲一定的延迟（latency）来换取可用性（availability），从而将一个原本会失败的用户请求转化为成功的请求。\n\n然而，在分布式系统中，重试（retries）既至关重要又充满危险。一方面，它们能将不可靠的网络转化为相对可靠的网络。但另一方面，不加区别的重试可能导致延迟放大（latency amplification）、资源耗尽（resource exhaustion）以及级联故障（cascading failures），甚至可能导致整个平台崩溃。\n\n在本文中，我们将深入探讨重试模式，了解何时以及如何安全有效地使用它。\n\n什么是重试？\n\n继续免费阅读此文章，由 Alex Xu 友情提供。\n\n领取我的免费文章\n\n或购买付费订阅。\n\n## 要点总结\n\n*   **分布式系统中的网络不可靠性**：与单体应用不同，分布式系统中的网络通信本质上不可靠，请求可能会因网络瞬时故障而失败。\n*   **重试模式的引入**：Retry pattern（重试模式）是一种防御性编程模式，旨在通过自动重试失败的操作来提高系统的可用性。\n*   **权衡与收益**：通过重试，系统可以牺牲一定的延迟（latency）来提高可用性（availability），将原本失败的请求转化为成功。\n*   **重试的危险性**：不加区别的重试可能导致延迟放大（latency amplification）、资源耗尽（resource exhaustion）和级联故障（cascading failures），甚至可能导致整个平台崩溃。\n*   **核心议题**：文章将深入探讨何时以及如何安全有效地使用重试模式。\n\n## 你可以从这篇文章学到什么\n\n作为一名资深的后端或系统设计工程师，你可能已经无数次遇到过因为网络波动或瞬时服务故障导致的请求失败。这篇文章虽然只是一个引子，但它精准地抓住了分布式系统中最核心、也最容易被忽视的问题——网络的本质不可靠性，并提出了一个关键的应对策略：Retry pattern（重试模式）。\n\n你可以从这篇文章中学到以下几点，并将其应用于实际项目：\n\n1.  **对分布式系统网络本质的深刻理解**：文章开篇便强调了“网络是不可靠的”这一分布式计算的基本谬误。这提醒我们，在设计分布式系统时，必须从根本上承认并处理网络通信的易变性。理解这一点是构建高可用、高韧性系统的基石，避免将本地函数调用的思维套用到远程服务调用上。\n2.  **重试模式的价值与局限性**：文章指出了 Retry pattern 在提升系统可用性方面的巨大价值——它能将瞬时故障“抹平”，将失败的请求转化为成功。然而，更重要的是它提前警告了重试的“危险性”。对于有经验的工程师而言，这并非简单的概念普及，而是对实践中可能遇到的真实问题的预警，例如：\n    *   **延迟放大**：不恰当的重试策略（如固定间隔、重试次数过多）可能导致用户请求响应时间大幅增加。\n    *   **资源耗尽**：当后端服务压力过大或出现故障时，大量的重试请求可能进一步压垮服务，消耗连接池、线程等资源。\n    *   **级联故障**：一个服务的重试行为可能像多米诺骨牌一样，将负载传递并放大到其依赖服务，最终导致整个系统崩溃。\n3.  **如何将这些理念应用于实际项目**：\n    *   **设计合理的重试策略**：在你的微服务、API网关、数据库客户端或消息队列消费者中实现重试机制时，应仔细考虑重试次数上限、重试间隔（例如采用指数退避算法，避免“惊群效应”）、以及抖动（jitter）来分散请求。\n    *   **区分可重试与不可重试错误**：并非所有错误都应重试。例如，HTTP 5xx 错误（服务器内部错误）、网络超时通常是可重试的；而 HTTP 4xx 错误（客户端错误，如认证失败、参数错误）或明确的业务逻辑错误则不应重试。你需要根据错误类型和业务幂等性来做决策。\n    *   **结合断路器（Circuit Breaker）模式**：为了防止重试导致级联故障，应将 Retry pattern 与 Circuit Breaker 模式结合使用。当服务持续失败时，断路器可以“跳闸”，直接拒绝请求，给下游服务恢复的时间，而不是盲目重试。\n    *   **完善监控与告警**：在系统中引入重试机制后，务必对重试次数、重试成功率、因重试导致的平均延迟以及下游服务的错误率进行监控和告警。这能帮助你及时发现重试是否在过度工作，或者是否存在潜在的、被重试掩盖的慢性问题。\n    *   **考虑幂等性**：对于涉及数据修改的操作，确保你的操作是幂等的至关重要。即使重试导致请求发送多次，也能保证系统状态的一致性，避免副作用。\n\n总而言之，这篇文章虽然短小，但它为你在分布式系统中设计和实现健壮的重试机制提供了一个重要的视角——重试并非万能药，它是一把双刃剑。作为工程师，你需要深入理解其原理，并在实际项目中谨慎、智慧地运用它。",
    "url": "https://blog.bytebytego.com/p/a-guide-to-retry-pattern-in-distributed"
  },
  {
    "id": "2025-12-19-a-guide-to-retry-pattern-in-distributed-systems",
    "title": "A Guide to Retry Pattern in Distributed Systems",
    "date": "2025-12-19",
    "preview": "# 分布式系统中的重试模式指南  ByteByteGo 2025年12月18日 ∙ 付费 57 1 5 分享  在单体应用（monolithic application）中，函数调用（function call）是一个本地的、在内存中执行的进程。除了灾难性的硬件故障或进程崩溃，函...",
    "content": "# 分布式系统中的重试模式指南\n\nByteByteGo\n2025年12月18日\n∙ 付费\n57\n1\n5\n分享\n\n在单体应用（monolithic application）中，函数调用（function call）是一个本地的、在内存中执行的进程。除了灾难性的硬件故障或进程崩溃，函数执行的成功几乎是板上钉钉的。如果进程活着，调用就会成功。\n\n然而，在分布式系统（distributed systems）中，这种保证就不复存在了。组件之间通过物理网络进行通信，而物理网络本质上是不可靠的。这一现实在“分布式计算的谬误”（Fallacies of Distributed Computing）中得到了体现，特别是第一个谬误：“网络是可靠的”（The network is reliable）。事实上，它并非如此。从服务 A（Service A）发送到服务 B（Service B）的请求可能会失败，并不是因为服务 B 自身有问题，而仅仅是因为通信介质（communication medium）暂时出现了故障。\n\n这催生了对防御性编程模式（defensive programming patterns）的需求，而我们使用的主要机制之一就是重试模式（Retry pattern）。通过自动重试失败的操作，系统可以“以延迟换取可用性”（trade latency for availability），从而将原本失败的用户请求转化为成功的请求。\n\n然而，在分布式系统中，重试（retries）既至关重要又充满危险。一方面，它们能将不可靠的网络转化为相对可靠的网络。但另一方面，不加区分的重试可能导致延迟放大（latency amplification）、资源耗尽（resource exhaustion）以及级联故障（cascading failures），最终可能使整个平台崩溃。\n\n在本文中，我们将深入探讨重试模式，理解何时以及如何安全有效地使用它。\n\n什么是重试（Retry）？\n\n通过7天免费试用继续阅读\n订阅 ByteByteGo Newsletter\n继续阅读本文并获得7天免费访问所有历史文章的权限。\n开始试用\n已是付费订阅者？\n登录\n\n---\n\n### 要点总结\n\n*   在单体应用中，函数调用具有很高的可靠性；但在分布式系统中，由于网络本质上不可靠，这种可靠性不复存在。\n*   “网络是可靠的”是分布式计算的第一大谬误，实际上，网络通信故障是常态。\n*   重试模式（Retry pattern）是一种重要的防御性编程机制，用于处理分布式系统中可能出现的瞬时故障。\n*   通过自动重试失败的操作，系统可以提高可用性，将原本失败的请求转化为成功，但这通常会增加请求的延迟。\n*   重试在提高系统可靠性的同时，也潜藏着巨大风险。\n*   不加区分的重试可能导致延迟放大（latency amplification）、系统资源耗尽（resource exhaustion），甚至引发级联故障（cascading failures），最终拖垮整个平台。\n*   理解何时以及如何安全有效地应用重试模式，是构建健壮分布式系统的关键。\n\n---\n\n### 你可以从这篇文章学到什么\n\n作为一名有几年经验的后端/系统设计工程师，你将从本文中获得以下重要洞察和实践指导：\n\n1.  **强化对分布式系统本质的理解**：文章开宗明义地指出，分布式系统与单体应用在网络可靠性上的根本差异。这提醒你在设计系统时，必须始终将“网络不可靠”作为基本假设，并据此构建容错机制，而不是将其视为偶发事件。\n2.  **认识重试模式的双面性**：你将了解到，Retry pattern（重试模式）是解决瞬时网络故障和提高系统可用性的关键工具。但更重要的是，文章强调了不加区分的重试所带来的巨大风险，如延迟放大、资源耗尽和级联故障。这能帮助你避免在实际项目中盲目引入重试机制，并促使你深入思考其潜在的副作用。\n3.  **系统设计中的防御性思维**：本文引入了“防御性编程模式”的概念，促使你在设计API、服务间通信及容错机制时，主动思考并预设各种失败场景，并提前规划应对策略。这有助于你构建更稳定、更具弹性的系统。\n4.  **实践应用指导**：\n    *   在考虑引入重试时，要深入思考其**必要性**和**潜在危害**。例如，对于幂等（idempotent）操作，重试通常是安全的；而对于非幂等操作，则需配合其他补偿机制或严格限制。\n    *   理解重试并非万能药，它需要结合**熔断（Circuit Breaker）**、**限流（Rate Limiting）**、**超时（Timeout）**等其他容错模式一同使用，才能构建出真正健壮的分布式系统。\n    *   关注重试策略的**参数配置**，如最大重试次数、重试间隔（backoff strategy，如指数退避）以及哪些错误码应该重试。不合理的配置会直接导致文中提到的风险。\n    *   在部署系统后，要密切**监控**重试行为和其对系统整体性能（如延迟、资源利用率）的影响，以便及时调整优化。",
    "url": "https://blog.bytebytego.com/p/a-guide-to-retry-pattern-in-distributed"
  },
  {
    "id": "2025-12-18-how-meta-built-a-new-ai-powered-ads-model-for-5-better-conversions",
    "title": "How Meta Built a New AI-Powered Ads Model for 5% Better Conversions",
    "date": "2025-12-18",
    "preview": "Meta 如何构建全新 AI 驱动的广告模型，实现 5% 的转化率提升 ByteByteGo 2025年12月17日 95 2 分享 将代码审查时间和错误减少一半（赞助内容） 代码审查至关重要但耗时。CodeRabbit 可作为您的 AI 副驾驶，为每次拉取请求提供即时代码审查评...",
    "content": "Meta 如何构建全新 AI 驱动的广告模型，实现 5% 的转化率提升\nByteByteGo\n2025年12月17日\n95\n2\n分享\n将代码审查时间和错误减少一半（赞助内容）\n代码审查至关重要但耗时。CodeRabbit 可作为您的 AI 副驾驶，为每次拉取请求提供即时代码审查评论和潜在影响。\n除了标记问题，CodeRabbit 还提供一键修复建议，并允许您使用 AST Grep 模式定义自定义代码质量规则，从而捕获传统静态分析工具可能遗漏的细微问题。\nCodeRabbit 迄今已审查了超过 1000 万个 PR，安装在 200 万个存储库上，并被 10 万个开源项目使用。CodeRabbit 对所有开源存储库免费。\n立即开始\n免责声明：本文中的细节来源于 Meta 工程团队在线分享的信息。所有技术细节的功劳归 Meta 工程团队所有。原文和参考资料的链接在文章末尾的参考文献部分。我们尝试分析了这些细节并提供了我们的看法。如果您发现任何不准确或遗漏之处，请留言，我们将尽力修正。\n\nMeta 在 2025 年第二季度宣布，其新的生成式广告模型（Generative Ads Model，简称 GEM）使 Instagram 的广告转化率提高了 5%，Facebook Feed 的转化率提高了 3%。这些数字可能看起来不大。\n\n然而，在 Meta 的规模下，这些百分比意味着数十亿美元的额外收入，并代表着 AI 驱动广告运作方式的根本性转变。\n\nGEM 是有史以来为推荐系统构建的最大基础模型。它的训练规模通常仅限于 GPT-4 或 Claude 等大型语言模型（LLMs）。但矛盾之处在于：GEM 如此强大且计算密集，以至于 Meta 实际上无法直接用它来向用户投放广告。\n\n相反，该公司开发了一种教师-学生架构（teacher-student architecture），让更小、更快的模型能够受益于 GEM 的智能，而无需承担其计算成本。\n\n在本文中，我们将探讨 Meta 工程团队如何构建 GEM 以及他们克服的挑战。\n\n👋 告别低测试覆盖率和缓慢的 QA 周期（赞助内容）\n当少于 80% 的用户流程在发布前未经测试时，Bug 就会悄然出现。然而，对于任何团队来说，实现这种覆盖率（并保持下去）既困难又昂贵。\nQA Wolf 的 AI 原生解决方案为 Web 和移动应用提供大容量、高速的测试覆盖，将您的组织的 QA 周期缩短至几分钟。\n他们可以为您提供：\n在数周而非数年内实现 80% 的自动化端到端（E2E）测试覆盖\n无限并行测试运行\n24 小时维护和按需测试创建\n零缺陷保证\n好处是什么？不再进行手动 E2E 测试。不再有缓慢的 QA 周期。不再有 Bug 进入生产环境。\n在 QA Wolf 的帮助下，Drata 的工程师团队实现了 4 倍的测试用例和 86% 更快的 QA 周期。\n⭐ 在 G2 上评分为 4.8/5\n安排演示以了解更多信息\n\nGEM 解决的核心问题\n每天，数十亿用户在 Facebook、Instagram 和其他 Meta 平台上滚动浏览，产生数万亿潜在的广告展示机会。每一次展示都代表一个决策点：从数百万种可能性中，应该在特定时刻向特定用户展示哪个广告？弄错了意味着在不相关的广告上浪费广告商的预算，并用用户不关心的内容惹恼用户。做对了则为所有相关方创造价值。\n\n传统的广告推荐系统在以下几个方面难以应对：\n一些系统将每个平台单独处理，这意味着关于用户在 Instagram 上行为的洞察无法用于 Facebook 上的预测。这种孤立的方法错过了有价值的跨平台模式。其他系统试图将所有平台视为相同，忽略了人们与 Instagram Stories 的互动方式与他们浏览 Facebook Feed 的方式截然不同。这两种方法都不是最优的。\n\n数据复杂性也以以下方式加剧了这些挑战：\n*   与总展示量相比，点击和转化等有意义的信号极其稀疏。\n*   用户特征是动态的，并且不断变化。\n*   系统必须处理多模态输入，包括文本、图像、视频和复杂的行为序列。\n*   传统模型存在严重的内存限制，通常只考虑用户的最近 10 到 20 次操作。\n\nGEM 的目标是创建一个统一的智能系统，在 Meta 的整个生态系统中全面理解用户，从长期的行为历史和复杂的跨平台模式中学习，同时保持针对每个特定界面和目标进行优化的细微差别。\n\nGEM 如何理解用户？\nGEM 的架构通过三个互补的系统处理用户和广告信息，每个系统处理预测问题的不同方面。\n\n第一个系统处理 Meta 称之为“非序列特征”（non-sequence features）的信息，这些信息本质上是静态属性及其组合。这包括用户的年龄和位置等人口统计数据、用户兴趣、广告的格式和创意内容等广告特征，以及广告商的目标。\n\n这里的挑战不仅在于了解这些个体特征，还在于理解它们如何相互作用。例如，一个 25 岁的技术工作者与一个 25 岁的教师有着截然不同的购买模式，即使他们有一些共同的兴趣。系统需要学习哪些特征组合是真正重要的。\n\nGEM 使用 Wukong 架构的增强版本，该架构具有可堆叠分解机（stackable factorization machines），可以在更深层次的交互方面纵向扩展，也可以在更广泛的特征覆盖方面横向扩展。该架构通过多个堆叠层工作，每个后续层都从前一层发现的更简单模式中学习越来越复杂的模式。例如，早期层可能会发现年轻专业人士对科技产品广告反应良好这一基本模式。堆栈中更深一层则在此基础上学习，发现居住在城市地区并对健身表现出兴趣的年轻专业人士对智能穿戴设备广告反应特别好。更深一层可能会进一步细化，发现这种组合在广告强调数据追踪功能而非时尚元素时效果最佳。\n\n第二个系统处理“序列特征”（sequence features），它捕捉用户行为的时间线。用户的行为并非孤立存在。它们通过顺序和意义讲述一个故事。一个点击了居家健身内容，然后搜索附近健身房，然后查看了几个健身房网站，然后研究了会员费用的用户，显然正在经历一个特定的旅程。传统架构难以高效处理长序列，因为计算成本随序列长度迅速增长。\n\nGEM 通过金字塔并行结构（pyramid-parallel structure）克服了这一问题。可以将其视为在底层以块状处理您的行为历史，然后在中间层将这些块组合成更广泛的模式，最后在顶层将所有内容综合为完整的旅程理解。多个块可以同时而不是顺序处理，这显著提高了效率。\n\n这里的突破是规模。GEM 现在可以分析您过去的数千次操作，而不仅仅是最近的几次。这种扩展的视角揭示了更短的时间窗口根本无法捕捉到的模式，例如从偶然兴趣到认真购买意图的进展，这可能需要数月的时间才能形成。\n\n请看下图：\n[此处应为图片，文本版省略]\n\n第三个系统，名为 InterFormer，通过连接您的静态个人资料和您的行为时间线来处理“跨特征学习”（cross-feature learning）。这是 GEM 智能真正显现的地方。以前的方法会将您的整个行为历史压缩成一个紧凑的摘要向量（就像将一部完整的小说缩减为单一评分）。这种压缩不可避免地会丢失关于您旅程的关键细节。\n\nInterFormer 采用交错结构（interleaving structure）的不同方法。它在纯粹专注于理解您的行为序列的层和将这些行为与您的个人资料属性连接起来的层之间交替。\n\n第一个序列层可能识别出您对健身的兴趣随时间增加。\n第一个跨特征层然后考虑您的年龄、收入和位置背景如何塑造这种健身兴趣的含义。\n第二个序列层用这些新洞察重新审视您的行为，并可能注意到在您工作地点附近开了一家健身房后，您的健身研究加剧了。\n第二个跨特征层然后对购买意图和时机做出更深层次的连接。\n\n这种交替过程通过多个层持续进行，每个周期都在不丢失对完整行为记录访问的情况下提炼理解。\n\n使用 GEM 面临的实际问题\n尽管 GEM 具有明显的优势，但 Meta 在使用 GEM 方面面临着一个根本性的工程挑战。\n\nGEM 体积庞大，使用数千个 GPU 进行了长时间训练。直接为每次广告预测运行 GEM 将是慢得令人无法接受且成本高昂的。当用户在 Instagram 上滚动时，系统需要在几十毫秒内做出广告决策。GEM 根本无法在同时服务数十亿用户的情况下以这种速度运行。\n\nMeta 的解决方案是一种教师-学生架构，其中 GEM 扮演着主导教师的角色，训练数百个更小、更快的“垂直模型”（Vertical Models，简称 VMs），这些模型才真正在生产中投放广告。这些 VM 专门用于特定场景，例如 Instagram Stories 的点击预测或 Facebook Feed 的转化预测。每个 VM 都足够轻量，可以在几毫秒内做出预测，但它们比独立训练时要智能得多，因为它们从 GEM 中学习。\n\n知识转移通过两种策略发生。当 VM 在与 GEM 训练的相同领域运行，具有相似数据和目标时，直接转移（Direct transfer）起作用。GEM 可以直接教授这些模型。当 VM 在与 GEM 训练领域截然不同的专业领域工作时，分层转移（Hierarchical transfer）适用。在这些情况下，GEM 首先为 Instagram 或 Facebook Marketplace 等领域训练中等大小的领域特定基础模型（domain-specific foundation models）。然后，这些领域模型再教授更小的 VM。知识通过层级向下流动，在每个阶段进行适应和专门化。\n\nMeta 采用了三种先进技术来最大化转移效率：\n*   **带有学生适配器（Student Adapter）的知识蒸馏（Knowledge distillation）：** 学生模型学习复制 GEM 的推理过程，而不仅仅是最终预测。Student Adapter 使用最近的真实数据精炼 GEM 的预测，调整时间延迟和领域特定差异。\n*   **表征学习（Representation learning）：** 在教师模型和学生模型之间创建共享的概念框架。GEM 学习以能很好地跨不同模型大小进行转移的方式编码信息，在广告服务期间不增加计算开销。\n*   **参数共享（Parameter sharing）：** 这允许 VM 选择性地直接整合 GEM 中的特定组件。小型 VM 保持快速，同时借用 GEM 的复杂组件来执行复杂的用户理解任务。\n\n这三种技术结合起来，达到了标准知识蒸馏单独使用时的两倍效果。持续改进循环的工作方式如下：\n用户实时与快速 VM 互动\n他们的参与数据流回 Meta 的数据管道\nGEM 定期用这些新数据进行再训练，更新后的知识通过后训练技术转移到 VM\n改进后的 VM 部署到生产环境。\n这个循环持续重复，GEM 变得更智能，VM 定期获得智能更新。\n\n前所未有的规模训练\n构建 GEM 需要 Meta 从头开始重建其训练基础设施。\n\n挑战在于以 LLM 规模训练模型，但任务根本不同，是推荐而非语言生成。该公司实现了 23 倍的有效训练吞吐量提升，同时使用了 16 倍的 GPU，并同时将硬件效率提高了 1.43 倍。\n\n这需要多个领域的创新。多维并行（Multi-dimensional parallelism）协调数千个 GPU 如何协同工作，使用混合分片分布式并行（Hybrid Sharded Distributed Parallel）等技术分割模型的密集组件，同时通过数据并行和模型并行的组合处理嵌入表（embedding tables）等稀疏组件。目标是确保每个 GPU 都保持忙碌，并最大限度地减少等待来自其他 GPU 通信的空闲时间。\n\n系统级优化进一步提高了 GPU 利用率：\n*   为可变长度用户序列设计的自定义 GPU 内核（GPU kernels），融合操作以减少内存带宽瓶颈。\n*   PyTorch 2.0 图级编译（graph-level compilation）自动化激活检查点（activation checkpointing）和操作符融合（operator fusion）等优化。\n*   内存压缩（Memory compression），包括 FP8 量化（FP8 quantization），以在不影响准确性的情况下减少内存占用。\n*   NCCLX 通信集合（NCCLX communication collectives）处理 GPU 间通信，而不消耗主要的计算资源。\n\n效率提升不仅仅是原始训练速度。\nMeta 通过优化训练器初始化、数据读取器设置和检查点，将作业启动时间缩短了 5 倍。他们通过智能缓存策略将 PyTorch 2.0 编译时间缩短了 7 倍。这些可能看起来是微小的细节，但当您训练的模型需要花费数百万美元的计算资源时，每个百分点的效率提升都意义重大。\n\n结果是一个训练系统，可以快速迭代 GEM，以以前基础设施无法实现的速度整合新数据和架构改进。这使 Meta 能够将 GEM 保持在推荐 AI 的前沿，同时控制成本，使得这项巨大投资物有所值。\n\n结论\nMeta 的 GEM 路线图远超其当前能力。\n\n下一个主要演进涉及真正的多模态学习（multimodal learning），其中 GEM 同时处理文本、图像、音频和视频，而不是将它们视为单独的输入流。这将使 GEM 对用户偏好和广告创意效果在所有内容类型上都有更丰富的理解。该公司还在探索推理时扩缩（inference-time scaling），这将允许系统动态地为困难的预测分配更多计算资源，同时更有效地处理简单情况。\n\n或许最雄心勃勃的是，Meta 设想了一个统一互动模型（unified engagement model），该模型使用相同的底层智能对有机内容和广告进行排名。这将从根本上改变广告如何融入社交信息流，潜在地创造更无缝的体验，使广告感觉更像是自然的内容推荐而不是干扰。在广告商方面，GEM 的智能将实现更复杂的智能体自动化（agentic automation），其中 AI 系统可以以最少的人工干预管理和优化广告活动，同时实现更好的结果。\n\n参考文献：\nMeta’s Generative Ads Model (GEM): The Central Brain Accelerating Ads Recommendation AI Innovation\nInterFormer Research Paper\nWukong: Towards a Scaling Law for Large-Scale Recommendation\n\n赞助我们\n让您的产品呈现在超过 1,000,000 名科技专业人士面前。\n我们的时事通讯将您的产品和服务直接展示给重要的受众——数十万工程领导者和高级工程师——他们对重要的技术决策和大额采购具有影响力。\n席位预订迅速——立即预订\n广告位通常提前约 4 周售罄。为确保您的广告能够触达这批有影响力的受众，请立即发送电子邮件至 sponsorship@bytebytego.com 预订您的席位。\n95\n2\n分享\n\n---\n\n### 要点总结\n\n1.  **显著的商业价值：** Meta 的生成式广告模型（GEM）在 Instagram 和 Facebook 上分别带来了 5% 和 3% 的广告转化率提升，转化为数十亿美元的额外收入。\n2.  **规模与性能的矛盾：** GEM 是目前最大的推荐系统基础模型，训练规模与大型语言模型（LLM）相当，但其计算开销过大，无法直接用于实时广告服务。\n3.  **教师-学生架构：** Meta 采用教师-学生架构（teacher-student architecture），由功能强大的 GEM（教师模型）训练数百个更小、更快的垂直模型（VMs，学生模型），用于生产环境中的实时广告投放。\n4.  **GEM 的多维用户理解：** GEM 通过处理非序列特征（静态属性）、序列特征（用户行为时间线）以及 InterFormer 实现的跨特征学习（连接静态档案与行为时间线），全面理解用户。\n5.  **应对复杂数据挑战：** GEM 解决了传统广告系统面临的平台孤岛、数据稀疏、动态用户特征、多模态输入以及内存限制（能分析用户数千次历史行为）等问题。\n6.  **高效知识转移策略：** 通过知识蒸馏（Knowledge distillation）与学生适配器（Student Adapter）、表征学习（Representation learning）和参数共享（Parameter sharing）三种技术，最大化 GEM 向 VM 的知识转移效率。\n7.  **持续改进的反馈循环：** 系统设计包含一个持续循环：用户互动数据回流 -> GEM 定期使用新数据再训练 -> 更新知识传递给 VM -> 改进后的 VM 部署到生产环境。\n8.  **前所未有的训练规模：** Meta 重建了训练基础设施，实现了 23 倍的有效训练吞吐量提升和 1.43 倍的硬件效率提升，得益于多维并行、自定义 GPU 内核、PyTorch 2.0 优化和 FP8 量化等创新。\n9.  **未来发展路线图：** GEM 的未来计划包括真正的多模态学习、推理时扩缩（inference-time scaling）以及一个统一互动模型（unified engagement model），用于同时排名有机内容和广告，并实现更高级的智能体自动化（agentic automation）。\n\n### 你可以从这篇文章学到什么\n\n对于具有几年经验的后端/系统设计工程师而言，这篇文章提供了宝贵的见解和可应用的设计模式：\n\n1.  **大规模模型部署的教师-学生架构（Teacher-Student Architecture）：** 这是处理大型、计算密集型 AI 模型上线部署的关键模式。当你拥有一个准确但运行成本高昂的模型（教师）时，可以利用它来训练多个小巧、快速的模型（学生），用于应对生产环境的实时请求。\n    *   **应用场景：** 如果你的数据科学团队开发出 SOTA（State-Of-The-Art）模型，但其推理延迟无法满足实时 API 调用需求，可以考虑知识蒸馏策略。教师模型可以离线运行或不频繁更新，而学生模型则负责处理实时流量，在保证性能的同时，继承教师模型的智能。这不仅限于广告推荐，也可用于大规模内容审核、个性化搜索等。\n2.  **处理复杂和多模态数据的系统设计：** 文章详细介绍了 GEM 如何整合静态特征、序列行为和跨特征交互。对于系统设计师来说，这强调了构建一个健壮的特征存储（feature store）和数据管道的重要性，该管道需要高效地摄取、转换并服务各种数据类型（结构化数据、时间序列数据、多模态数据），以喂给复杂的模型。\n    *   **应用场景：** 在设计机器学习数据管道时，不仅要考虑原始数据，还要思考如何有效地整合用户画像、历史交互和上下文信息。例如，如何存储和快速检索一个用户“数千次过去的行为”而不造成性能瓶颈，可以考虑使用时间序列数据库、图数据库或优化的列式存储。\n3.  **大规模 ML 训练基础设施的优化：** Meta 在训练基础设施上的创新（如多维并行、GPU 利用率优化、PyTorch 2.0 特性、内存压缩和通信集合）对任何大规模机器学习项目都具有指导意义。即使你没有构建 LLM 规模的系统，理解这些概念也能帮助你设计更高效的训练环境，显著降低成本和时间。\n    *   **应用场景：** 当你在处理大型模型或数据集时，应该了解数据并行、模型并行、混合精度训练（如 FP8 量化）和高效的 GPU 间通信（如 NCCLX）等技术。这些是优化计算资源利用率、减少模型训练时间与成本的关键。\n4.  **持续学习与反馈循环的设计：** 文章中描绘的用户互动 -> 数据回流 -> GEM 再训练 -> VM 更新 -> 部署的连续改进循环，是一个强大的设计模式。系统设计师应始终考虑如何将生产环境中的反馈数据高效地重新注入模型训练流程，实现模型的持续学习和适应。\n    *   **应用场景：** 在设计你的机器学习系统时，明确定义数据采集、清洗、特征工程、模型训练、模型评估和部署的反馈闭环。思考如何自动化这些流程，以及如何实现模型的 A/B 测试和灰度发布，确保新模型迭代能够稳定且快速地投入生产。\n5.  **构建统一智能层的思路：** Meta 设想的“统一互动模型”，使用同一套底层智能来排名有机内容和广告，展示了一种更宏观、更统一的系统设计趋势。\n    *   **应用场景：** 如果你的平台涉及多种内容类型（例如，社交媒体信息流、电商推荐、搜索结果），可以思考如何抽象出一个共享的“理解”层或“意图”层，为不同的子系统提供服务。这不仅可能带来更连贯、更个性化的用户体验，也能减少不同系统间的重复开发和维护成本。",
    "url": "https://blog.bytebytego.com/p/how-meta-built-a-new-ai-powered-ads"
  },
  {
    "id": "2025-12-17-how-meta-built-a-new-ai-powered-ads-model-for-5-better-conversions",
    "title": "How Meta Built a New AI-Powered Ads Model for 5% Better Conversions",
    "date": "2025-12-17",
    "preview": "Meta 如何构建新的 AI 驱动广告模型以实现 5% 的转化率提升 ByteByteGo  当 Meta 在 2025 年第二季度宣布其新的生成式广告模型 (GEM) 使 Instagram 的广告转化率提高了 5%，Facebook Feed 提高了 3% 时，这些数字可能看...",
    "content": "Meta 如何构建新的 AI 驱动广告模型以实现 5% 的转化率提升\nByteByteGo\n\n当 Meta 在 2025 年第二季度宣布其新的生成式广告模型 (GEM) 使 Instagram 的广告转化率提高了 5%，Facebook Feed 提高了 3% 时，这些数字可能看起来不大。\n\n然而，在 Meta 的规模下，这些百分比意味着数十亿美元的额外收入，并代表了 AI 驱动广告运作方式的根本性转变。\n\nGEM 是有史以来为推荐系统构建的最大基础模型。它的训练规模通常只用于像 GPT-4 或 Claude 这样的大型语言模型。然而，悖论在于：GEM 如此强大且计算密集，以至于 Meta 实际上无法直接使用它来向用户提供广告。\n\n相反，该公司开发了一种教师-学生架构，让更小、更快的模型能够从 GEM 的智能中获益，而无需继承其计算成本。\n\n在本文中，我们将探讨 Meta 工程团队如何构建 GEM 以及他们克服的挑战。\n\n## GEM 解决的核心问题\n\n每天，数十亿用户滚动浏览 Facebook、Instagram 和其他 Meta 平台，产生数万亿潜在的广告展示机会。每一次展示都代表一个决策点：从数百万种可能性中，应该在特定时刻向特定用户展示哪个广告？做错了，就意味着浪费广告商预算在不相关的广告上，并用用户不关心的内容惹恼他们。做对了，就能为所有相关方创造价值。\n\n传统的广告推荐系统在几个方面都面临挑战。一些系统将每个平台独立对待，这意味着关于用户在 Instagram 上行为的洞察无法用于 Facebook 上的预测。这种孤立的方法错失了有价值的跨平台模式。其他系统试图将所有平台同等对待，却忽略了人们与 Instagram Stories 互动的方式与他们浏览 Facebook Feed 的方式截然不同。这两种方法都不是最优的。\n\n数据复杂性也通过以下方式加剧了这些挑战：\n\n*   与总展示量相比，点击和转化等有意义的信号极其稀疏。\n*   用户特征是动态且不断变化的。\n*   系统必须处理多模态输入，包括文本、图像、视频和复杂的行为序列。\n*   传统模型存在严重的内存限制，通常只考虑用户最近 10 到 20 个行为。\n\nGEM 的目标是创建一个统一智能，在 Meta 的整个生态系统中全面理解用户，从长期的行为历史和复杂的跨平台模式中学习，同时保持针对每个具体界面和目标进行优化所需的细微差别。\n\n## GEM 如何理解用户？\n\nGEM 的架构通过三个互补系统处理用户和广告信息，每个系统处理预测问题的不同方面。\n\n第一个系统处理 Meta 所谓的非序列特征，这本质上是静态属性及其组合。这些包括用户人口统计信息（如年龄和位置）、用户兴趣、广告特征（如格式和创意内容）以及广告商目标。\n\n这里的挑战不仅在于了解这些单独的特征，还在于理解它们如何相互作用。例如，一个 25 岁的科技工作者与一个 25 岁的教师有非常不同的购买模式，即使他们有一些共同的兴趣。系统需要学习哪些特征组合真正重要。\n\nGEM 使用 Wukong 架构的增强版，该架构带有可堆叠因子分解机 (stackable factorization machines)，可以垂直扩展以实现更深层次的交互，也可以水平扩展以实现更广泛的特征覆盖。该架构通过多个堆叠层工作，其中每个后续层从前一层发现的更简单模式中学习日益复杂的模式。例如，早期层可能发现年轻专业人士对科技产品广告反应良好这一基本模式。堆栈中更深一层则在此基础上学习到，城市地区对健身感兴趣的年轻专业人士对智能可穿戴设备广告反应尤其好。更深一层可能会进一步细化这一点，发现这种组合在广告强调数据跟踪功能而非时尚元素时效果最佳。\n\n第二个系统处理序列特征，它捕捉用户行为的时间线。用户的行为并非孤立存在，它们以顺序和意义讲述一个故事。一个用户先点击了家庭健身内容，然后搜索附近的健身房，接着浏览了几个健身房网站，然后研究了会员费，这显然是在进行一次特定的旅程。传统架构难以有效地处理长序列，因为计算成本随序列长度快速增长。\n\nGEM 通过金字塔并行结构克服了这一点。可以将其想象成在底层分块处理你的行为历史，然后将这些分块组合成中间层更广泛的模式，最后在顶层将所有信息合成，形成完整的旅程理解。多个分块可以同时处理而非顺序处理，这显著提高了效率。\n\n这里的突破是规模。GEM 现在可以分析你过去数千个行为，而不仅仅是最近的几个。这种扩展视图揭示了更短窗口根本无法捕捉到的模式，例如从随意兴趣到认真购买意图的渐进发展，这可能需要数月时间。\n\n请参见下图：\n(原文配图，此处省略)\n\n第三个系统，名为 InterFormer，通过连接你的静态画像和行为时间线来处理跨特征学习。这正是 GEM 智能真正显现的地方。以前的方法会将你的整个行为历史压缩成一个紧凑的摘要向量（就像将一部完整的小说缩减为单一评分）。这种压缩不可避免地会丢失你旅程中的关键细节。\n\nInterFormer 采用一种不同的方法，使用交错结构。它在纯粹专注于理解你的行为序列的层和将这些行为与你的画像属性连接起来的层之间交替。\n\n*   第一个序列层可能识别出你对健身的兴趣随时间增长。\n*   第一个跨特征层然后考虑你的年龄、收入和位置上下文如何塑造这种健身兴趣的含义。\n*   第二个序列层用这些新洞察重新审视你的行为，可能会注意到你在工作地点附近开设健身房后，你的健身研究变得更加深入。\n*   第二个跨特征层然后对购买意图和时机做出更深层次的连接。\n\n这种交替过程通过多个层持续进行，每个周期都在不丢失完整行为记录的情况下，循环地完善理解。\n\n## 使用 GEM 的实际问题\n\n尽管 GEM 具有明显的优势，Meta 在使用 GEM 时面临一个根本性的工程挑战。\n\nGEM 规模庞大，使用数千个 GPU 经过长时间训练。直接为每次广告预测运行 GEM 将是慢得无法接受且成本高昂的。当用户滚动浏览 Instagram 时，系统需要在几十毫秒内做出广告决策。GEM 在同时服务数十亿用户时根本无法以这种速度运行。\n\nMeta 的解决方案是采用教师-学生架构，其中 GEM 充当主导师，训练数百个更小、更快的垂直模型 (VMs)，这些 VMs 实际在生产环境中提供广告服务。这些 VMs 针对特定上下文进行专门化，例如 Instagram Stories 的点击预测或 Facebook Feed 的转化预测。每个 VM 都足够轻量，可以在几毫秒内做出预测，但它们比独立训练时更智能，因为它们从 GEM 中学习。\n\n知识迁移通过两种策略进行。当 VM 在与 GEM 训练的相同领域运作，具有相似数据和目标时，直接迁移 (Direct transfer) 起作用。GEM 可以直接教授这些模型。当 VMs 在与 GEM 训练领域截然不同的专业领域工作时，分层迁移 (Hierarchical transfer) 则适用。在这些情况下，GEM 首先为 Instagram 或 Facebook Marketplace 等领域训练中型领域特定基础模型。然后，这些领域模型再训练更小的 VMs。知识通过层级向下流动，在每个阶段得到适应和专门化。\n\nMeta 采用了三种复杂技术来最大化迁移效率：\n\n*   **带有 Student Adapter 的知识蒸馏 (Knowledge distillation with Student Adapter)**：学生模型学习复制 GEM 的推理过程，而不仅仅是最终预测。Student Adapter 使用最新的真实数据优化 GEM 的预测，调整时间延迟和领域特定差异。\n*   **表示学习 (Representation learning)**：在教师和学生之间创建共享的概念框架。GEM 学习以易于在不同模型大小之间迁移的方式编码信息，在广告服务期间不增加计算开销。\n*   **参数共享 (Parameter sharing)**：这使得 VMs 能够选择性地直接从 GEM 中整合特定组件。小型 VMs 保持快速，同时借用 GEM 的复杂组件来执行复杂的用户理解任务。\n\n这三种技术共同实现了单独使用标准知识蒸馏两倍的效果。持续改进循环的工作方式如下：\n\n*   用户实时与快速的 VMs 互动。\n*   他们的互动数据流回 Meta 的数据管道。\n*   GEM 定期基于这些新数据进行再训练，更新的知识通过训练后技术迁移到 VMs。\n*   改进后的 VMs 部署到生产环境。\n\n这个循环持续重复，GEM 变得越来越智能，VMs 定期获取智能更新。\n\n## 空前规模的训练\n\n构建 GEM 要求 Meta 从头开始重建其训练基础设施。\n\n挑战在于以 LLM（大语言模型）的规模训练一个模型，但任务是推荐而非语言生成，这与 LLM 根本不同。该公司实现了有效训练吞吐量增加 23 倍，同时使用了 16 倍的 GPU，并将硬件效率提高了 1.43 倍。\n\n这需要多个领域的创新。多维并行 (Multi-dimensional parallelism) 协调数千个 GPU 如何协同工作，使用像 Hybrid Sharded Distributed Parallel 这样的技术分割模型的密集组件，并通过数据并行和模型并行的结合处理像嵌入表 (embedding tables) 这样的稀疏组件。目标是确保每个 GPU 都保持忙碌，并最大限度地减少等待来自其他 GPU 通信的空闲时间。\n\n系统级优化进一步提高了 GPU 利用率：\n\n*   **专为可变长度用户序列设计的自定义 GPU 内核 (Custom GPU kernels)**，融合操作以减少内存带宽瓶颈。\n*   **PyTorch 2.0 图级编译 (graph-level compilation)** 自动化激活检查点 (activation checkpointing) 和操作符融合 (operator fusion) 等优化。\n*   **内存压缩 (Memory compression)**，包括 FP8 量化 (quantization) 以减少占用空间而不影响准确性。\n*   **NCCLX 通信集合 (communication collectives)** 处理 GPU 间通信，不占用主要计算资源。\n\n效率提升不仅仅是原始训练速度。\n\nMeta 通过优化训练器初始化、数据读取器设置和检查点 (checkpointing)，将作业启动时间缩短了 5 倍。他们通过智能缓存策略将 PyTorch 2.0 编译时间缩短了 7 倍。这些看似微不足道的细节，但在训练消耗数百万美元计算资源的模型时，每提高一个百分点的效率都至关重要。\n\n结果是一个能够快速迭代 GEM 的训练系统，以过去基础设施无法达到的速度整合新数据和架构改进。这使 Meta 能够将 GEM 保持在推荐 AI 的前沿，同时足够控制成本，使这项巨大投资物有所值。\n\n## 结论\n\nMeta 的 GEM 路线图远远超出了其当前能力。\n\n下一个主要演进涉及真正的多模态学习 (multimodal learning)，即 GEM 同时处理文本、图像、音频和视频，而不是将它们视为单独的输入流。这将对用户偏好和广告创意效果在所有内容类型上实现更丰富的理解。该公司还在探索推理时扩展 (inference-time scaling)，这将允许系统动态地为困难的预测分配更多计算资源，同时更高效地处理直接的案例。\n\n或许最雄心勃勃的是，Meta 设想一个统一互动模型 (unified engagement model)，使用相同的底层智能对有机内容和广告进行排名。这将从根本上改变广告如何融入社交信息流，可能创造更无缝的体验，让广告感觉像是自然的内容推荐而不是中断。在广告商方面，GEM 的智能将实现更复杂的代理自动化 (agentic automation)，其中 AI 系统可以以最少的人工干预管理和优化广告活动，同时实现更好的结果。\n\n## 参考文献:\n*   Meta’s Generative Ads Model (GEM): The Central Brain Accelerating Ads Recommendation AI Innovation\n*   InterFormer Research Paper\n*   Wukong: Towards a Scaling Law for Large-Scale Recommendation\n\n---\n\n## 要点总结\n\n*   **核心挑战与 GEM 的目标**：传统广告推荐系统难以处理跨平台、数据稀疏、动态特征和多模态输入。GEM 旨在通过统一智能，在 Meta 整个生态系统中全面理解用户，优化特定场景。\n*   **GEM 的用户理解架构**：GEM 通过三个互补系统理解用户：非序列特征系统（基于 Wukong 架构和可堆叠因子分解机）、序列特征系统（采用金字塔并行结构处理长序列）和 InterFormer（通过交错结构连接静态画像和行为时间线进行跨特征学习）。\n*   **教师-学生架构**：由于 GEM 本身计算成本过高，无法直接服务实时请求，Meta 采用教师-学生架构。GEM 作为“教师”训练数百个更小、更快的“垂直模型 (VMs)”，这些 VMs 在生产环境中提供广告服务。\n*   **知识迁移策略**：知识从 GEM 迁移到 VMs 的策略包括直接迁移和分层迁移，并结合了三种核心技术：带有 Student Adapter 的知识蒸馏、表示学习和参数共享，以最大化迁移效率。\n*   **持续改进循环**：系统通过用户互动数据反馈给 GEM 进行再训练，然后将更新的知识迁移到 VMs 并部署，形成一个不断学习和优化的闭环。\n*   **空前规模的训练基础设施**：Meta 为 GEM 的训练从头构建了基础设施，实现了 LLM 规模的推荐模型训练，大幅提升了训练吞吐量和硬件效率。\n*   **关键的训练优化技术**：高效训练依赖于多维并行（处理密集和稀疏组件）、自定义 GPU 内核、PyTorch 2.0 图级编译（包括激活检查点和操作符融合）以及内存压缩（如 FP8 量化）。\n*   **工程效率提升**：通过优化训练器初始化、数据读取器设置、检查点和智能缓存策略，Meta 将作业启动和编译时间大幅缩短，提升了整体工程迭代效率。\n*   **GEM 的未来方向**：包括真正的多模态学习（处理多种媒体类型）、推理时扩展（动态分配计算资源）以及统一互动模型（将有机内容和广告一同排名），以创造更无缝的用户体验和实现更高级的代理自动化。\n\n## 你可以从这篇文章学到什么\n\n作为一名有几年经验的后端/系统设计工程师，这篇文章为你提供了在构建和优化超大规模 AI 驱动系统方面的宝贵洞察和实践经验：\n\n1.  **处理复杂性的分层架构设计**：GEM 在理解用户方面采用了“非序列特征”、“序列特征”和“跨特征学习”三个互补系统，这种将复杂问题分解为多个专业化、协同工作的子系统的思想，在设计任何大型后端系统时都非常有用。你可以学习如何将一个宏大的功能拆解为可管理、可优化的模块。\n2.  **师生模型 (知识蒸馏) 的实用策略**：当你面对一个功能强大但计算资源消耗巨大的核心模型时（例如一个复杂的机器学习模型，或一个耗时的大型复杂计算模块），“教师-学生架构”是一种非常有效的解决方案。它可以帮助你在性能、成本和准确性之间找到平衡点，在生产环境中提供快速、低成本的服务，同时保留核心模型的“智能”。这对于优化延迟敏感的服务尤其重要。\n3.  **大规模机器学习基础设施的挑战与解决方案**：文章详细描述了 Meta 如何应对 LLM 规模的推荐模型训练挑战。即使你不是 ML 工程师，理解多维并行、GPU 内核优化、内存管理（如 FP8 量化）、以及 PyTorch 2.0 编译优化等技术，能帮助你更好地与 ML 团队协作，并为任何计算密集型服务提供基础设施支持和优化思路。\n4.  **持续改进和迭代的系统思维**：从用户互动到数据回流、模型再训练、知识迁移和部署的闭环，是现代数据驱动系统不断进化的关键。这强调了监控、数据管道、A/B 测试和快速迭代在系统设计中的核心地位，确保系统能够随着业务和用户行为的变化而演进。\n5.  **特征工程和模式识别的深度思考**：GEM 如何通过 Wukong 架构处理特征交互、通过金字塔并行结构处理长序列行为，以及 InterFormer 如何整合静态与动态特征，都提供了在设计数据模型和处理业务逻辑时，对数据维度、时间序列和多源信息整合的深刻启发。这能帮助你设计更智能的数据处理流程和更准确的业务规则。\n6.  **性能与效率优化的细节考量**：文章中提到的作业启动时间、编译时间优化，以及 GPU 利用率的提升，都提醒我们，在超大规模系统中，即使是看似微小的细节，其累积效应也可能带来巨大的成本节约和效率提升。这培养了对系统每个环节进行性能剖析和优化的习惯。\n7.  **前瞻性的技术发展趋势**：了解多模态学习、推理时资源动态分配、以及统一内容与广告排名等未来方向，有助于你对技术栈进行前瞻性规划，并保持对行业最新发展趋势的敏感度，从而在职业发展中保持竞争力。",
    "url": "https://blog.bytebytego.com/p/how-meta-built-a-new-ai-powered-ads"
  }
]